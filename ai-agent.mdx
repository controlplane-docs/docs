---
title: AI Agent Helper
---

This file aggregates all pages in the project to assist AI agents.

## Sections
## common-configs


### environment-variables
**Path**: `common-configs/environment-variables.mdx`




### Tags
**Path**: `common-configs/tags.mdx`

---
title: Tags
---

Tags are key-value pairs that can be assigned to items. All Control Plane resources support tags except for `quota` items.

These tags can be used by the clients to query/filter/select a resource based on its keys and value.

Also some kinds support targeting items of other kinds, by utilizing tags through a [query](/platform/query).

## CPLN Assigned Tags

Control Plane Platform can assign tags to items. See the list below for each item kind that is assigned a tag automatically,

TODO add tags for each items here

## Invalid Tag Keys

Any tag key starting with `cpln/` is reserved and cannot be altered by the user.


## common-configs/envoy


### auth
**Path**: `common-configs/envoy/auth.mdx`




### overview
**Path**: `common-configs/envoy/overview.mdx`




## getting-started


### 3. Connect a Custom Domain
**Path**: `getting-started/connect-a-custom-domain.mdx`

---
title: 3. Connect a Custom Domain
---

## Overview

This quick start will demonstrate how to:

- Create and configure a [domain](/reference/domain) resource within Control Plane using both path and subdomain based routing to serve requests to your workload.
- Review and test your configured domain.

## Prerequisites

- A running [Workload](/reference/workload). If you don't have one, follow this [Quick Start](/quickstart/sample-application).
- Access to a domain name and the ability to update its DNS records.

## Step One - Register your APEX Domain

An apex domain, also known as a root domain, refers to a domain name that does not have any subdomain prefix (e.g., **example.com**).

Even if the apex domain isn't served at Control Plane, it needs to be created and configured for verification. This verification is done by adding a TXT record to DNS.

For this quick start guide, we'll set up the apex domain solely for verification, without configuring any routing.

<Tip>As a best practice, create the apex domain in the Org designated for your production environment.</Tip>

1. Create a new Domain resource by using one of the following methods:

   - Clicking `Domains` in the left menu and click `New`, or
   - Click the `Create` dropdown in the upper right corner and select `Domain`.

2. The console will prompt for the domain name (e.g., **example.com**). Enter your apex domain and click `Continue`.

3. The console will display the necessary TXT record to be added to DNS. Once you've added it, wait a few minutes for it to propagate online. Afterward, press the "I Configured DNS, Continue" button to allow Control Plane to verify the apex domain.

4. After verification, the console will default to show the configuration for `Path Based Routing`. Since the apex domain will not be routed to a workload, click the `Edit` button to the right of `DNS & ROUTING MODES`, then click `Advanced Mode`, then click `Show More Options`.

5. Select `None` for the `Routing Mode`, and click `Continue`.

6. The console will show the default setting for advanced mode. Scroll to the bottom of the page and click `Create`.

Your APEX domain has been successfully created at Control Plane and sub-domains of the apex domain can now be created.

## Step Two - Review Routing Modes

Control Plane provides two routing modes for directing requests to your domain. Read the descriptions below to determine the best mode for your needs.

1. **Path Routing**

   - A CNAME records is added to DNS.
   - Best choice when path based routing is required.
   - You maintain full control of DNS for the domain.
   - CDN / WAF Compatible.
   - Examples:
     - **https://sub.example.com/workload_one**
     - **https://sub.example.com/workload_two**
   - Refer to [Step Three](#step-three-configure-path-routing) for configuration instructions.

2. **Subdomain Routing**

   - NS records are added to your DNS to delegate DNS to Control Plane for this domain **only**.
   - Best choice when a unique DNS subdomain is required for each workload.
   - One-time configuration.
   - Works for all current and future workloads in a GVC.
   - Examples:
     - **https://workload_one.sub.example.com**
     - **https://workload_two.sub.example.com**
   - Refer to [Step Four](#step-four-configure-subdomain-routing) for configuration instructions.

## Step Three - Configure Path Routing

1. Create a new domain resource by using one of the following methods:

   - Clicking `Domains` in the left menu and click `New`, or
   - Click the `Create` dropdown in the upper right corner and select `Domain`.

2. The console will prompt for the desired domain name (e.g., **sub.example.com**). Click `Continue`.

3. The console will display the two routing modes. Click `Use CNAME Record & Path Routing`.

4. The console will prompt you to select the GVC which contains the workload that the domain will be routed to.

5. Once the GVC is selected, the console will prompt you to select the workload. After the workload is selected, click `Continue`.

6. The required CNAME record will be displayed. This record will need to be added by the person who is responsible for maintaining DNS for the domain. After adding it, allow a few minutes for propagation across the Internet. Click the `I have created the DNS record` checkbox and then click `Create`.

<Note>

Control Plane won't verify the CNAME record. Certificate generation and routing will only commence once the record is added, and the chosen workload is in a ready state, capable of accepting requests from the Internet.

**Tip:** When adding the domain using GoDaddy, the minimum TTL is 600.

</Note>

Your domain has been successfully created at Control Plane and will serve the selected workload on the path `"/"` once DNS is updated and the certificates have been generated.

Additional routes and advanced domain configuration options are available by clicking the `Edit` link and clicking the `Advanced Mode` button. For additional details on path based routing, click [here](/reference/domain#path-based-routing).

## Step Four - Configure Subdomain Routing

1. Create a new domain resource by using one of the following methods:

   - Clicking `Domains` in the left menu and click `New`, or
   - Click the `Create` dropdown in the upper right corner and select `Domain`.

2. The console will prompt for the desired domain name (e.g., **sub.example.com**). Click `Continue`.

3. The console will display the two routing modes. Click `Use NS Records & Subdomain Routing`.

4. The console will prompt you to select the GVC which contains the workloads that the domain will be routed to. Click `Continue`.

5. The required NS records will be displayed. These records will need to be added by the person who is responsible for maintaining DNS for the domain. After adding it, allow a few minutes for propagation across the Internet. Click the `I have created the DNS record` checkbox and then click `Create`.

<Note>

Control Plane won't verify the NS records. Certificate generation and routing will only commence once the records are added, and the chosen workload is in a ready state, capable of accepting requests from the Internet.

**Tip:** When adding the domain using GoDaddy, the minimum TTL is 600.

</Note>

Your domain has been successfully created at Control Plane and will serve all the workloads within the GVC using the pattern: `https://WORKLOAD_NAME.sub.example.com`.

Advanced domain configuration options are available by clicking the `Edit` link and clicking the `Advanced Mode` button. For additional details on subdomain routing, click [here](/reference/domain#subdomain-based-routing).

## Step Five - Review and Test Domains

1. In the left menu, click on `Workloads` and choose the workload specified during the domain configuration. If your org has multiple GVCs, ensure the GVC currently selected matches the one chosen during the domain configuration.

2. The Workload `Info` page will be displayed which includes the list of URLs that will route to this workload.

   - **Internal Name:** Use this URL to call another workload within your Org. See the [service-to-service quick start](/quickstart/quick-start-5-service-to-service-calls) for more information.
   - **Canonical Endpoint (Global):** This URL uses the default Control Plane domain `cpln.app` and is typically used for troubleshooting or when there is no domain serving the workload.
   - The rest of the list displays the URLs configured for path-based or subdomain-based routing.
   - This list of URLs are automatically secured using TLS certificates, load balanced, and DNS geo-routed to the nearest healthy [Location](/reference/location).

3. Click `Deployments`. This page shows the providers this Workload is deployed to. Next to each provider is the location specific URL. Clicking the `Open` link will load the Workload only in that Location. These links can be used for troubleshooting.

## Summary

By taking the step to configure your custom domain enables a secure and reliable pathway to access your Workload. This not only enhances the integrity and reliability of your operations but also ensures that every interaction is seamlessly aligned with the identity and branding of your organization. This practice fosters trust and consistency, especially when dealing with external stakeholders or customers who recognize and resonate with your brand's identity.


### "1. Create an Account & Org"
**Path**: `getting-started/create-an-account-org-gvc.mdx`

---
title: "1. Create an Account & Org"
---

Currently, only way to create a Control Plane account is through the [Console](https://console.cpln.io/signup). 

<Note>
You will need to input a credit card to be able to create an account and use the platform. 

No money will be collected outside of the usage.
</Note>

During the account creation, you are also asked to create an [Org](/objects/org) and a [GVC](/objects/gvc).

If somehow you have issues while creating the org and gvc, you can still create them afterwards. See the guides [Create an Org](/guides/create-an-org) and [Create a GVC](/guides/create-a-gvc).


### 2. Deploy Your First Workload
**Path**: `getting-started/deploy-your-first-workload.mdx`

---
title: 2. Deploy Your First Workload
---

Follow the steps below to get started using Control Plane by deploying a sample application.

This quick start will demonstrate:

- Logging in to the Control Plane console.
- Creating a [GVC](/reference/gvc) and a Workload.
- Deploying an application to multiple cloud providers and locations.

## Create a Workload

In this step, you will deploy a sample application by creating a [Workload](/objects/workload).

<Tabs>
  <Tab title="Console">
      <Steps>
         <Step title="Navigate to Create Form">
            Either use the `Create` button on top right and select Workload, or navigate to `Workloads` page from the left side menu. 
            Once the workload list is, click the `New` button above the table.
         </Step>
         <Step title="Name The Workload">
            Enter a name for your workload and click `Next (Container 1)`.
            Workload name must be at least 2 characters and it must starts with a letter.
         </Step>
         <Step title="Configure Container">
            In the `Image` textbox, type `cplnquickstarts/helloworld-go`
            The image `cplnquickstarts/helloworld-go` is a web app written in Go. When the Workload is navigated to, it will display the cloud provider and location in the browser.
            
            Toggle on the `Serves Traffic` switch to indicate that this workload will be serving requests on port 8080.
            <Note>
               The default port number in the UI is 8080 and happens to be the exposed port of the sample web app. Your containerized application may expose any other port except for the ports listed [here](/reference/workload#ports).
            </Note>

            Container name will be derived from the image name. Feel free to override it and customize the container name.
         </Step>
         <Step title="Allow Public Access">
            At the top of the Workload form, a `Make Public` button will appear. 

            By default, the workload firewall is closed to external inbound, external outbound and internal communication.

            Click `Make Public` button to allow all external inbound and outbound communication.
         </Step>
         <Step title="Confirm Creation">
            Click the `Create` button. The workload will be created and the `Info` page will be shown.
         </Step>
      </Steps>
   </Tab>
   <Tab title="CLI">
      Install CLI
      Setup default profile with org and gvc context

      ```bash Create a Workload Command
      cpln workload create --name example --image cplnquickstarts/helloworld-go --public
      ```

      `--public` argument opens this workload to all external inbound and outbound communication.

      <Note>
         The image `cplnquickstarts/helloworld-go` is a web app written in Go.

         When the Workload is navigated to, it will display the cloud provider and location in the browser.
      </Note>
   </Tab>
   <Tab title="Terraform">
   <Steps>
      <Step title="Setup Terraform Project">
         Create a terraform project and create the main.tf file shown as below.
   
         This file will set up the terraform provider plugin for Control Plane. It will also set up your profile, context and other necessary common values.
         
         ```hcl main.tf
         terraform {
            required_providers {
               cpln = {
                  source  = "controlplane-com/cpln"
                  version = "~> 1.0" # This constraint means use any version in the 1.x range
               }
            }
         }

         provider "cpln" {
            org     = "replaceWithYourOrgName"
            profile = "replaceWithYourCLIProfileName"
            token   = "replaceWithYourToken"
         }
         ```

         <Note>
            Use either profile or token, if you use profile, the system will receive a token from your cli profile.
         </Note>

         // TODO guide for creating a service account and using its key here
      </Step>
      <Step title="Workload Definition">
         After having the basic setup with `main.tf` file, you can create a `workload.tf` file with the content below.

         This file describes the example workload we want to create.

         ```hcl workload.tf
         resource "cpln_workload" "example" {
            name        = "example"

            container {
               name   = "main"
               image  = "cplnquickstarts/helloworld-go"
               ports {
                  number = 8080
                  protocol = "http"
               }
            }

            firewall_spec {
               external {
                  inbound_allow_cidr  = ["0.0.0.0/0"]
               }
            }
         }

         output "terraform-cp-gvc-example" {
            value = cpln_gvc.terraform-cp-gvc-example
         }   
         ```
      </Step>
   </Steps>
   </Tab>
   <Tab title="Pulumi">
   <Steps>
      <Step title="Prepare Pulumi Project">
      Execute commands below to create and setup a pulumi project

      // TODO guide to install pulumi

      ```
      pulumi new
      ```

      Follow pulumi cli directions to setup your project as you like.

      ```
      pulumi config set cpln:org replaceWithYourOrg
      ```

      ```
      pulumi config set cpln:profile replaceWithYourCLIProfile
      ```

      ```
      pulumi config set cpln:token replaceWithYourToken
      ```

      <Note>
         Use either profile or token, if you use profile, the system will receive a token from your cli profile.
      </Note>

      </Step>
      <Step title="Workload Definition">
      <CodeGroup>
      ```typescript Typescript
      import * as cpln from "@pulumiverse/cpln";

      const workload = new cpln.Workload("example", {
      containers: [
         {
            name: "main",
            image: "cplnquickstarts/helloworld-go",
            ports: [
            {
               number: 8080,
               protocol: "http",
            },
            ],
         },
      ],
      type: "serverless",
      gvc: "replaceWithYourGVC",
      });

      export const workloadId = workload.id;
      ```
      ```python Python
      import pulumiverse_cpln as cpln

      workload = cpln.Workload("example",
         containers=[
            {
                  "name": "main",
                  "image": "cplnquickstarts/helloworld-go",
                  "ports": [
                     {
                        "number": 8080,
                        "protocol": "http",
                     },
                  ],
            },
         ],
         type="serverless",
         gvc="replaceWithYourGVC",
      )

      workload_id = workload.id
      ```
      ```go Go
      package main

      import (
         "github.com/pulumi/pulumi-cpln/sdk/go/cpln"
         "github.com/pulumi/pulumi/sdk/v3/go/pulumi"
      )

      func main() {
         pulumi.Run(func(ctx *pulumi.Context) error {
            workload, err := cpln.NewWorkload(ctx, "example", &cpln.WorkloadArgs{
               Containers: cpln.WorkloadContainerArray{
                  &cpln.WorkloadContainerArgs{
                     Name:  pulumi.String("main"),
                     Image: pulumi.String("cplnquickstarts/helloworld-go"),
                     Ports: cpln.WorkloadContainerPortArray{
                        &cpln.WorkloadContainerPortArgs{
                           Number:   pulumi.Int(8080),
                           Protocol: pulumi.String("http"),
                        },
                     },
                  },
               },
               Type: pulumi.String("serverless"),
               Gvc:  pulumi.String("replaceWithYourGVC"),
            })
            if err != nil {
               return err
            }

            ctx.Export("workloadId", workload.ID())
            return nil
         })
      }

      ```
      ```csharp C#
      using Pulumi;
      using Pulumi.Cpln;

      class Program
      {
         static Task Main() => Deployment.RunAsync(() =>
         {
            var workload = new Workload("example", new WorkloadArgs
            {
                  Containers = 
                  {
                     new WorkloadContainerArgs
                     {
                        Name = "main",
                        Image = "cplnquickstarts/helloworld-go",
                        Ports = 
                        {
                              new WorkloadContainerPortArgs
                              {
                                 Number = 8080,
                                 Protocol = "http",
                              },
                        },
                     },
                  },
                  Type = "serverless",
                  Gvc = "replaceWithYourGVC",
            });

            return new Dictionary<string, object?>
            {
                  { "workloadId", workload.Id },
            };
         });
      }
      ```
      </CodeGroup>
      </Step>

   </Steps>
   </Tab>
</Tabs>

## Browse to the running Workload

In this step, you will browse to the global endpoint URL that was generated for this [Workload](/reference/workload). This URL is automatically secured using TLS, load balanced, and DNS geo-routed to the nearest healthy location.

1. After a minute or two, if the deployment was successful, the `Workload Health` will indicate `Ready`.
2. Click the `Open` link besides the `Global Endpoint` URL to launch the application in a new tab.
3. The output of the sample application will be shown indicating the cloud provider and location closest to you that served the request.

## View individual deployments

In this step, you will launch the sample application at each [Location](/reference/location).

1. Return to the console and click `Deployments`.
2. Next to each location is an `Open` link that will launch the application at its respective location. Take note that the URL is secured using TLS.

The output for each location will be similar to:

<CodeGroup>

```text aws-eu-central-1
Hello World!

Provider: aws
Location: /org/ORG_NAME/location/aws-eu-central-1
```

```text gcp-us-east1
Hello World!

Provider: gcp
Location: /org/ORG_NAME/location/gcp-us-east1
```

</CodeGroup>

## Summary

With a minimal amount of effort, you were able to deploy an application to multiple cloud providers and locations. This [Workload](/reference/workload) is now managed by Control Plane and you can easily modify any of the available options.

Click the `Next` button below to learn how to configure a custom domain for your [Workload](/reference/workload).


### 5. Service-to-Service Calls
**Path**: `getting-started/service-to-service-calls.mdx`

---
title: 5. Service-to-Service Calls
---

## Overview

Multiple [Workloads](/reference/workload) can be deployed to Control Plane that have a dependency on one another. By default, [Workloads](/reference/workload) are hardened and don't allow any access from other [Workloads](/reference/workload). Using the [internal firewall](/reference/workload#internal) settings, secure access (using mTLS) from other [Workloads](/reference/workload) can be enabled. This quick start will focus on allowing internal service-to-service calls between [Workloads](/reference/workload).

This quick start will demonstrate how to:

- Set up two [Workloads](/reference/workload) with a sample application.
- Configure a [Workloads'](/reference/workload) [internal firewall](/reference/workload#internal) to accept requests from other [Workloads](/reference/workload).
- Prove, using the sample application, that requests are only received by allowed [Workloads](/reference/workload).

## Prerequisites

- [Permissions](/reference/policy#permissions) to:

  - Create and edit a [GVC](/reference/gvc).
  - Create and edit a [Workloads](/reference/workload).

- Latest [CLI](/reference/cli#installation) installed.

## Sample Application

A sample application for this quick start is available as an image from [Docker Hub](https://hub.docker.com) that will display the following:

- [GVC](/reference/gvc) name.
- Cloud provider location.
- [Workload](/reference/workload) name.
- Response from a call to another URL (using the `url` query string parameter).
- The image is located at: `cplnquickstarts/service-to-service-quick-start:1.1`.

The source code for the sample application can be viewed [here](https://github.com/controlplane-com/examples/tree/main/quickstarts/5/service-to-service-quick-start).

## Step One - Create GVC and Two Workloads

1. Authenticate to Control Plane by executing the following [CLI](/reference/cli) command:

```
cpln login
```

2. Execute the following [CLI](/reference/cli) command to update your profile with a default [Org](/reference/org) which will be used by the subsequent commands (substitute ORG_NAME for your org):

```
cpln profile update default --org ORG_NAME
```

3. Execute the following [CLI](/reference/cli) command to create a [GVC](/reference/gvc) that will contain the two [Workloads](/reference/workload):

```
cpln gvc create --name quick-start-service-to-service --location aws-us-west-2
```

The [GVC](/reference/gvc) created is named `quick-start-service-to-service` and will be hosted at AWS within the us-west-2 region.

---

4. Execute the following [CLI](/reference/cli) command to create the two [Workloads](/reference/workload) that will be hosting the sample application.

**Note:** The [cpln apply](/guides/cpln-apply) command is used to create the [Workloads](/reference/workload) that are defined in the YAML manifest file. The file can be viewed by clicking [here](https://raw.githubusercontent.com/controlplane-com/examples/main/quickstarts/5/01_create_workloads.yaml).

```
curl https://raw.githubusercontent.com/controlplane-com/examples/main/quickstarts/5/01_create_workloads.yaml | cpln apply -f - --gvc quick-start-service-to-service
```

The first [Workload](/reference/workload) is named `server` and the second is named `client`. They are both configured with the sample application image and the firewall rules has been set to allow outside traffic.

---

5. Browse to the `server` [Workload](/reference/workload) using the [Console](https://console.cpln.io/):

   - Select the [GVC](/reference/gvc) named `quick-start-service-to-service`.
   - Click `Workloads` in the left menu and select `server`.

Once the `Workload Health` shows `Ready`, click on the `Open` link next to the `Global Endpoint` URL. A new browser tab will open and display the following:

```
Hello! Version: 1.1

GVC Name: quick-start-service-to-service
Location: /org/ORG_NAME/location/aws-us-west-2
Workload Name: /org/ORG_NAME/gvc/quick-start-service-to-service/workload/server

Response from URL:

No URL in querystring
```

## Step Two - Demonstrate a Failed Request

1. Browse to the `client` [Workload](/reference/workload) using the [Console](https://console.cpln.io/):
   - Click `Workloads` in the left menu and select `client`.

Once the `Workload Health` shows `Ready`, click on the `Open` link next to the `Global Endpoint` URL. A new browser tab will open and display the output similar to step 1, but showing the second [Workload](/reference/workload) name `client`.

The sample application can call another URL endpoint by using the `url` query string parameter. Since the `client` will be calling the `server`, the URL will follow the [Service Endpoint Syntax](/guides/service-to-service#service-endpoint-syntax).

From the new browser tab, test the call to the first service by browsing to:

```
https://GLOBAL_ENDPOINT_CLIENT_WORKLOAD/?url=http://server.quick-start-service-to-service.cpln.local
```

Since we haven't changed the [internal firewall](/reference/workload#internal) rules, the response from the sample application will display the following (indicating that the `client` cannot connect to the `server`):

```
Hello! Version: 1.1

GVC Name: quick-start-service-to-service
Location: /org/ORG_NAME/location/aws-us-west-2
Workload Name: /org/ORG_NAME/gvc/quick-start-service-to-service/workload/client

Response from URL:

Request failed with status code 502
```

Leave this browser tab open. It will be used in [step three](#step-three-configure-internal-firewall).

## Step Three - Configure Internal Firewall

Execute the following [CLI](/reference/cli) command to update the firewall rules of the `server` [Workload](/reference/workload) to grant inbound access from any [Workload](/reference/workload) in the same [GVC](/reference/gvc):

```
curl https://raw.githubusercontent.com/controlplane-com/examples/main/quickstarts/5/02_update_first_workload_firewall.yaml | cpln apply -f - --gvc quick-start-service-to-service
```

The YAML file can be viewed by clicking [here](https://raw.githubusercontent.com/controlplane-com/examples/main/quickstarts/5/02_update_first_workload_firewall.yaml).

Notice that the [internal firewall](/reference/workload#internal) configuration has been set to the allow type of `same-gvc`.

## Step Four - Test the Updated Firewall Rule

1. In the browser tab that was opened for [step two](#step-two-demonstrate-a-failed-request), we should still have the failed response displayed.
2. Refresh the page and the following response will be displayed (it might take a minute or two for the new deployment to complete):

```
Hello! Version: 1.1

GVC Name: quick-start-service-to-service
Location: /org/ORG_NAME/location/aws-us-west-2
Workload Name: /org/ORG_NAME/gvc/quick-start-service-to-service/workload/client

Response from URL:
---
Hello! Version: 1.1

GVC Name: quick-start-service-to-service
Location: /org/ORG_NAME/location/aws-us-west-2
Workload Name: /org/ORG_NAME/gvc/quick-start-service-to-service/workload/server

Response from URL:

No URL in querystring
```

<Tip>
  If you received the same response, this demonstrated that the `client` [Workload](/reference/workload) was able to call the `server`
  [Workload](/reference/workload) internally.
</Tip>

# Configure Other Internal Firewall Rules

In [step three](#step-three-configure-internal-firewall), the [internal firewall](/reference/workload#internal) rule for the `server` [Workload](/reference/workload) was set to allow access from any [Workload](/reference/workload) in the same [GVC](/reference/gvc).

The rule can also be set to:

- Allow access ONLY from specific [Workloads](/reference/workload). These [Workloads](/reference/workload) can be from the same or different [GVCs](/reference/gvc). The user configuring this setting must have the `view` permission, set within a [policy](/reference/policy#permissions), on the [Workload](/reference/workload) being specified.
- Allow access from **any** [Workloads](/reference/workload) within the same [Org](/reference/org), crossing [GVC](/reference/gvc) boundaries.

Please experiment with the other settings using the sample application to verify that the [internal firewall](/reference/workload#internal) rules are enforced. Remember that any changes to the firewall rules will be updated within a minute and a deployment of the [Workload](/reference/workload) will be queued. Please allow a few minutes between tests.

# Summary

Using a sample application that can call endpoints from within a [Workload](/reference/workload), we were able to demonstrate that a [Workload](/reference/workload) is locked down by default and will not accept any requests internally.

By setting the [internal firewall](/reference/workload#internal) rule, [Workloads](/reference/workload) can allow different types of internal traffic from other [Workloads](/reference/workload). Depending on the use case, multiple [Workloads](/reference/workload) can be deployed within your [Org](/reference/org) and call each other internally without having to access the public Internet.


### 4. Use a Custom Container Image
**Path**: `getting-started/use-custom-container-image.mdx`

---
title: 4. Use a Custom Container Image
---

## Overview

The Control Plane [CLI](/reference/cli) offers developers the ability to containerize their code and push the resulting [image](/reference/image) to their [Org's](/reference/org) private [image registry](/reference/image). The [image registry](/reference/image) is scoped to the [Org](/reference/org) and available for use by all [Workloads](/reference/workload) within the [Org](/reference/org). Along with the console, the [CLI](/reference/cli) can be used to deploy the [image](/reference/image) to the cloud by configuring a [GVC](/reference/gvc) and [Workload](/reference/workload).

This quick start will demonstrate how to:

- Containerize a Node.js application.
- Configure a [GVC](/reference/gvc) and [Workload](/reference/workload) using the [CLI](/reference/cli).
- Test the deployed application.

## Prerequisites

- Install the [CLI](/reference/cli#install-npm).
- Log in to the [CLI](/reference/cli#login).
- Install [Docker](https://www.docker.com/get-started).
- Install [Node.js](https://nodejs.org/en/download/) version 12+.
- Download sample application:

<CardGroup cols={2}>
  <Card title="macOS / Linux" icon="download" href="https://controlplane.com/downloads/cpln_app.tgz">
    Sample Application
  </Card>
  <Card title="Windows" icon="download" href="https://controlplane.com/downloads/cpln_app.zip">
    Sample Application
  </Card>
</CardGroup>

## Step One - Containerize the Sample Application

1. Decompress the sample application to a new directory. The application is a web app that will display the environment variables of the running process that also include Control Plane variables such as cloud provider and location.

<Tip>
Decompression helper commands:

| OS                         | Command                                  |
| :------------------------- | :--------------------------------------- |
| macOS                      | gunzip cpln_app.tgz && open cpln_app.tar |
| Linux                      | tar -xvf cpln_app.tgz                    |
| Windows 10/11 (PowerShell) | Expand-Archive cpln_app.zip              |

</Tip>

2. Execute the following command from the `cpln_app` directory to containerize the application:

<Note>
  Substitute ORG_NAME with the name of your [Org](/reference/org). If you have already set a default [Org](/reference/org) in your
  [profile](/guides/manage-profile), you can omit the `--org` flag.
</Note>

```bash
cpln image build --name quick-start-4:0.1 --push --org ORG_NAME
```

This command will containerize the application locally using Docker and push the [image](/reference/image) to your [Org's](/reference/org) private [image registry](/reference/image). The [image](/reference/image) name will be `quick-start-4` and the tag is `0.1`. You can build and push multiple versions with the same name and
different tags (e.g., 0.2, 0.3, etc.).

<Tip>
  Notice that the application doesn't contain a `Dockerfile`. The `cpln image build` command uses [Buildpacks](https://buildpacks.io) to
  scan the application and automatically build the [image](/reference/image). If your application has an existing `Dockerfile`, the command
  will use that file to containerize the application.
</Tip>

Review the [Push an Image](/guides/push-image) guide for additional details.

## Step Two - Configure a GVC

In this step, you will configure a new [GVC](/reference/gvc) for the application using the [CLI](/reference/cli). If you'd like to use the [GVC](/reference/gvc) created in the previous [quick start](/quickstart/sample-application), skip to [step 3](#step-three-configure-a-workload).

Execute the following command to create a new [GVC](/reference/gvc) mapped to two different cloud providers/locations:

```bash
cpln gvc create --name quick-start-4 --location aws-us-west-2 --location gcp-us-east1 --org ORG_NAME
```

The output from this command will show the new [GVC](/reference/gvc) and its associated [locations](/reference/location).

<Tip>To view the list of available locations, execute the command: `cpln location get --org ORG_NAME`.</Tip>

Review the [Create a GVC](/guides/create-gvc) guide for additional details.

## Step Three - Configure a Workload

In this step, you will configure a new [Workload](/reference/workload) for the application.

Execute the following command to create a new [Workload](/reference/workload).

For the `--name` flag, choose an appropriate name for the workload. It will be used when generating the endpoint URL.

For the `--image` flag, use the name of the [image](/reference/image) that was created in [step 1](#step-one-containerize-the-sample-application). Prefix the [image](/reference/image) name with `//image/`
to have the platform pull the [image](/reference/image) from your [Org's](/reference/org) private registry.

For the `--gvc` flag, use the [GVC](/reference/gvc) name created in [step 2](#step-two-configure-a-gvc) or from the previous [quick start](/quickstart/sample-application).

For the `--port` flag, use port 8080 which is the port the application exposes.

The command uses the `--public` flag which will automatically set the [firewall rules](/reference/workload#firewall) for this [Workload](/reference/workload) to allow inbound and outbound Internet traffic.

```bash
cpln workload create --name show-env-variables --image //image/quick-start-4:0.1 --port 8080 --public --gvc quick-start-4 --org ORG_NAME
```

The output from this command will show the new [Workload](/reference/workload) name and the endpoint URL. The endpoint is using the domain name that is set on the [GVC](/reference/gvc). Notice that the URL is HTTPS. A TLS certificate was generated and configured for the endpoint. The platform automatically performs TLS termination and port translation from 443 to 8080.

Review the [Create a Workload](/guides/create-workload) and [Workload Reference](/reference/workload) guide for additional details.

## Step Four - Test the Deployed Application

Allow a few minutes for the workload to deploy, then copy the endpoint URL and paste it into a browser. The output will display the environment variables for the running process. The variables that are prefixed with `CPLN_` are added by Control Plane and can be used by your application.

For example, the variable `CPLN_LOCATION` will be the location where the [Workload](/reference/workload) was served from. Since we configured the [GVC](/reference/gvc) with two locations, this variable can change depending on the location of the caller since the endpoint URL is DNS geo-routed to the nearest healthy location.

For more details on the built-in variables, visit the [Workload Environment Variables](/reference/workload#environment-variables) reference page.

## Summary

This quick start demonstrated how to deploy an application, from code to a deployed [Workload](/reference/workload), in just a couple of steps. The sample application targeted Node.js, but you can deploy any language that can be containerized (e.g., Java, .NET, Go, etc.).

In the previous [quick start](/quickstart/sample-application), you used the console to deploy an application, here you exercised the [CLI](/reference/cli) to perform similar actions. All Control Plane resources, such as [GVCs](/reference/gvc) and [Workloads](/reference/workload), can be created/modified either using the console or the [CLI](/reference/cli).


## guides/agent-sizing-guidance


### aws
**Path**: `guides/agent-sizing-guidance/aws.mdx`

**AWS**

- Region tested: `aws-us-west-2`
- qperf server running on: `c5.2xlarge` instance type
- Test runtime: 30 seconds

| Agent Instance Type | Average Bandwidth (MB/sec) | Average Latency (us) | Basline Bandwidth (Gbps) |
| :------------------ | :------------------------- | :------------------- | :------------------------- |
| No Agent            | 307.6                      | 585.6                | n/a                        |
| t2.micro            | 21.23                      | 1301                 | 0.064                      |
| t3.small            | 143.9                      | 1107                 | 0.128                      |
| c5.large            | 341.1                      | 629.6                | 0.75                       |
| c4.xlarge           | 70.25                      | 680.8                | 5.0                        |

<Warning>When capacity planning the Basline Bandwidth should be used instead of the Burst Bandwidth.</Warning>

Available Basline Bandwidth for each instance can be discovered using the AWS CLI.
  This query shows the BaselineBandwidthInGbps for t3 instances.
  Adjust as needed for the instance types required.

```bash
  aws ec2 describe-instance-types \
  --filters "Name=instance-type,Values=t3.*" \
  --query "InstanceTypes[].[InstanceType, NetworkInfo.NetworkCards[0].BaselineBandwidthInGbps] | sort_by(@,&[1])" \
  --output table

  -------------------------
  | DescribeInstanceTypes |
  +-------------+---------+
  |  t3.nano    |  0.032  |
  |  t3.micro   |  0.064  |
  |  t3.small   |  0.128  |
  |  t3.medium  |  0.256  |
  |  t3.large   |  0.512  |
  |  t3.xlarge  |  1.024  |
  |  t3.2xlarge |  2.048  |
  +-------------+---------+
```


### gcp
**Path**: `guides/agent-sizing-guidance/gcp.mdx`

**GCP**

- Region tested: `gcp-us-east1`
- qperf server running on: `e2-standard-8` machine type
- Test runtime: 30 seconds

| Agent Machine Type | Average Bandwidth (MB/sec) | Average Latency (us) |
| :----------------- | :------------------------- | :------------------- |
| No Agent           | 313.4                      | 251.2                |
| n2-standard-2      | 250.3                      | 407.7                |
| n2-standard-8      | 223.3                      | 350.7                |
| n2-standard-4      | 217.5                      | 354.1                |
| n1-standard-1      | 199.9                      | 409.3                |


### Overview
**Path**: `guides/agent-sizing-guidance/index.mdx`

---
title: Overview
---

## Agent Sizing Guidance

When utilizing an agent, the machine type running the agent affects the bandwidth and latency exhibited by the agent.

The tables below are provided to help guide your agent machine type selection.

Tests were performed using [qperf](https://github.com/linux-rdma/qperf/blob/master/src/help.txt). The qperf client was configured as a container workload running on the Control Plane platform and deployed in the same region as the qperf server running on a virtual machine.

Based on the results for reach provider, select an agent type suitable for your performance requirements.


## guides/audit


### writing-audit-records-from-a-workload
**Path**: `guides/audit/writing-audit-records-from-a-workload.mdx`

1. Make sure the workload is assigned an identity that is granted writeAudit permissions to your custom audit context.
2. Write events using the internal audit endpoint

   ```bash
   #minimal example
   curl -H "Content-Type: application/json" -X POST http://127.0.0.1:43000/audit/org/${CPLN_ORG}/auditctx/custom-audit-context?async=true -d '{"resource": {"id": "anyid123", "type": "anytype"}}'
   ```


## guides/auth


### "Configure SAML Authentication"
**Path**: `guides/auth/configure-saml.mdx`

---
title: "Configure SAML Authentication"
---

## SAML (Security Assertion Markup Language) Configuration

To enable SAML authentication for your organization in Control Plane, you will need the assistance of our support team.

Please contact us on Slack or at [support@controlplane.com](mailto:support@controlplane.com) to schedule a configuration session.

The following values must be obtained from your authentication provider:

- Entity ID
- SSO URL
- Certificate

SAML configuration values:

- Service Provider Entity ID: `cpln.io`
- Assertion Consumer Service (ACS) / Callback URL: `https://console.cpln.io/__/auth/handler`


### "CPLN API"
**Path**: `guides/auth/cpln-api.mdx`

---
title: "CPLN API"
---

## Overview

To authenticate requests to the Control Plane API, you need to include an authorization header with a Bearer token. This token can be either a user token or a service account key.

### Using a User Token

1. Obtain a user token by using the `cpln profile token --profile {profileName}` command.
2. Replace `{profileName}` with the name of the profile you want to use.
3. Copy the token generated by the command.

### Using a Service Account Key

1. Create a service account in the Control Plane platform.
2. Generate a key for the service account and copy the key.

### Adding the Authorization Header

Include the token or key in the authorization header of your API requests with the `Bearer` prefix. Here is an example using cURL:

```bash
curl -H "Authorization: Bearer {tokenOrKey}" https://api.cpln.io/org
```

Replace `{tokenOrKey}` with the token or key you obtained from the previous steps.

This method ensures that your API requests are authenticated and secure, allowing you to interact with the Control Plane API effectively.


### "CPLN CLI"
**Path**: `guides/auth/cpln-cli.mdx`

---
title: "CPLN CLI"
---

## Overview

To authenticate to the CPLN CLI, you have two primary options: using a profile with a login command or using a service account key. Here's how you can do both:

### Option 1: Using a Profile with Login

<Steps>
<Step title="Create a Profile">
You can create a profile for your CPLN CLI access. This is useful if you want to manage multiple profiles for different environments or use cases.
</Step>

<Step title="Login with Profile">
Use the following command to log in with a specific profile:

   ```bash
   cpln profile {profileName} --login
   ```

   Replace `{profileName}` with the name of the profile you want to use. This command will prompt you to authenticate, typically through a web-based login flow.
</Step>
</Steps>

### Option 2: Using a Service Account Key

<Steps>
<Step title="Create a Profile with a Service Account Key">
If you have a service account key, you can create a profile using that key. This is useful for automated scripts or services that need to authenticate without user interaction.
</Step>

<Step title="Use the Service Account Key">
Use the following command to create a profile with a service account key:

   ```bash
   cpln profile create {name} --token {serviceAccountKey}
   ```

   Replace `{name}` with the desired name for your profile and `{serviceAccountKey}` with your actual service account key. This will set up a profile that uses the service account key for authentication.
</Step>
</Steps>


### "Pulumi"
**Path**: `guides/auth/pulumi.mdx`

---
title: "Pulumi"
---

TODO


### "Terraform Provider"
**Path**: `guides/auth/terraform-provider.mdx`

---
title: "Terraform Provider"
---

TODO


## guides/cli


### Browserless CLI Login
**Path**: `guides/cli/browser-less-cli-login.mdx`

---
title: Browserless CLI Login
---

## Overview

You can use the CLI without an interactive login by using a [service account](/reference/serviceaccount).

## Prerequisites

- The user executing the steps below must be a member of the [superusers group](/reference/group#built-in-groups) or have a [policy](/reference/policy), targeting [service accounts](/reference/serviceaccount), with the following [permissions](/reference/policy#permissions):
  - create
  - edit
  - addKey
- [CLI](/reference/cli) installed

## Required Steps

To set up a [service account](/reference/serviceaccount) used by the CLI to perform a browserless login:

1. Using the console:

   - [Create a Service Account](/guides/create-service-account) whose key will be used in step #2.

   - Create one or more [policies](/guides/policy) granting the [service account](/reference/serviceaccount) permissions to resources (GVCs, workloads, etc.) as required.

<Tip>
If you wish, the CLI can be used instead of using the console.

See [service account create](/reference/cli#serviceaccount-create), [service account add-key](/reference/cli#serviceaccount-add-key), [policy create](/reference/cli#policy-create), [policy add-binding](/reference/cli#policy-add-binding)

</Tip>

2. To configure the CLI to use the [service account](/reference/serviceaccount), run the following command (choose your own PROFILE_NAME):

```
cpln profile create PROFILE_NAME --token SERVICE_ACCOUNT_KEY_FROM_STEP_1
```

3. To set the profile as the default, run the following command:

```
cpln profile set-default PROFILE_NAME
```

Once the profile is set as the default, subsequent CLI commands will run as the [service account](/reference/serviceaccount) with its permissions.

## Troubleshooting

If logging in with a [service account](/reference/serviceaccount) using the steps above is not executing the CLI commands as expected, add the service account to the `superusers` [group](/reference/group#built-in-groups).

This [group](/reference/group) will give full access to the [service account](/reference/serviceaccount). If the CLI commands are now returning as expected, additional permissions will need to be added to the [service account](/reference/serviceaccount) using [policies](/guides/policy).

If it is still not working, ensure that the default profile is set to PROFILE_NAME.


### Deploy From Docker-Compose
**Path**: `guides/cli/compose-deploy.mdx`

---
title: Deploy From Docker-Compose
---

## Overview

Using the [CLI](/reference/cli), you can deploy docker-compose resources directly to Control Plane.

## Prerequisites

- [Permissions](/reference/policy#permissions) to push an [image](/reference/image)
- [Permissions](/reference/policy#permissions) to create a [workload](/reference/workload), [volumeset](/reference/volumeset), [secret](/reference/secret), [identity](/reference/identity)
- Install the [CLI](/reference/cli)
- A docker-compose project

## Deploy project

Refer to the [stack deploy](/reference/cli#stack-deploy) command for details and examples on how to deploy from a docker-compose project.

## Delete project

Refer to the [stack rm](/reference/cli#stack-rm) command for details and examples on how to delete resources generated by a docker-compose project.

## Generate Control Plane Spec

You can generate a Control Plane spec without deploying the resources. Refer to the [stack manifest](/reference/cli#stack-manifest) command for details and examples on how generate a Control Plane spec from a docker-compose project.

## Requirements

- Service-to-service connections must use the [CPLN local syntax](/guides/service-to-service#service-endpoint-syntax) for host name.
  - Workload name would be the service name in this case.
  - E.g., if service1 connects to service to using `http://service2:8080`, this must be replaced with `http://service2.{GVC}.cpln.local:8080`
- Docker Compose file must specify all ports to be exposed, even just internally exposed ports.

## Translation Notes

- Compose services become single container workloads
- Compose networks are used to configure the internal firewall of the workload
- Compose volumes are converted to volumesets, with 10gb storage
- Compose secrets, conifgs, and file bind mounts are converted to [secrets](/reference/secret). Necessary [policies](/reference/policy) and [identities](/reference/identity) will be created.
- All external outbound requests are enabled by default, unless `network_mode` is set to `none`
- `deploy.resource.limit.cpus` and `deploy.resource.limit.memory` will determine cpu and memory allocation respectively.
- Default cpu and memory (if above not specified) set to 42m and 128Mi respectively
- Environment variables determined from `environment` field and/or `env_file`
- `ports` and `expose` field maps to container ports
  - Note: We only use the container port, not host port. Other services MUST connect to the container port.
- Capacity AI will be enabled if `deploy.resources.reservations` < `deploy.resources.limits`
- `deploy.replicas` will determine replica count (min AND max)
- `healthcheck` values will map to readiness probe
- Services with a GPU device will have GPU enabled.
  - Note: cpu and memory values may have to be increased if GPU is enabled.


### cpln apply
**Path**: `guides/cli/cpln-apply.mdx`

---
title: cpln apply
---

## Overview

The [cpln apply](/reference/cli#apply) command is used to automate the management of Control Plane
resources using JSON or YAML metadata as input.

This automation can be used for:

- [GitOps](#use-in-gitops)
- Scripting
- Testing

<Tip>Using `cpln apply` is a good way to leverage the CLI in an idempotent manner.</Tip>

The usage, limitations, and example templates are described below.

## Using the CLI

Using the CLI, the `apply` command is called by executing:

```
cpln apply --file FILE_NAME [OPTIONS]
```

The `FILE_NAME` is the path for the file and it can be either a JSON or YAML file containing the resource metadata.

To apply an [Identity](/reference/identity), a [Volume Set](/reference/volumeset) or a [Workload](/reference/workload) resource you need to specify a GVC using one of the following methods.

- Specify a `gvc` within your [cpln profile](/guides/manage-profile). This will add the `gvc` to the session context of the profile and will be refered to as the default `gvc` when executing any future command including the `cpln apply` command.

  ```
  cpln profile update PROFILE_NAME --gvc GVC_NAME
  ```

- Specify a `--gvc` flag to the `apply` command. This will pass the `gvc` as an option and will override the default `gvc` that is defined in the profile.

  ```
  cpln apply --file FILE_NAME --gvc GVC_NAME
  ```

- Specify a `gvc` property in the resource definition within the file you intend to apply.

  ```yaml
  kind: identity
  name: example-identity
  description: example-description
  tags: {}
  gvc: example-gvc
  ```

<Note>You can specify either a GVC property or use the `--gvc` flag, but not both.</Note>

[Click here](/reference/cli#apply) to view the CLI reference page for the `apply` command.

### Apply a K8s File

The CLI has the ability to convert K8s resources into Control Plane resources. By passing the `--k8s true` option to the `apply` command, the K8s resources will be converted and applied.

```
cpln apply --file FILE_NAME --k8s true
```

The `apply` command utilizes the logic of the CLI [convert](/reference/cli#convert) command and then applies the resulting output.

### Apply Standard Input

In case you would like to pass Control Plane resources through `stdin` (Standard Input), use the following command.

```
CONTROL_PLANE_RESOURCES | cpln apply --file -
```

<Tip>This is useful if you want to pass the stdout of a command to the `cpln apply` command.</Tip>

## Using the Console

The console has the ability to upload a JSON or YAML file or accept a resource definition in JSON or YAML as input. The functionality is the same as using the CLI. To start applying, click the `cpln apply` button in the upper right corner of the console. A modal will be displayed containing the upload instructions.

The cpln apply modal provides the ability to specify in which `org` and `gvc` a resource will be executed. The default is your currently selected `org` and `gvc`.

A file or an input containing an [Identity](/reference/identity), a [Volume Set](/reference/volumeset) or a [Workload](/reference/workload) resource will be executed in the scope of the specified `gvc` in the cpln apply modal. In case a `gvc` is defined within a resource, the resource will be executed in the scope of that `gvc`.

## Multiple Resources

The apply command can accept a YAML file containing multiple resources. Each resource must be separated using ---.

If a resource has a reference to another resource (e.g., a workload refers to a GVC), the referenced resource must be defined in the same file ONLY in case it does not already exist at Control Plane.

## Renaming of Resources

If the name of an exisiting resource is changed, the `cpln apply` command will create a new resource.

**NOTE:** Any orphaned resources will need to be manually deleted.

## Limitations

- To create an [agent](/reference/agent), use the console or the CLI agent command to obtain the bootstrap config data. Using the `cpln apply` command from the CLI or console does not output the config data.
- Before creating a [cloud account](/reference/cloudaccount), additional configuration is required at the target cloud provider. Refer to the [Create Cloud Account](/guides/create-cloud-account) guide for instructions.
- Before creating a [domain](/reference/domain), the required DNS entries must exist. Refer to the [Configure a Domain](/guides/configure-domain#required-dns-records) guide for instructions.

## Generate Sample Input

Samples of existing resources can be generated using the console or the CLI. These samples can assist when defining resources for your application.

**Using the console:**

- After selecting a resource, there will be an Actions pull down button in the upper right corner. Inside it you will find the View and Export options.
- The View will allow you to see the resource definition as JSON, YAML and Terraform.
- For the Export option select JSON Slim or YAML Slim to download the file.

**Using the CLI:**

- Using the get command for each resource, the -o flag can output the resource as JSON or YAML.
- For example: The command `cpln gvc get GVC_NAME -o yaml-slim --org ORG_NAME` will output the GVC_NAME as YAML.

<Tip>
  The `json-slim` and `yaml-slim` format options will output only the necessary values needed for a subsequent call to the `cpln apply`
  command.
</Tip>

## Use in GitOps

The `apply` command can be used to manage Control Plane resources as part of a CI/CD pipeline.

Refer to the [GitOps CLI](/guides/gitops#cli) documentation for additional information.

## Example Templates

The examples below can be used as templates when creating your own metadata files.

These files can be download [here](https://github.com/controlplane-com/examples/raw/main/examples/cpln-apply/cpln-apply-examples.zip).

<Accordion title="GVC">

[GVC Reference Page](/reference/gvc)

<CodeGroup>

```json JSON
{
  "kind": "gvc",
  "name": "example-gvc",
  "description": "example-gvc description",
  "tags": {
    "tag1": "value1"
  },
  "spec": {
    "pullSecretLinks": ["/org/ORG_NAME/secret/SECRET_NAME"],
    "staticPlacement": {
      "locationLinks": [
        "/org/ORG_NAME/location/aws-eu-central-1",
        "/org/ORG_NAME/location/aws-us-west-2",
        "/org/ORG_NAME/location/azure-eastus2",
        "/org/ORG_NAME/location/gcp-us-east1"
      ]
    }
  }
}
```

```yaml YAML
kind: gvc
name: example-gvc
description: example-gvc description
tags:
  tag1: value1
spec:
  pullSecretLinks:
    - /org/ORG_NAME/secret/SECRET_NAME
  staticPlacement:
    locationLinks:
      - /org/ORG_NAME/location/aws-eu-central-1
      - /org/ORG_NAME/location/aws-us-west-2
      - /org/ORG_NAME/location/azure-eastus2
      - /org/ORG_NAME/location/gcp-us-east1
```

</CodeGroup>

</Accordion>

<Accordion title="Agent">

[Agent Reference Page](/reference/agent)

<CodeGroup>

```json JSON
{
  "kind": "agent",
  "name": "example-agent",
  "description": "example-agent description"
}
```

</CodeGroup>

</Accordion>

<Accordion title="Cloud Accounts">

[Cloud Accounts Reference Page](/reference/cloudaccount)

<Accordion title="Cloud Account - AWS">

<CodeGroup>

```json JSON
{
  "kind": "cloudaccount",
  "name": "example-aws-cloud-account",
  "description": "example-aws-cloud-account description",
  "tags": {},
  "provider": "aws",
  "data": {
    "roleArn": "ROLE_ARN"
  }
}
```

```yaml YAML
kind: cloudaccount
name: example-aws-cloud-account
description: example-aws-cloud-account description
tags: {}
provider: aws
data:
  roleArn: 'ROLE_ARN'
```

</CodeGroup>

</Accordion>

<Accordion title="Cloud Account - Azure">

<CodeGroup>

```json JSON
{
  "kind": "cloudaccount",
  "name": "example-azure-cloud-account",
  "description": "example-azure-cloud-account description",
  "tags": {},
  "provider": "azure",
  "data": {
    "secretLink": "/org/ORG_NAME/secret/AZURE_SECRET"
  }
}
```

```yaml YAML
kind: cloudaccount
name: example-azure-cloud-account
description: example-azure-cloud-account description
tags: {}
provider: azure
data:
  secretLink: /org/ORG_NAME/secret/AZURE_SECRET
```

</CodeGroup>

</Accordion>

<Accordion title="Cloud Account - GCP">

<CodeGroup>

```json JSON
{
  "kind": "cloudaccount",
  "name": "example-gcp-cloud-account",
  "description": "example-gcp-cloud-account description",
  "tags": {},
  "provider": "gcp",
  "data": {
    "projectId": "PROJECT_ID"
  }
}
```

```yaml YAML
kind: cloudaccount
name: example-gcp-cloud-account
description: example-gcp-cloud-account description
tags: {}
provider: gcp
data:
  projectId: PROJECT_ID
```

</CodeGroup>

</Accordion>

<Accordion title="Cloud Account - NGS">

<CodeGroup>

```json JSON
{
  "kind": "cloudaccount",
  "name": "example-ngs-cloud-account",
  "description": "example-ngs-cloud-account description",
  "provider": "ngs",
  "data": {
    "secretLink": "/org/ORG_NAME/secret/NATS_SECRET"
  }
}
```

```yaml YAML
kind: cloudaccount
name: example-ngs-cloud-account
description: example-ngs-cloud-account description
tags: {}
provider: ngs
data:
  secretLink: /org/ORG_NAME/secret/NATS_SECRET
```

</CodeGroup>

</Accordion>

</Accordion>

<Accordion title="Domains">

[Domain Reference Page](/reference/domain)

<CodeGroup>

```json JSON
{
  "kind": "domain",
  "name": "sub.example.com",
  "description": "domain description",
  "tags": {}
}
```

```yaml YAML
kind: domain
name: sub.example.com
description: domain description
tags: {}
```

</CodeGroup>

</Accordion>

<Accordion title="Secrets">

[Secrets Reference Page](/reference/secret)

<Accordion title="Secret - AWS">

<CodeGroup>

```json JSON
{
  "kind": "secret",
  "name": "example-aws-secret",
  "description": "example-aws-secret description",
  "tags": {},
  "type": "aws",
  "data": {
    "accessKey": "AKIAIOSFODNN7EXAMPLE",
    "roleArn": "arn:awskey",
    "secretKey": "AKIAwJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY",
    "externalId": "EXTERNAL_ID"
  }
}
```

```yaml YAML
kind: secret
name: example-aws-secret
description: example-aws-secret description
tags: {}
type: aws
data:
  accessKey: AKIAIOSFODNN7EXAMPLE
  roleArn: 'arn:awskey'
  secretKey: AKIAwJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY
  externalId: EXTERNAL_ID
```

</CodeGroup>

</Accordion>

<Accordion title="Secret - Azure Connector">

<CodeGroup>

```json JSON
{
  "kind": "secret",
  "name": "example-azure-connector-secret",
  "description": "example-azure-connector-secret description",
  "tags": {},
  "type": "azure-connector",
  "data": {
    "code": "CODE",
    "url": "URL"
  }
}
```

```yaml YAML
kind: secret
name: example-azure-connector-secret
description: example-azure-connector-secret description
tags: {}
type: azure-connector
data:
  code: CODE
  url: 'URL'
```

</CodeGroup>

</Accordion>

<Accordion title="Secret - Azure-SDK">

<CodeGroup>

```json JSON
{
  "kind": "secret",
  "name": "example-azure-sdk-secret",
  "description": "example-azure-sdk-secret",
  "tags": {},
  "type": "azure-sdk",
  "data": "{\"subscriptionId\":\"2cd8674e-4f89-4a1f-b420-7a1361b46ef7\",\"tenantId\":\"292f5674-c8b0-488b-9ff8-6d30d77f38d9\",\"clientId\":\"649846ce-d862-49d5-a5eb-7d5aad90f54e\",\"clientSecret\":\"cpln\"}"
}
```

```yaml YAML
kind: secret
name: example-azure-sdk-secret
description: example-azure-sdk-secret
tags: {}
type: azure-sdk
data: >-
  {"subscriptionId":"2cd8674e-4f89-4a1f-b420-7a1361b46ef7","tenantId":"292f5674-c8b0-488b-9ff8-6d30d77f38d9","clientId":"649846ce-d862-49d5-a5eb-7d5aad90f54e","clientSecret":"cpln"}
```

</CodeGroup>

</Accordion>

<Accordion title="Secret - Dictionary">

<CodeGroup>

```json JSON
{
  "kind": "secret",
  "name": "example-dictionary-secret",
  "description": "example-dictionary-secret description",
  "tags": {},
  "type": "dictionary",
  "data": {
    "key01": "value01",
    "key02": "value02"
  }
}
```

```yaml YAML
kind: secret
name: example-dictionary-secret
description: example-dictionary-secret description
tags: {}
type: dictionary
data:
  key01: value01
  key02: value02
```

</CodeGroup>

</Accordion>

<Accordion title="Secret - Docker">

<CodeGroup>

```json JSON
{
  "kind": "secret",
  "name": "example-docker-secret",
  "description": "example-docker-secret description",
  "tags": {},
  "type": "docker",
  "data": "{\"auths\":{\"https://index.docker.io/v1/\":{\"username\":\"USERNAME\",\"password\":\"PASSWORD\"}}}"
}
```

```yaml YAML
kind: secret
name: example-docker-secret
description: example-docker-secret description
tags: {}
type: docker
data: >-
  {"auths":{"https://index.docker.io/v1/":{"username":"USERNAME","password":"PASSWORD"}}}
```

</CodeGroup>

</Accordion>

<Accordion title="Secret - ECR">

<CodeGroup>

```json JSON
{
  "kind": "secret",
  "name": "example-ecr-secret",
  "description": "example-ecr-secret description",
  "tags": {},
  "type": "ecr",
  "data": {
    "accessKey": "AKIA_ACCESS_KEY",
    "repos": ["015716931711.dkr.ecr.us-west-2.amazonaws.com/repo"],
    "secretKey": "SECRET_KEY",
    "externalId": "EXTERNAL_ID"
  }
}
```

```yaml YAML
kind: secret
name: example-ecr-secret
description: example-ecr-secret description
tags: {}
data:
  accessKey: AKIA_ACCESS_KEY
  repos:
    - 015716931711.dkr.ecr.us-west-2.amazonaws.com/repo
  secretKey: SECRET_KEY
  externalId: EXTERNAL_ID
```

</CodeGroup>

</Accordion>

<Accordion title="Secret - GCP">

<CodeGroup>

```json JSON
{
  "kind": "secret",
  "name": "example-gcp-secret",
  "description": "example-gcp-secret description",
  "tags": {},
  "type": "gcp",
  "data": "{\"type\":\"gcp\",\"project_id\":\"cpln12345\",\"private_key_id\":\"pvt_key\",\"private_key\":\"key\",\"client_email\":\"support@cpln.io\",\"client_id\":\"12744\",\"auth_uri\":\"cloud.google.com\",\"token_uri\":\"token.cloud.google.com\",\"auth_provider_x509_cert_url\":\"cert.google.com\",\"client_x509_cert_url\":\"cert.google.com\"}"
}
```

```yaml YAML
kind: secret
name: example-gcp-secret
description: example-gcp-secret description
tags: {}
type: gcp
data: >-
  {"type":"gcp","project_id":"cpln12345","private_key_id":"pvt_key","private_key":"key","client_email":"support@cpln.io","client_id":"12744","auth_uri":"cloud.google.com","token_uri":"token.cloud.google.com","auth_provider_x509_cert_url":"cert.google.com","client_x509_cert_url":"cert.google.com"}
```

</CodeGroup>

</Accordion>

<Accordion title="Secret - KeyPair">

**NOTE:** The example below uses a self-signed certificate. Do not use for production.

<CodeGroup>

```json JSON
{
  "kind": "secret",
  "name": "example-keypair-secret",
  "description": "example-keypair-secret description",
  "tags": {},
  "type": "keypair",
  "data": {
    "passphrase": "cpln",
    "publicKey": "-----BEGIN PUBLIC KEY-----\nMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAwrVyExI0uvRmwCAKFHiv\nbaAcPMcKJDa6f6TtaVo2p8jyfEhVwDTmR3FUrDDZAjh0Q8G/Up8Ob3+IJafNymCO\nBhUKou+8ie7guqsbU9JrT0Zos1k/pd0aVfnAR0EpW3es/7fdkWUszU0uweeEj22m\nXMlLplnqqoYOGAhuNMqGsZwBr36Bxq9EeB2O79QsAFDNkPVg7xIaYKn32j69o0Zr\nryYI8xqOYYy5Dw6CX+++YYLYiR/PkLYJTVAsxXeqyltCfb3Iv7vN5HrfoYBhndr3\nNxBPkcIJZeh3Z+QzfJ5U+bB5fP/aOsEk5bPbtLzylj2KnOOM/ZxXJtOcu0xtJLd3\nXwIDAQAB\n-----END PUBLIC KEY-----\n",
    "secretKey": "-----BEGIN RSA PRIVATE KEY-----\nProc-Type: 4,ENCRYPTED\nDEK-Info: DES-EDE3-CBC,9A26BB15304B18E7\n\nZdBgMExsvIJEsIFDMQ02xh4nDnhXEGUNu7LiWIZjn9WS6QB2jApyOFOBWmp0lK6L\ndIJ+Mb8wMeHtkiKS6ZbYeea8M29kwEejZRnKl1Wq0EFycdwbONtbcbjzF+tQGEBT\ngQQgkY7wjDWl8HwjFEA+NUuitzi6uI2xWlQpFdUrmqJAZCbxNFa0aM8nW6jnitvP\n616ps3HjLnWCjoyqS4hWxiWmt+VE3KruPnUVVV7bWlzc6jnoZcSaeqeaoQrNKguH\nte2iBIMdY/uldb7Ik2Kxr2+kBRmV4YNkp1EelNi/m39VcoUHJLk1jLldzuINhbi2\nIRqYZe4EEMSYdb3TkSosXa64Sz7jMBz5AxlA0n78FKlB9G5FAxaXcVYNQIlvzCbw\nuXPbQd/UYKUuEI1Yn8OmGBN5xcOdgWz8hfyxA2Hq1tmo1XN6snavGe7TKbZd70N+\n1yFbclB2T1z8fPcLwUZUxOl4g2DoMMHIzCSPaIe/otT8389k4H6hEulLis4lW0p3\nqopL5kdpxmSGgXsX6q6CUFb/0cw9HskNT3zbzKLx2MzjFCo93IB07UxPwkCD2kb1\nsLKMcpTC8a0vLaTVNYgDX7wW/YjBrCokaqk0z1whuN6iSReOtvmu5ybrq1Ksg8UQ\nyvCSScM/+muKi+gbEOskQs4Ph3ZLHqAX3/XYoyBcFnPNxVHTIa5Dcju6h5gl1/uY\n6tkRsHDr0Lzy8pd6jjf/ApPf9ypCuxKUO1q8PzPg2E4bmEFxc8zOB2NLvfPgFrUR\n0Sbkapv/6x6nNRw75cu69c5we/atip6wst8J1MSU0fTqb6bZ3TF2pDyNEOkdkvoZ\nYZ0r3hUytdT0pImoDLKoyy17mtHLLApzHyIgmR3cqtSt07ncmC5lyEBcZBrQXMa8\naZeOr8iUWQE/q+4BvoxeKsOD6ttKuFnrgl0rmMnYQsSyLJOPizrU4L1d1HMIKswm\niW+Rg7xlWmQg95m8XEWTjAb3tuNz/tGXC7Qa88HvC7YfyG69yM61oPsT83YnxcBT\nC/X67lSFTYguFa3HgDZpjGq7Hc/Q7nhaoqNMEs01O6jbcmrue8IIa2FH1tTwPN0W\nD7JefjCQjEghue2mjc0fovOGe9A9jvWf+gJHF3vRtFa67uQiQxge9zUzpHyVNpOj\nVe0y0HvibNTd6TSCArctJpIcwpjO3MTT5LBJ1p/8v4b4+knEKD2c69jumNbKGbWr\nWjq39M/MGNUO5SbZMO3gFCt6fgtXkOktH9pJ9iOQpYKgl7QTe2qQygfWkIm0EZRN\n6EaQdNNKgENWicpKyKQ4BxoY1LYAHFHJ95VisLf3KmmOF5MwajADZQT/yth3gvht\nxx21b9iudcgq/CRccSvfIPIWZKi6oaqNIXK+E3DQd40TUopLsBWzacTZn9maSZtW\nRyAY1TkRn1qDR2soyhBcihrX5PZ83jnOlM3XTdfF1784g8zB9ooDnK7mUKueH1W3\nhWFADMUF7uaBbo5EZ9sE+dFPzWPJLhu2j67a1iHmByqEvFY64lzq7VwwU/GE8JdA\n85oEkhg1ZEPJp3OYTQfPI/CC/2fc93Exf6wmaXuss8AHehuGcKQniOZmFOKOBprv\n-----END RSA PRIVATE KEY-----"
  }
}
```

```yaml YAML
kind: secret
name: example-keypair-secret
description: example-keypair-secret secret
tags: {}
type: keypair
data:
  passphrase: cpln
  publicKey: |
    -----BEGIN PUBLIC KEY-----
    MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAwrVyExI0uvRmwCAKFHiv
    baAcPMcKJDa6f6TtaVo2p8jyfEhVwDTmR3FUrDDZAjh0Q8G/Up8Ob3+IJafNymCO
    BhUKou+8ie7guqsbU9JrT0Zos1k/pd0aVfnAR0EpW3es/7fdkWUszU0uweeEj22m
    XMlLplnqqoYOGAhuNMqGsZwBr36Bxq9EeB2O79QsAFDNkPVg7xIaYKn32j69o0Zr
    ryYI8xqOYYy5Dw6CX+++YYLYiR/PkLYJTVAsxXeqyltCfb3Iv7vN5HrfoYBhndr3
    NxBPkcIJZeh3Z+QzfJ5U+bB5fP/aOsEk5bPbtLzylj2KnOOM/ZxXJtOcu0xtJLd3
    XwIDAQAB
    -----END PUBLIC KEY-----
  secretKey: |-
    -----BEGIN RSA PRIVATE KEY-----
    Proc-Type: 4,ENCRYPTED
    DEK-Info: DES-EDE3-CBC,9A26BB15304B18E7

    ZdBgMExsvIJEsIFDMQ02xh4nDnhXEGUNu7LiWIZjn9WS6QB2jApyOFOBWmp0lK6L
    dIJ+Mb8wMeHtkiKS6ZbYeea8M29kwEejZRnKl1Wq0EFycdwbONtbcbjzF+tQGEBT
    gQQgkY7wjDWl8HwjFEA+NUuitzi6uI2xWlQpFdUrmqJAZCbxNFa0aM8nW6jnitvP
    616ps3HjLnWCjoyqS4hWxiWmt+VE3KruPnUVVV7bWlzc6jnoZcSaeqeaoQrNKguH
    te2iBIMdY/uldb7Ik2Kxr2+kBRmV4YNkp1EelNi/m39VcoUHJLk1jLldzuINhbi2
    IRqYZe4EEMSYdb3TkSosXa64Sz7jMBz5AxlA0n78FKlB9G5FAxaXcVYNQIlvzCbw
    uXPbQd/UYKUuEI1Yn8OmGBN5xcOdgWz8hfyxA2Hq1tmo1XN6snavGe7TKbZd70N+
    1yFbclB2T1z8fPcLwUZUxOl4g2DoMMHIzCSPaIe/otT8389k4H6hEulLis4lW0p3
    qopL5kdpxmSGgXsX6q6CUFb/0cw9HskNT3zbzKLx2MzjFCo93IB07UxPwkCD2kb1
    sLKMcpTC8a0vLaTVNYgDX7wW/YjBrCokaqk0z1whuN6iSReOtvmu5ybrq1Ksg8UQ
    yvCSScM/+muKi+gbEOskQs4Ph3ZLHqAX3/XYoyBcFnPNxVHTIa5Dcju6h5gl1/uY
    6tkRsHDr0Lzy8pd6jjf/ApPf9ypCuxKUO1q8PzPg2E4bmEFxc8zOB2NLvfPgFrUR
    0Sbkapv/6x6nNRw75cu69c5we/atip6wst8J1MSU0fTqb6bZ3TF2pDyNEOkdkvoZ
    YZ0r3hUytdT0pImoDLKoyy17mtHLLApzHyIgmR3cqtSt07ncmC5lyEBcZBrQXMa8
    aZeOr8iUWQE/q+4BvoxeKsOD6ttKuFnrgl0rmMnYQsSyLJOPizrU4L1d1HMIKswm
    iW+Rg7xlWmQg95m8XEWTjAb3tuNz/tGXC7Qa88HvC7YfyG69yM61oPsT83YnxcBT
    C/X67lSFTYguFa3HgDZpjGq7Hc/Q7nhaoqNMEs01O6jbcmrue8IIa2FH1tTwPN0W
    D7JefjCQjEghue2mjc0fovOGe9A9jvWf+gJHF3vRtFa67uQiQxge9zUzpHyVNpOj
    Ve0y0HvibNTd6TSCArctJpIcwpjO3MTT5LBJ1p/8v4b4+knEKD2c69jumNbKGbWr
    Wjq39M/MGNUO5SbZMO3gFCt6fgtXkOktH9pJ9iOQpYKgl7QTe2qQygfWkIm0EZRN
    6EaQdNNKgENWicpKyKQ4BxoY1LYAHFHJ95VisLf3KmmOF5MwajADZQT/yth3gvht
    xx21b9iudcgq/CRccSvfIPIWZKi6oaqNIXK+E3DQd40TUopLsBWzacTZn9maSZtW
    RyAY1TkRn1qDR2soyhBcihrX5PZ83jnOlM3XTdfF1784g8zB9ooDnK7mUKueH1W3
    hWFADMUF7uaBbo5EZ9sE+dFPzWPJLhu2j67a1iHmByqEvFY64lzq7VwwU/GE8JdA
    85oEkhg1ZEPJp3OYTQfPI/CC/2fc93Exf6wmaXuss8AHehuGcKQniOZmFOKOBprv
    -----END RSA PRIVATE KEY-----
```

</CodeGroup>

</Accordion>

<Accordion title="Secret - Opaque">

<CodeGroup>

```json JSON
{
  "kind": "secret",
  "name": "example-opaque-secret",
  "description": "example-opaque-secret",
  "tags": {},
  "type": "opaque",
  "data": {
    "encoding": "plain",
    "payload": "sample payload"
  }
}
```

```yaml YAML
kind: secret
name: example-opaque-secret
description: example-opaque-secret description
tags: {}
type: opaque
data:
  encoding: plain
  payload: sample payload
```

</CodeGroup>

</Accordion>

<Accordion title="Secret - TLS">

<CodeGroup>

```json JSON
{
  "kind": "secret",
  "name": "example-tls-secret",
  "description": "example-tls-secret description",
  "tags": {},
  "type": "tls",
  "data": {
    "cert": "-----BEGIN CERTIFICATE-----\nMIID+zCCAuOgAwIBAgIUEwBv3WQkP7dIiEIxyj+Wi1STz7QwDQYJKoZIhvcNAQEL\nBQAwgYwxCzAJBgNVBAYTAlVTMRMwEQYDVQQIDApDYWxpZm9ybmlhMRQwEgYDVQQH\nDAtMb3MgQW5nZWxlczENMAsGA1UECgwEQ1BMTjERMA8GA1UECwwIQ1BMTi1PUkcx\nEDAOBgNVBAMMB2NwbG4uaW8xHjAcBgkqhkiG9w0BCQEWD3N1cHBvcnRAY3Bsbi5p\nbzAeFw0yMDEwMTQxNzI4MDhaFw0zMDEwMTIxNzI4MDhaMIGMMQswCQYDVQQGEwJV\nUzETMBEGA1UECAwKQ2FsaWZvcm5pYTEUMBIGA1UEBwwLTG9zIEFuZ2VsZXMxDTAL\nBgNVBAoMBENQTE4xETAPBgNVBAsMCENQTE4tT1JHMRAwDgYDVQQDDAdjcGxuLmlv\nMR4wHAYJKoZIhvcNAQkBFg9zdXBwb3J0QGNwbG4uaW8wggEiMA0GCSqGSIb3DQEB\nAQUAA4IBDwAwggEKAoIBAQDBzN2jRf9ouoF4XG0eUxcc4f1sP8vhW1fQXjun3cl0\nRsN4jRdOyTKWcls1yAxlOkwFod8d6HND9OvNrsl7U4iJIEcJL6vTqHY7jTGXQkd9\nyPONMpMXYE8Dsiqtk0deoOab7fafYcvq1iWnpvg157mJ/u9qdyU+1h8DncES30Fk\nPsG8TsIsjx94JkTJeMmEJxtws4dfuoCk88INbBHLjxBQgwTu0vgMxN34b5z+esHr\naetDN2fqxSoTOeIlyFzeS+kwG3GK4I1hUQBiL2TeDrnEY6qP/ZoGuyyVnsT/6pHY\n/BTAcH3Rgeqose7mqBT+7zlxDfHYHceuNB/ljq0e1j69AgMBAAGjUzBRMB0GA1Ud\nDgQWBBRxncC/8RRio/S9Ly8tKFS7WnTcNTAfBgNVHSMEGDAWgBRxncC/8RRio/S9\nLy8tKFS7WnTcNTAPBgNVHRMBAf8EBTADAQH/MA0GCSqGSIb3DQEBCwUAA4IBAQAr\nsDZQj4K47fW6JkJbxlzZ1hd7IX6cQhI/DRIdTGR1u0kM1RtZoS0UtV5qsYV/g/S4\nChuB/aIARyTWvHKDhcT3bRGHLnoZJ8pLlQh4nEfO07SRhyeNiO4qmWM9az0nP5qD\nwAXpLpmYIairzAgY7QXbk5wXbTrXli3mz14VaNoqN4s7iyLtHn5TGAXc12aMwo7M\n5yn/RGxoWQoJqSQKc9nf909cR81AVCdG1dFcp7u8Ud1pTtlmiU9ZJ/YOXDCT/1hZ\nYxoeotDBBOIao3Ym/3351somMoQ7Lz6hRWvG0WhDIsCXvth4XSxRkZFXgjWNuhdD\nu2ZCis/EwXsqRJPkIPnL\n-----END CERTIFICATE-----\t\t",
    "chain": "-----BEGIN CERTIFICATE-----\nMIID+zCCAuOgAwIBAgIUEwBv3WQkP7dIiEIxyj+Wi1STz7QwDQYJKoZIhvcNAQEL\nBQAwgYwxCzAJBgNVBAYTAlVTMRMwEQYDVQQIDApDYWxpZm9ybmlhMRQwEgYDVQQH\nDAtMb3MgQW5nZWxlczENMAsGA1UECgwEQ1BMTjERMA8GA1UECwwIQ1BMTi1PUkcx\nEDAOBgNVBAMMB2NwbG4uaW8xHjAcBgkqhkiG9w0BCQEWD3N1cHBvcnRAY3Bsbi5p\nbzAeFw0yMDEwMTQxNzI4MDhaFw0zMDEwMTIxNzI4MDhaMIGMMQswCQYDVQQGEwJV\nUzETMBEGA1UECAwKQ2FsaWZvcm5pYTEUMBIGA1UEBwwLTG9zIEFuZ2VsZXMxDTAL\nBgNVBAoMBENQTE4xETAPBgNVBAsMCENQTE4tT1JHMRAwDgYDVQQDDAdjcGxuLmlv\nMR4wHAYJKoZIhvcNAQkBFg9zdXBwb3J0QGNwbG4uaW8wggEiMA0GCSqGSIb3DQEB\nAQUAA4IBDwAwggEKAoIBAQDBzN2jRf9ouoF4XG0eUxcc4f1sP8vhW1fQXjun3cl0\nRsN4jRdOyTKWcls1yAxlOkwFod8d6HND9OvNrsl7U4iJIEcJL6vTqHY7jTGXQkd9\nyPONMpMXYE8Dsiqtk0deoOab7fafYcvq1iWnpvg157mJ/u9qdyU+1h8DncES30Fk\nPsG8TsIsjx94JkTJeMmEJxtws4dfuoCk88INbBHLjxBQgwTu0vgMxN34b5z+esHr\naetDN2fqxSoTOeIlyFzeS+kwG3GK4I1hUQBiL2TeDrnEY6qP/ZoGuyyVnsT/6pHY\n/BTAcH3Rgeqose7mqBT+7zlxDfHYHceuNB/ljq0e1j69AgMBAAGjUzBRMB0GA1Ud\nDgQWBBRxncC/8RRio/S9Ly8tKFS7WnTcNTAfBgNVHSMEGDAWgBRxncC/8RRio/S9\nLy8tKFS7WnTcNTAPBgNVHRMBAf8EBTADAQH/MA0GCSqGSIb3DQEBCwUAA4IBAQAr\nsDZQj4K47fW6JkJbxlzZ1hd7IX6cQhI/DRIdTGR1u0kM1RtZoS0UtV5qsYV/g/S4\nChuB/aIARyTWvHKDhcT3bRGHLnoZJ8pLlQh4nEfO07SRhyeNiO4qmWM9az0nP5qD\nwAXpLpmYIairzAgY7QXbk5wXbTrXli3mz14VaNoqN4s7iyLtHn5TGAXc12aMwo7M\n5yn/RGxoWQoJqSQKc9nf909cR81AVCdG1dFcp7u8Ud1pTtlmiU9ZJ/YOXDCT/1hZ\nYxoeotDBBOIao3Ym/3351somMoQ7Lz6hRWvG0WhDIsCXvth4XSxRkZFXgjWNuhdD\nu2ZCis/EwXsqRJPkIPnL\n-----END CERTIFICATE-----\t\t",
    "key": "-----BEGIN PRIVATE KEY-----\nMIIEvgIBADANBgkqhkiG9w0BAQEFAASCBKgwggSkAgEAAoIBAQDBzN2jRf9ouoF4\nXG0eUxcc4f1sP8vhW1fQXjun3cl0RsN4jRdOyTKWcls1yAxlOkwFod8d6HND9OvN\nrsl7U4iJIEcJL6vTqHY7jTGXQkd9yPONMpMXYE8Dsiqtk0deoOab7fafYcvq1iWn\npvg157mJ/u9qdyU+1h8DncES30FkPsG8TsIsjx94JkTJeMmEJxtws4dfuoCk88IN\nbBHLjxBQgwTu0vgMxN34b5z+esHraetDN2fqxSoTOeIlyFzeS+kwG3GK4I1hUQBi\nL2TeDrnEY6qP/ZoGuyyVnsT/6pHY/BTAcH3Rgeqose7mqBT+7zlxDfHYHceuNB/l\njq0e1j69AgMBAAECggEAPGhrPZV4A2D/MlE9AhLMRYh7wd4w4tHiEWUOG0kank/g\nZhc0iK5WQmbq31y34GXHhInsThpCs5AIYFh3HSXwjS2udsKRQKxmDjH4nzldp2uX\n3w9Aoiy29GP4wZoCyRBGUZxfH1cQhOazXgrBm6vbPZRldD4nMer0R+BIamWEsIYD\nYjDj1pT0noLUSeqoLmGxSQ4DNIBQVZB/T8ziMcEzl6bhprT0QrapJSyD2CtA8tH1\nZ8cyhmyE0CUvSkV4K2ecvVukWBJvrAYc6euPAnkS5LJrQotI5+3jJO2QawOlL6Uw\nrFWBpgBrCgbzquMRpDCQ/J9/GDYaZjim4YdonboBgQKBgQD7jx3CVnG4LDz198am\nspmPwKCW1ke6PhlG7zf3YR00xg9vPBYiy4obb1Jg6em1wr+iZ0dEt8fimeZXewBf\nLzlrR8T1Or0eLzfbn+GlLIKGKhn2pKB/i1iolkfIonchqXRk9WNx+PzjgUqiYWRC\n/1tH2BsODlVrzKL2lnbWKNIFdQKBgQDFOLedpMeYemLhrsU1TXGt1xTxAbWvOCyt\nvig/huyz4SQENXyu3ImPzxIxpTHxKhUaXo/qFXn0jhqnf0LfWI4nbQUbkivb5BPr\nKY9aj7XwwsY4MXW5C12Qi0lIwHOWCmfzvyS7TCMqnQb7sT4Mjmm4ydEbiI1TjlFJ\nD/RFxzcDKQKBgQCehPcJyZNrrWTU0sh5rz4ZWhdYNbuJXyxqiMBJwQa4hL6hJ8oD\nLyPeWe4daAmAIjLEUjSU1wK8hqKiKb54PLgAJH+20MbvyG14lm2Iul2d0dX+mIsT\nFGpQAjNF+Sr9KV1RaVi7L12ct5KidKDLn0KUKVgTKXEmtxNSNEq6dYqzKQKBgDI8\nzljzvnwSwNloIYgAYDK+FPGHU/Z8QrVHOQ1lmyn+8aO41DfeqZPeVW4b/GrII3QC\nHnqsWdJ32EZOXoRyFFPqq2BojY+Hu6MthPy2msvncYKi5q/qOz00nchQbaEMqYon\naH3lWRfjxAGdFocwR7HwhrmSwR1FpWMNE1Yq9tJxAoGBANc0nZSy5ZlTiMWdRrTt\ngFc9N/jz8OL6qLrJtX2Axyv7Vv8H/gbDg4olLR+Io38M0S1WwEHsaIJLIvJ6msjl\n/LlseAW6oiO6jzhWEr0VQSLkuJn45hG/uy7t19SDuNR7W5NuEr0YbWd6fZEpR7RR\nS1hFKnRRcrVqA+HjWnZ//BGi\n-----END PRIVATE KEY-----"
  }
}
```

```yaml YAML
kind: secret
name: example-tls-secret
description: example-tls-secret description
tags: {}
type: tls
data:
  cert: |-
    -----BEGIN CERTIFICATE-----
    MIID+zCCAuOgAwIBAgIUEwBv3WQkP7dIiEIxyj+Wi1STz7QwDQYJKoZIhvcNAQEL
    BQAwgYwxCzAJBgNVBAYTAlVTMRMwEQYDVQQIDApDYWxpZm9ybmlhMRQwEgYDVQQH
    DAtMb3MgQW5nZWxlczENMAsGA1UECgwEQ1BMTjERMA8GA1UECwwIQ1BMTi1PUkcx
    EDAOBgNVBAMMB2NwbG4uaW8xHjAcBgkqhkiG9w0BCQEWD3N1cHBvcnRAY3Bsbi5p
    bzAeFw0yMDEwMTQxNzI4MDhaFw0zMDEwMTIxNzI4MDhaMIGMMQswCQYDVQQGEwJV
    UzETMBEGA1UECAwKQ2FsaWZvcm5pYTEUMBIGA1UEBwwLTG9zIEFuZ2VsZXMxDTAL
    BgNVBAoMBENQTE4xETAPBgNVBAsMCENQTE4tT1JHMRAwDgYDVQQDDAdjcGxuLmlv
    MR4wHAYJKoZIhvcNAQkBFg9zdXBwb3J0QGNwbG4uaW8wggEiMA0GCSqGSIb3DQEB
    AQUAA4IBDwAwggEKAoIBAQDBzN2jRf9ouoF4XG0eUxcc4f1sP8vhW1fQXjun3cl0
    RsN4jRdOyTKWcls1yAxlOkwFod8d6HND9OvNrsl7U4iJIEcJL6vTqHY7jTGXQkd9
    yPONMpMXYE8Dsiqtk0deoOab7fafYcvq1iWnpvg157mJ/u9qdyU+1h8DncES30Fk
    PsG8TsIsjx94JkTJeMmEJxtws4dfuoCk88INbBHLjxBQgwTu0vgMxN34b5z+esHr
    aetDN2fqxSoTOeIlyFzeS+kwG3GK4I1hUQBiL2TeDrnEY6qP/ZoGuyyVnsT/6pHY
    /BTAcH3Rgeqose7mqBT+7zlxDfHYHceuNB/ljq0e1j69AgMBAAGjUzBRMB0GA1Ud
    DgQWBBRxncC/8RRio/S9Ly8tKFS7WnTcNTAfBgNVHSMEGDAWgBRxncC/8RRio/S9
    Ly8tKFS7WnTcNTAPBgNVHRMBAf8EBTADAQH/MA0GCSqGSIb3DQEBCwUAA4IBAQAr
    sDZQj4K47fW6JkJbxlzZ1hd7IX6cQhI/DRIdTGR1u0kM1RtZoS0UtV5qsYV/g/S4
    ChuB/aIARyTWvHKDhcT3bRGHLnoZJ8pLlQh4nEfO07SRhyeNiO4qmWM9az0nP5qD
    wAXpLpmYIairzAgY7QXbk5wXbTrXli3mz14VaNoqN4s7iyLtHn5TGAXc12aMwo7M
    5yn/RGxoWQoJqSQKc9nf909cR81AVCdG1dFcp7u8Ud1pTtlmiU9ZJ/YOXDCT/1hZ
    YxoeotDBBOIao3Ym/3351somMoQ7Lz6hRWvG0WhDIsCXvth4XSxRkZFXgjWNuhdD
    u2ZCis/EwXsqRJPkIPnL
    -----END CERTIFICATE-----
  chain: |-
    -----BEGIN CERTIFICATE-----
    MIID+zCCAuOgAwIBAgIUEwBv3WQkP7dIiEIxyj+Wi1STz7QwDQYJKoZIhvcNAQEL
    BQAwgYwxCzAJBgNVBAYTAlVTMRMwEQYDVQQIDApDYWxpZm9ybmlhMRQwEgYDVQQH
    DAtMb3MgQW5nZWxlczENMAsGA1UECgwEQ1BMTjERMA8GA1UECwwIQ1BMTi1PUkcx
    EDAOBgNVBAMMB2NwbG4uaW8xHjAcBgkqhkiG9w0BCQEWD3N1cHBvcnRAY3Bsbi5p
    bzAeFw0yMDEwMTQxNzI4MDhaFw0zMDEwMTIxNzI4MDhaMIGMMQswCQYDVQQGEwJV
    UzETMBEGA1UECAwKQ2FsaWZvcm5pYTEUMBIGA1UEBwwLTG9zIEFuZ2VsZXMxDTAL
    BgNVBAoMBENQTE4xETAPBgNVBAsMCENQTE4tT1JHMRAwDgYDVQQDDAdjcGxuLmlv
    MR4wHAYJKoZIhvcNAQkBFg9zdXBwb3J0QGNwbG4uaW8wggEiMA0GCSqGSIb3DQEB
    AQUAA4IBDwAwggEKAoIBAQDBzN2jRf9ouoF4XG0eUxcc4f1sP8vhW1fQXjun3cl0
    RsN4jRdOyTKWcls1yAxlOkwFod8d6HND9OvNrsl7U4iJIEcJL6vTqHY7jTGXQkd9
    yPONMpMXYE8Dsiqtk0deoOab7fafYcvq1iWnpvg157mJ/u9qdyU+1h8DncES30Fk
    PsG8TsIsjx94JkTJeMmEJxtws4dfuoCk88INbBHLjxBQgwTu0vgMxN34b5z+esHr
    aetDN2fqxSoTOeIlyFzeS+kwG3GK4I1hUQBiL2TeDrnEY6qP/ZoGuyyVnsT/6pHY
    /BTAcH3Rgeqose7mqBT+7zlxDfHYHceuNB/ljq0e1j69AgMBAAGjUzBRMB0GA1Ud
    DgQWBBRxncC/8RRio/S9Ly8tKFS7WnTcNTAfBgNVHSMEGDAWgBRxncC/8RRio/S9
    Ly8tKFS7WnTcNTAPBgNVHRMBAf8EBTADAQH/MA0GCSqGSIb3DQEBCwUAA4IBAQAr
    sDZQj4K47fW6JkJbxlzZ1hd7IX6cQhI/DRIdTGR1u0kM1RtZoS0UtV5qsYV/g/S4
    ChuB/aIARyTWvHKDhcT3bRGHLnoZJ8pLlQh4nEfO07SRhyeNiO4qmWM9az0nP5qD
    wAXpLpmYIairzAgY7QXbk5wXbTrXli3mz14VaNoqN4s7iyLtHn5TGAXc12aMwo7M
    5yn/RGxoWQoJqSQKc9nf909cR81AVCdG1dFcp7u8Ud1pTtlmiU9ZJ/YOXDCT/1hZ
    YxoeotDBBOIao3Ym/3351somMoQ7Lz6hRWvG0WhDIsCXvth4XSxRkZFXgjWNuhdD
    u2ZCis/EwXsqRJPkIPnL
    -----END CERTIFICATE-----
  key: |-
    -----BEGIN PRIVATE KEY-----
    MIIEvgIBADANBgkqhkiG9w0BAQEFAASCBKgwggSkAgEAAoIBAQDBzN2jRf9ouoF4
    XG0eUxcc4f1sP8vhW1fQXjun3cl0RsN4jRdOyTKWcls1yAxlOkwFod8d6HND9OvN
    rsl7U4iJIEcJL6vTqHY7jTGXQkd9yPONMpMXYE8Dsiqtk0deoOab7fafYcvq1iWn
    pvg157mJ/u9qdyU+1h8DncES30FkPsG8TsIsjx94JkTJeMmEJxtws4dfuoCk88IN
    bBHLjxBQgwTu0vgMxN34b5z+esHraetDN2fqxSoTOeIlyFzeS+kwG3GK4I1hUQBi
    L2TeDrnEY6qP/ZoGuyyVnsT/6pHY/BTAcH3Rgeqose7mqBT+7zlxDfHYHceuNB/l
    jq0e1j69AgMBAAECggEAPGhrPZV4A2D/MlE9AhLMRYh7wd4w4tHiEWUOG0kank/g
    Zhc0iK5WQmbq31y34GXHhInsThpCs5AIYFh3HSXwjS2udsKRQKxmDjH4nzldp2uX
    3w9Aoiy29GP4wZoCyRBGUZxfH1cQhOazXgrBm6vbPZRldD4nMer0R+BIamWEsIYD
    YjDj1pT0noLUSeqoLmGxSQ4DNIBQVZB/T8ziMcEzl6bhprT0QrapJSyD2CtA8tH1
    Z8cyhmyE0CUvSkV4K2ecvVukWBJvrAYc6euPAnkS5LJrQotI5+3jJO2QawOlL6Uw
    rFWBpgBrCgbzquMRpDCQ/J9/GDYaZjim4YdonboBgQKBgQD7jx3CVnG4LDz198am
    spmPwKCW1ke6PhlG7zf3YR00xg9vPBYiy4obb1Jg6em1wr+iZ0dEt8fimeZXewBf
    LzlrR8T1Or0eLzfbn+GlLIKGKhn2pKB/i1iolkfIonchqXRk9WNx+PzjgUqiYWRC
    /1tH2BsODlVrzKL2lnbWKNIFdQKBgQDFOLedpMeYemLhrsU1TXGt1xTxAbWvOCyt
    vig/huyz4SQENXyu3ImPzxIxpTHxKhUaXo/qFXn0jhqnf0LfWI4nbQUbkivb5BPr
    KY9aj7XwwsY4MXW5C12Qi0lIwHOWCmfzvyS7TCMqnQb7sT4Mjmm4ydEbiI1TjlFJ
    D/RFxzcDKQKBgQCehPcJyZNrrWTU0sh5rz4ZWhdYNbuJXyxqiMBJwQa4hL6hJ8oD
    LyPeWe4daAmAIjLEUjSU1wK8hqKiKb54PLgAJH+20MbvyG14lm2Iul2d0dX+mIsT
    FGpQAjNF+Sr9KV1RaVi7L12ct5KidKDLn0KUKVgTKXEmtxNSNEq6dYqzKQKBgDI8
    zljzvnwSwNloIYgAYDK+FPGHU/Z8QrVHOQ1lmyn+8aO41DfeqZPeVW4b/GrII3QC
    HnqsWdJ32EZOXoRyFFPqq2BojY+Hu6MthPy2msvncYKi5q/qOz00nchQbaEMqYon
    aH3lWRfjxAGdFocwR7HwhrmSwR1FpWMNE1Yq9tJxAoGBANc0nZSy5ZlTiMWdRrTt
    gFc9N/jz8OL6qLrJtX2Axyv7Vv8H/gbDg4olLR+Io38M0S1WwEHsaIJLIvJ6msjl
    /LlseAW6oiO6jzhWEr0VQSLkuJn45hG/uy7t19SDuNR7W5NuEr0YbWd6fZEpR7RR
    S1hFKnRRcrVqA+HjWnZ//BGi
    -----END PRIVATE KEY-----
```

</CodeGroup>

</Accordion>

<Accordion title="Secret - Username/Password">

<CodeGroup>

```json JSON
{
  "kind": "secret",
  "name": "example-username-secret",
  "description": "example-username-secret description",
  "tags": {},
  "type": "userpass",
  "data": {
    "encoding": "plain",
    "password": "PASSWORD",
    "username": "USERNAME"
  }
}
```

```yaml YAML
kind: secret
name: sample-username
description: sample-username
tags: {}
type: userpass
data:
  encoding: plain
  password: PASSWORD
  username: USERNAME
```

</CodeGroup>

</Accordion>

</Accordion>

<Accordion title="Groups">

[Groups Reference Page](/reference/group)

See the [Group Query Rules](/reference/group#query-rules) reference page for details on how to create a query.

<CodeGroup>

```json JSON
{
  "kind": "group",
  "name": "example-group",
  "description": "example-group description",
  "tags": {},
  "memberLinks": ["/org/ORG_NAME/serviceaccount/SERVICE_ACCOUNT_NAME", "/org/ORG_NAME/user/USER_EMAIL", "/org/ORG_NAME/user/USER_EMAIL"],
  "memberQuery": {
    "kind": "user",
    "fetch": "items",
    "spec": {
      "match": "all",
      "terms": [
        {
          "op": "=",
          "tag": "test-tag",
          "value": "test-value"
        }
      ]
    }
  }
}
```

```yaml YAML
kind: group
name: example-group
description: example-group description
tags: {}
memberLinks:
  - /org/ORG_NAME/serviceaccount/SERVICE_ACCOUNT_NAME
  - /org/ORG_NAME/user/USER_EMAIL
  - /org/ORG_NAME/user/USER_EMAIL
memberQuery:
  kind: user
  fetch: items
  spec:
    match: all
    terms:
      - op: '='
        tag: test
        value: '1234'
```

</CodeGroup>

</Accordion>

<Accordion title="Policies">

[Policies Reference Page](/reference/policy)

The first example shows a policy for an explicit secret ('targetLinks') that contain a binding for all four of the [principal types](/concepts/principal_types) with the 'edit' and 'manage' permissions.

The second example shows a policy that targets all secrets within the org. When the target key set to `all`. The `targetLinks` and `targetQuery` properties are not evaluated.

Each 'targetKind' has its own unique set of binding permissions. The permissions can be obtained by:

1. Running the CLI permissions command (e.g., `cpln secret permissions`), or
2. The reference page for each target (e.g. [Secret Permissions](/reference/secret#permissions)).

<Accordion title="Policy - Explict Secret">

<CodeGroup>

```json JSON
{
  "kind": "policy",
  "name": "example-policy-explicit",
  "description": "example-policy description",
  "tags": {},
  "targetKind": "secret",
  "bindings": [
    {
      "permissions": ["edit", "manage"],
      "principalLinks": [
        "/org/ORG_NAME/group/GROUP_NAME",
        "/org/ORG_NAME/gvc/GVC_NAME/identity/IDENTITY_NAME",
        "/org/ORG_NAME/serviceaccount/SERVICE_ACCOUNT_NAME",
        "/org/ORG_NAME/user/USER_EMAIL"
      ]
    }
  ],
  "targetLinks": ["/org/ORG_NAME/secret/SECRET_NAME"],
  "targetQuery": {
    "kind": "secret",
    "fetch": "items",
    "spec": {
      "match": "all",
      "terms": [
        {
          "op": "=",
          "tag": "example-tag",
          "value": "example-value"
        }
      ]
    }
  }
}
```

```yaml YAML
kind: policy
name: example-policy-explicit
description: example-policy description
tags: {}
origin: default
bindings:
  - permissions:
      - edit
      - manage
    principalLinks:
      - /org/ORG_NAME/group/GROUP_NAME
      - /org/ORG_NAME/gvc/GVC_NAME/identity/IDENTITY_NAME
      - /org/ORG_NAME/serviceaccount/SERVICE_ACCOUNT_NAME
      - /org/ORG_NAME/user/USER_EMAIL
targetKind: secret
targetLinks:
  - /org/ORG_NAME/secret/SECRET_NAME
targetQuery:
  kind: secret
  fetch: items
  spec:
    match: all
    terms:
      - op: '='
        tag: example-tag
        value: example-value
```

</CodeGroup>

</Accordion>

<Accordion title="Policy - All Secrets">

<CodeGroup>

```json JSON
{
  "kind": "policy",
  "name": "example-policy-all",
  "description": "example-policy-all description",
  "tags": {},
  "targetKind": "secret",
  "target": "all",
  "bindings": [
    {
      "permissions": ["edit", "manage"],
      "principalLinks": [
        "/org/ORG_NAME/group/GROUP_NAME",
        "/org/ORG_NAME/gvc/GVC_NAME/identity/IDENTITY_NAME",
        "/org/ORG_NAME/serviceaccount/SERVICE_ACCOUNT_NAME",
        "/org/ORG_NAME/user/USER_EMAIL"
      ]
    }
  ]
}
```

```yaml YAML
kind: policy
name: example-policy-all
description: example-policy-all description
tags: {}
targetKind: secret
target: all
bindings:
  - permissions:
      - edit
      - manage
    principalLinks:
      - /org/terraform-test-org/group/test
      - /org/terraform-test-org/gvc/toolbox-gvc/identity/tbd
      - /org/terraform-test-org/serviceaccount/tbd
      - /org/terraform-test-org/user/eric@controlplane.com
```

</CodeGroup>

</Accordion>

</Accordion>


### cpln convert
**Path**: `guides/cli/cpln-convert.mdx`

---
title: cpln convert
---

## Overview

The [cpln convert](/reference/cli#convert) command is designed to facilitate the migration from Kubernetes environments to Control Plane by converting Kubernetes objects into Control Plane objects.

Typically, this command is utilized alongside the [cpln apply](/reference/cli#apply) command to seamlessly convert and then directly apply the configurations.

## Prerequisites

- [CLI](/reference/cli) installed.

## Options

### Required

- `--file`
  - A `JSON`/`YAML` file containing Kubernetes objects. Use `--file -` to enable input from stdin.

### Optional

- `--protocol`
  - The port protocol to be assigned to each container within a workload converted from a deployment. Default: `http`. [choices: `http`, `http2`, `grpc`, `tcp`].

## Limitations

The [cpln convert](/reference/cli#convert) command has specific conversion capabilities, detailed as follows:

- **Workloads Conversion**
  - Can convert objects of kind Deployment and CronJob into [workloads](/reference/workload).
- **Secrets Conversion**
  - Capable of converting objects of kind Secret into Control Plane [secrets](/reference/secret).

## Create a K8s file

To demonstrate the `convert` command, create a `k8s.yaml` file with the following content:

```yaml YAML
apiVersion: apps/v1
kind: Deployment
metadata:
  name: example-deployment
  labels:
    app: nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
        - name: nginx
          image: nginx:latest
          ports:
            - containerPort: 80
```

## Convert a K8s file

### Basic Convert

The following command will convert the Kubernetes object defined in the above `k8s.yaml` file into a Control Plane object and output it to the terminal.

```
cpln convert --file k8s.yaml
```

<Accordion title="Output">

```yaml YAML
kind: workload
name: example-deployment
spec:
  containers:
    - name: nginx
      image: 'nginx:latest'
      env: []
      ports:
        - number: 80
          protocol: http
      args: []
  defaultOptions:
    suspend: false
    capacityAI: false
    autoscaling:
      minScale: 3
      maxScale: 3
  type: serverless
```

</Accordion>

### Convert With a Specific Protocol

Each Kubernetes object, whether of type `Deployment` or `CronJob`, will be transformed into workloads. These workloads will feature containers whose port protocols are aligned with the specification provided in the `--protocol` option.

```
cpln convert --file k8s.yaml --protocol tcp
```

<Accordion title="Output">

```yaml YAML
kind: workload
name: example-deployment
spec:
  containers:
    - name: nginx
      image: 'nginx:latest'
      env: []
      ports:
        - number: 80
          protocol: tcp
      args: []
  defaultOptions:
    suspend: false
    capacityAI: false
    autoscaling:
      minScale: 3
      maxScale: 3
  type: serverless
```

</Accordion>

## Convert & Apply

Use the [cpln apply](/reference/cli#apply) command to convert and apply.

```
cpln apply --file k8s.yaml --k8s true
```

Alternatively, you can pass the conversion result as a stdin to the [cpln apply](/reference/cli#apply) command.

`cpln convert --file k8s.yaml | cpln apply --file - `

## Revert Apply

To revert the apply, use the following command.

```
cpln delete --file k8s.yaml --k8s true
```


### cpln cp
**Path**: `guides/cli/cpln-cp.mdx`

---
title: cpln cp
---

## Overview

Copy files and directories to and from [workload containers](/reference/workload#containers).

<Warning>

IMPORTANT

The `tar` binary is required to be installed within the workload container image, otherwise, the `cpln cp` command will fail.

</Warning>

## Prerequisites

- [CLI](/reference/cli) installed.
- A running [workload](/reference/workload) in at least one location. Refer to our [create a workload](/guides/create-workload) guide for additional details.
- Permissions to interact with the [workload](/reference/workload#permissions).

## Options

### Optional

- `--location`
  - The location associated with the workload deployment (e.g., `aws-us-west-1`). Defaults to the first location fetched from the specified GVC. When specifying, make sure that the specified location is part of the specified GVC.
- `--replica`
  - The replica name associated with the workload deployment. Defaults to the first replica.
- `--container`
  - The container name associated with the workload deployment. Defaults to the first container.
- `--no-preserve`
  - The copied file/directory's ownership and permissions will not be preserved in the container. Default: `false`.

## Copy from Local to Workload

To copy a file or directory to a workload, use the following format:

```
cpln cp <source-path> <workload-name>:<destination-path> --location <location> --org <org> --gvc <gvc>
```

Refer to the following examples:

### Copy a File

To copy a local file `demo-file.txt` to the `tmp/` directory in a workload named `demo-workload`, run:

```
cpln cp demo-file.txt demo-workload:tmp/ --location aws-us-west-1 --org demo-org --gvc demo-gvc
```

### Copy a Directory

To copy a local directory `demo-directory` to the `tmp/` directory in a workload named `demo-workload`, run:

```
cpln cp demo-directory demo-workload:tmp/ --location aws-us-west-1 --org demo-org --gvc demo-gvc
```

### Copy a File or Directory With a New Name

To copy a local file or a directory to a workload and simultaneously change its name, run:

```
cpln cp <src> <workload-name>:<path>/<new-name> --location aws-us-west-1 --org demo-org --gvc demo-gvc
```

## Copy from Workload to Local

To copy a file or directory from a workload to a path within the local machine, use the following format:

```
cpln cp <workload-name>:<source-path> <destination-path> --location <location-name> --org <org> --gvc <gvc>
```

Refer to the following examples:

### Copy a File

To copy the file `tmp/demo-file.txt` from a workload named `demo-workload` to your local machine, run:

```
cpln cp demo-workload:tmp/demo-file.txt /path/within/local/machine --location aws-us-west-1 --org demo-org --gvc demo-gvc
```

### Copy a Directory

To copy the directory `tmp/demo-directory` from a workload named `demo-workload` to your local machine, run:

```
cpln cp demo-workload:tmp/demo-directory /path/within/local/machine --location aws-us-west-1 --org demo-org --gvc demo-gvc
```

### Copy a File or Directory With a New Name

To copy a local file or a directory to a workload and simultaneously change its name, run:

```
cpln cp <workload-name>:<path> <src>/<new-name> --location aws-us-west-1 --org demo-org --gvc demo-gvc
```


### cpln delete
**Path**: `guides/cli/cpln-delete.mdx`

---
title: cpln delete
---

## Overview

The [cpln delete](/reference/cli#delete) command serves as the opposite of the CLI [apply](/reference/cli#apply) command. While the `apply` command creates and updates resources, the `delete` command deletes resources. Both the `apply` and the `delete` commands accept the same options.

## Using the CLI

```
cpln delete --file FILE_NAME [OPTIONS]
```

The `FILE_NAME` is the path for the file and it can be either a JSON or YAML file containing the resource metadata.

To delete an [Identity](/reference/identity), a [Volume Set](/reference/volumeset) or a [Workload](/reference/workload) resource you need to specify a GVC in one of the following methods.

- Specify a `gvc` within your [cpln profile](/guides/manage-profile). This will add the `gvc` to the session context of the profile and will be refered to as the default `gvc` when executing any future command including the `cpln delete` command.

  ```
  cpln profile update PROFILE_NAME --gvc GVC_NAME
  ```

- Specify a `--gvc` flag to the `delete` command. This will pass the `gvc` as an option and will override the default `gvc` that is defined in the session context of the profile.

  ```
  cpln delete --file FILE_NAME --gvc GVC_NAME
  ```

- Specify a `gvc` property in the resource definition in the file you wish to run the delete command against.

  ```yaml YAML
  kind: identity
  name: example-identity
  description: example-description
  tags: {}
  gvc: example-gvc
  ```

<Note>You can either specify a gvc property or a --gvc flag, you can't specify both.</Note>

[Click here](/reference/cli#delete) to view the CLI reference page for the `delete` command.

### Delete an Applied K8s File

The CLI has the ability to convert K8s resources into Control Plane resources. By passing the `--k8s true` option to the `delete` command, the K8s resources will be converted and deleted.

```
cpln delete --file FILE_NAME --k8s true
```

The `delete` command will use the logic of the CLI [convert](/reference/cli#convert) command and then delete the resources defined in the output.

### Delete from Standard Input

In case you would like to pass Control Plane resources through `stdin` (Standard Input) and delete them, use the following command.

```
CONTROL_PLANE_RESOURCES | cpln delete --file -
```

<Tip>This is useful if you would like to pass the stdout of a command to the cpln delete command.</Tip>

## Using the Console

The console has the ability to upload a JSON or YAML file or accept a resource definition in JSON or YAML as input. The functionality is the same as using the CLI. Click the `cpln apply` button in the upper right corner of the console. A modal will be displayed containing the upload instructions. Enable the `Use as Delete` switch in order to delete a resource.

The cpln apply modal provides the ability to specify in which `org` and `gvc` a resource will be deleted. The default is your currently selected `org` and `gvc`.

A file or an input containing an [Identity](/reference/identity), a [Volume Set](/reference/volumeset) or a [Workload](/reference/workload) resource will be deleted in the scope of the specified `gvc` in the cpln apply modal. In case a `gvc` is defined within a resource, the resource will be deleted in the scope of that `gvc`.

## Multiple Resources

To delete multiple resources, specify a JSON array or YAML's separated with `---`.

```yaml YAML
kind: gvc
name: example-gvc
description: example-gvc
tags: {}
spec:
  staticPlacement:
    locationLinks:
      - /org/ORG_NAME/location/aws-eu-central-1
---
kind: identity
name: example-identity
description: example-identity
tags: {}
gvc: example-gvc
```


### cpln helm
**Path**: `guides/cli/cpln-helm.mdx`

---
title: cpln helm
---

## Overview

The [cpln helm](/reference/cli#helm) command streamlines the process of managing Control Plane resources
by leveraging the output generated by the [helm template](https://helm.sh/docs/helm/helm_template) command. This functionality proves invaluable for those preferring to define their Control Plane
resources within a [helm chart](https://helm.sh/docs/topics/charts/), facilitating regular
updates to these resources with ease.

To ensure a seamless transition for users familiar with the original [helm](https://helm.sh) commands, we
have intentionally designed our CLI helm subcommands to closely resemble their helm counterparts. This approach aims to minimize confusion and provide a familiar environment, as our CLI helm command adheres to the same foundational principles and workflows
as the traditional helm commands.

## Prerequisites

- [CLI](/reference/cli) installed.
- [helm](https://helm.sh) installed.
- Defined [policies](/concepts/policy) to create applicable Control Plane resources.
- [Policy](/concepts/policy) to reveal applicable [secrets](/reference/secret).

## Definitions

### cpln release

The definition of a `cpln release` mirrors that of a [helm release](https://helm.sh/docs/intro/using_helm/#three-big-concepts), essentially representing a deployed instance
of a [helm chart](https://helm.sh/docs/topics/charts) within Control Plane. Executing a `cpln release` involves the use of the [cpln helm install](/reference/cli#helm-install) command. Each [upgrade](#upgrade-a-release) ensures that the resources defined in the [helm chart](https://helm.sh/docs/topics/charts) are appropriately applied. The [upgrade](#upgrade-a-release) also takes care of removing any resources that are no longer part of the chart and updates the [cpln release state](#cpln-release-state) to reflect these changes.

When you run the [cpln helm install](/reference/cli#helm-install) command, it results in the creation of a secret of type [opaque](/reference/secret#opaque) within your org. This secret is integral to the process, as it contains the payload corresponding to the [cpln release state](#cpln-release-state).

### cpln release state

The `cpln release state` serves as the definitive source for managing releases through the CLI. This functionality is crucial for understanding the dynamics of your deployments, such as identifying when a new resource is introduced or an existing one is removed. The CLI achieves this by comparing the current `cpln release state` with the output from the [helm template](https://helm.sh/docs/helm/helm_template) command.

The `cpln release state` is structured as a JSON object, which includes:

- `schemaVersion`
  - Represents the version of the generator used to create the `cpln release state`. This is particularly important for version control, especially when updates are made to the state's structure or functionalities by the CLI.
- `release`
  - This key stores the name of the release, allowing for easy identification and reference.
- `deployments`
  - A list of deployments. Each [install](#install-a-release)/[upgrade](#upgrade-a-release) adds a new deployment in which it can be [rolled back](#rollback-a-release) to. Each deployment consists of the following properties:
    - `gvc`: The value of the `--gvc` option that was specified on install/upgrade.
    - `revision`: The revision number of the deployment. Each time you update or roll back a release, the revision number increases. It helps you keep track of changes made to your deployment over time.
    - `updated`: The last modified date and time in UTC format.
    - `status`: The status of the deployment is equivalent to the helm deployment status. The value could be one of the following:
      - superseded
      - deployed
      - failed
      - pending-install
      - pending-upgrade
      - pending-rollback
      - uninstalling
      - uninstalled
    - `chart`: The name of the helm chart.
    - `appVersion`: The `appVersion` that is defined within the **Chart.yml** file.
    - `description`: The string passed to the `--description` flag in the [cpln helm install](/reference/cli#helm-install) and [cpln helm upgrade](/reference/cli#helm-upgrade) commands, providing contextual information about the release.
    - `values`: A string that contains the contents of the `values.yaml` file along with any additional values provided through the `-f` or `--values` options.
    - `resources`
      - A list of the active resources that were defined in the last [cpln release](#cpln-release) install. Each item is an object that has the following properties that are relative to the resource:
        - `id`: A unique identifier for the resource.
        - `kind`: Specifies the type of the resource.
        - `version`: The version of the resource.
        - `link`: The self-link of the resource.
        - `template`: The resource definition extracted from the output generated by the [helm template](https://helm.sh/docs/helm/helm_template) command.

## Create a Helm Chart

To create a helm chart, follow these steps:

1. In an empty directory, execute the command (substitute CHART_NAME with your desired name):
   - `helm create CHART_NAME`
2. A directory named `CHART_NAME` will be created which will contain the following resources:
   - Directories: `charts` and `templates`
   - Files: `.helmignore`, `Chart.yaml`, and `values.yaml`
3. Delete the contents of the `templates` directory.
4. Using your favorite text editor, open the `values.yaml` file and replace the contents with the following:

```yaml YAML
exampleGvc:
  name: example-gvc
  description: This is a description
  locationLinks:
    - //location/aws-eu-central-1

exampleHttpbinWorkload:
  name: httpbin-example

exampleIdentity:
  name: example-identity
```

5. Create a file called `resources.yaml` within the `templates` directory and paste the following:

```yaml YAML
kind: gvc
name: {{ .Values.exampleGvc.name }}
description: {{ .Values.exampleGvc.description }}
spec:
  staticPlacement:
    locationLinks:
    {{- range .Values.exampleGvc.locationLinks }}
      - {{ . }}
    {{- end }}
---
kind: identity
name: {{ .Values.exampleIdentity.name }}
description: {{ .Values.exampleIdentity.name }}
gvc: {{ .Values.exampleGvc.name }}
---
kind: workload
name: {{ .Values.exampleHttpbinWorkload.name }}
description: {{ .Values.exampleHttpbinWorkload.name }}
gvc: {{ .Values.exampleGvc.name }}
spec:
  identityLink: //gvc/{{ .Values.exampleGvc.name }}/identity/{{ .Values.exampleIdentity.name }}
  type: serverless
  containers:
    - name: httpbin
      cpu: 50m
      image: kennethreitz/httpbin
      inheritEnv: false
      memory: 128Mi
      ports:
        - number: 80
          protocol: http
  defaultOptions:
    autoscaling:
      maxConcurrency: 1000
      maxScale: 1
      metric: concurrency
      minScale: 1
      scaleToZeroDelay: 300
      target: 100
    capacityAI: true
    debug: false
    suspend: true
    timeoutSeconds: 5
  firewallConfig:
    external:
      inboundAllowCIDR:
        - 0.0.0.0/0
      outboundAllowCIDR:
        - 0.0.0.0/0
      outboundAllowHostname: []
      outboundAllowPort: []
    internal:
      inboundAllowType: none
      inboundAllowWorkload: []
  localOptions: []
  supportDynamicTags: false
```

## Generate a Helm Template

The [cpln helm template](/reference/cli#helm-template) command will
execute the [helm template](https://helm.sh/docs/helm/helm_template) command in the background and will output to stdout.

Example:

```
cpln helm template NAME PATH_TO_HELM_CHART
```

<Accordion title="Output from executing the chart created in the above example">

```yaml YAML
---
# Source: test-chart/templates/resources.yaml
kind: gvc
name: example-gvc
description: This is a description
spec:
  staticPlacement:
    locationLinks:
      - //location/aws-eu-central-1
---
# Source: test-chart/templates/resources.yaml
kind: identity
name: example-identity
description: example-identity
gvc: example-gvc
---
# Source: test-chart/templates/resources.yaml
kind: workload
name: httpbin-example
description: httpbin-example
gvc: example-gvc
spec:
  identityLink: //gvc/example-gvc/identity/example-identity
  type: serverless
  containers:
    - name: httpbin
      cpu: 50m
      image: kennethreitz/httpbin
      inheritEnv: false
      memory: 128Mi
      ports:
        - number: 80
          protocol: http
  defaultOptions:
    autoscaling:
      maxConcurrency: 1000
      maxScale: 1
      metric: concurrency
      minScale: 1
      scaleToZeroDelay: 300
      target: 100
    capacityAI: true
    debug: false
    suspend: true
    timeoutSeconds: 5
  firewallConfig:
    external:
      inboundAllowCIDR:
        - 0.0.0.0/0
      outboundAllowCIDR:
        - 0.0.0.0/0
      outboundAllowHostname: []
      outboundAllowPort: []
    internal:
      inboundAllowType: none
      inboundAllowWorkload: []
  localOptions: []
  supportDynamicTags: false
```

</Accordion>

### Helm Template Options

For the list of options, browse to the [cpln helm template](/reference/cli#helm-template) command and expand the `References` panel.

<Tip>If the release name is not specified, the flag `--generate-name` must be added and will auto generate a release name.</Tip>

### Injected Values

The following values get injected into the [cpln helm template](https://helm.sh/docs/helm/helm_template) command which can be accessed from within your chart.

- Key: `cpln.org`, Value: `Name of your organization`.
- Key: `cpln.gvc`, Value: `Name of your GVC`.

Example Usage:

```
{{ .Values.cpln.org }}
```

<Warning>
  It is recommended that you avoid defining a top-level `cpln` property within your `values.yaml` file, as the injected values above will
  override them.
</Warning>

## Chart Notes

After executing [cpln helm install](/reference/cli#helm-install) or [cpln helm upgrade](/reference/cli#helm-upgrade), the content of the NOTES.txt file that is defined within the chart directory will be output to stdout.

## Injected Tags

When you [install](#install-a-release) or [upgrade](#upgrade-a-release), the specified tags are added to each resource that is being installed or upgraded.

- Key: `cpln/release`, Value: The name of the release.

## Tell Helm Not To Uninstall a Resource

Sometimes there are resources that should not be uninstalled. Chart developers can add the `helm.sh/resource-policy: keep` tag to a resource to prevent it from being uninstalled.

```yaml YAML
kind: location
tags:
  helm.sh/resource-policy: keep
[...]
```

The tag `helm.sh/resource-policy: keep` instructs the [CLI](/reference/cli) to skip deleting this resource when a `cpln helm` operation (such as `cpln helm uninstall`, `cpln helm upgrade` or `cpln helm rollback`) would result in its deletion.

## Install a Release

The [cpln helm install](/reference/cli#helm-install) command accepts the same options
as the [cpln helm template](/reference/cli#helm-template) command. It injects the same values
and executes the [helm template](https://helm.sh/docs/helm/helm_template) command in the background. It will
use the output to create, update, and remove resources based on content that is added/modified within the chart.

<Note>
  The release name should follow the same naming convention that is used to name resources in Control Plane since the name of the release
  will be part of the [secret](/reference/secret) name that will be created.
</Note>

Example usage:

```
cpln helm install NAME PATH_TO_HELM_CHART
```

<Accordion title="Output from executing the chart created in the above example">

```
Created /org/cpln-test-org/gvc/example-gvc
Created /org/cpln-test-org/gvc/example-gvc/identity/example-identity
Created /org/cpln-test-org/gvc/example-gvc/workload/httpbin-example

Release 'example' has been installed successfully!
```

</Accordion>

### Wait for Workload Readiness

To guarantee the readiness of one or more workloads during the [cpln helm install](/reference/cli#helm-install), include the `--wait` option in your command. This will enforce a default waiting period of 300 seconds (5 minutes). If you need to adjust this duration, use the `--timeout` option with your preferred number of seconds.

Example usage:

```
cpln helm install NAME PATH_TO_HELM_CHART --wait --timeout 600
```

## Upgrade a Release

If you need to modify your release following alterations to your chart — be it adding a new resource, updating an existing one, or removing
a resource — execute the [cpln helm upgrade](/reference/cli#helm-upgrade) command. It's crucial to use the same release name when running this command. This
consistency enables the CLI to accurately determine which resources should be deleted and to appropriately update the [cpln release state](#cpln-release-state) with these changes and a new deployment.

<Warning>
  A release can only have up to 10 deployments. Every additional upgrade will omit the oldest one (i.e. the deployment with the lowest
  revision number).
</Warning>

Using the above example, the updated template (resources.yaml) below has the identity and the identityLink (from the workload) removed.

<Accordion title="Updated Resources Template">

```yaml YAML
kind: gvc
name: {{ .Values.exampleGvc.name }}
description: {{ .Values.exampleGvc.description }}
spec:
  staticPlacement:
    locationLinks:
    {{- range .Values.exampleGvc.locationLinks }}
      - {{ . }}
    {{- end }}
---
kind: workload
name: {{ .Values.exampleHttpbinWorkload.name }}
description: {{ .Values.exampleHttpbinWorkload.name }}
gvc: {{ .Values.exampleGvc.name }}
spec:
  type: serverless
  containers:
    - name: httpbin
      cpu: 50m
      image: kennethreitz/httpbin
      inheritEnv: false
      memory: 128Mi
      ports:
        - number: 80
          protocol: http
  defaultOptions:
    autoscaling:
      maxConcurrency: 1000
      maxScale: 1
      metric: concurrency
      minScale: 1
      scaleToZeroDelay: 300
      target: 100
    capacityAI: true
    debug: false
    suspend: true
    timeoutSeconds: 5
  firewallConfig:
    external:
      inboundAllowCIDR:
        - 0.0.0.0/0
      outboundAllowCIDR:
        - 0.0.0.0/0
      outboundAllowHostname: []
      outboundAllowPort: []
    internal:
      inboundAllowType: none
      inboundAllowWorkload: []
  localOptions: []
  supportDynamicTags: false
```

</Accordion>

Example usage:

```
cpln helm upgrade NAME PATH_TO_HELM_CHART
```

<Accordion title="Output from executing the updated template">

```
Updated gvc 'example-gvc'
Updated workload 'httpbin-example'

Performing cleanup...

Deleted /org/cpln-test-org/gvc/example-gvc/identity/example-identity

Release 'example' has been installed successfully!
```

</Accordion>

## Rollback a Release

The [cpln helm rollback](/reference/cli#helm-rollback) command rolls back a release to a previous revision. If no revision is specified, the command will rollback to the previous revision. To view the revision number of each deployment, refer to the [cpln helm history](/reference/cli#helm-history) command.

Example usage:

```
cpln helm rollback NAME [REVISION]
```

<Accordion title="Output">

```
Updated gvc 'example-gvc'
Updated identity 'example-identity'
Updated workload 'httpbin-example'

Rollback to deployment revision '1' has been successfully!
```

</Accordion>

## Release History

The [cpln helm history](/reference/cli#helm-history) command will output the deployments of a given release in the format defined in your profile (YAML, JSON, etc.). You can override the formatting with the `--output` option.

Example usage:

```
cpln helm history NAME
```

<Accordion title="Output">

```
+---------+--------------+-----------+--------+------------+-----------------+
|REVISION |UPDATED       |STATUS     |CHART   |APP VERSION |DESCRIPTION      |
| :------ | :----------- | :-------- | :----- | :--------- | :-------------- |
|1        |0 minutes ago |superseded |example |1.16.0      |Install complete |
|2        |0 minutes ago |deployed   |example |1.16.0      |Upgrade complete |
+---------+--------------+-----------+--------+------------+-----------------+
```

</Accordion>

## Get

### Manifest

The [cpln helm get manifest](/reference/cli#helm-get-manifest) command fetches the generated manifest for a given release.

Example usage:

```
cpln helm get manifest RELEASE_NAME
```

<Accordion title="Output">

```json JSON
[
  {
    "id": "c6613b07-507d-484f-9260-41cc516219d3",
    "kind": "gvc",
    "version": 1,
    "link": "/org/cpln-test-org/gvc/example-gvc",
    "template": {
      "kind": "gvc",
      "name": "example-gvc",
      "description": "This is a description",
      "spec": {
        "staticPlacement": {
          "locationLinks": ["//location/aws-eu-central-1"]
        }
      },
      "tags": {
        "cpln/release": "cpln-release-example"
      }
    }
  },
  {
    "id": "564a472a-ddfe-46c9-9f42-f63468260035",
    "kind": "identity",
    "version": 1,
    "link": "/org/cpln-test-org/gvc/example-gvc/identity/example-identity",
    "template": {
      "kind": "identity",
      "name": "example-identity",
      "description": "example-identity",
      "gvc": "example-gvc",
      "tags": {
        "cpln/release": "cpln-release-example"
      }
    }
  },
  {
    "id": "6de0c688-e1ad-4e35-8253-bee0b79693ca",
    "kind": "workload",
    "version": 2,
    "link": "/org/cpln-test-org/gvc/example-gvc/workload/httpbin-example",
    "template": {
      "kind": "workload",
      "name": "httpbin-example",
      "description": "httpbin-example",
      "gvc": "example-gvc",
      "spec": {
        "identityLink": "//gvc/example-gvc/identity/example-identity",
        "type": "serverless",
        "containers": [
          {
            "name": "httpbin",
            "cpu": "50m",
            "image": "kennethreitz/httpbin",
            "inheritEnv": false,
            "memory": "128Mi",
            "ports": [
              {
                "number": 80,
                "protocol": "http"
              }
            ]
          }
        ],
        "defaultOptions": {
          "autoscaling": {
            "maxConcurrency": 1000,
            "maxScale": 1,
            "metric": "concurrency",
            "minScale": 1,
            "scaleToZeroDelay": 300,
            "target": 100
          },
          "capacityAI": true,
          "debug": false,
          "suspend": true,
          "timeoutSeconds": 5
        },
        "firewallConfig": {
          "external": {
            "inboundAllowCIDR": ["0.0.0.0/0"],
            "outboundAllowCIDR": ["0.0.0.0/0"],
            "outboundAllowHostname": [],
            "outboundAllowPort": []
          },
          "internal": {
            "inboundAllowType": "none",
            "inboundAllowWorkload": []
          }
        },
        "localOptions": [],
        "supportDynamicTags": false
      },
      "tags": {
        "cpln/release": "cpln-release-example",
        "cpln/deployTimestamp": "2024-09-26T18:18:47.066Z"
      }
    }
  }
]
```

</Accordion>

You can always change the output format by adjusting the `--output` option.

### Values

The [cpln helm get values](/reference/cli#helm-get-values) command will output the values of a given release.

Example usage:

```
cpln helm get values RELEASE_NAME
```

<Accordion title="Output">

```yaml YAML
exampleGvc:
  name: example-gvc
  description: This is a description
  locationLinks:
    - //location/aws-eu-central-1
exampleHttpbinWorkload:
  name: httpbin-example
exampleIdentity:
  name: example-identity
```

</Accordion>

You can always change the output format by adjusting the `--output` option.

## List Releases

The [cpln helm list](/reference/cli#helm-list) command lists all [cpln releases](#cpln-release).

Example usage:

```
cpln helm list
```

<Accordion title="Output">

```text
+--------+--------+---------+---------------+---------+--------+------------+
|NAME    |GVC     |REVISION |UPDATED        |STATUS   |CHART   |APP VERSION |
| :----- | :----- | :------ | :------------ | :------ | :----- | :--------- |
|example |example |1        |12 minutes ago |deployed |example |1.16.0      |
+--------+--------+---------+---------------+---------+--------+------------+
```

</Accordion>

You can always change the output format by adjusting the `--output` option.

## Uninstall a Release

The [cpln helm uninstall](/reference/cli#helm-uninstall) command will help uninstall a [cpln release](#cpln-release), that includes deleting every resource defined in the [cpln release state](#cpln-release-state) and will also delete the [secert](/reference/secret) that has been created to represent the [cpln release](#cpln-release).

Example usage:

```
cpln helm uninstall NAME
```

<Accordion title="Output">

```
Deleted /org/cpln-test-org/gvc/example-gvc/workload/httpbin-example
Deleted /org/cpln-test-org/gvc/example-gvc

Release 'example' has been uninstalled successfully!
```

</Accordion>


### Manage CLI Profiles
**Path**: `guides/cli/manage-profile.mdx`

---
title: Manage CLI Profiles
---

## Overview

The CLI is used to perform actions against the Control Plane API. Since most of the CLI commands require the caller to be authenticated and authorized, the CLI profile is used to store the security token and default properties.

## Prerequisites

- Install the [CLI](/reference/cli)
- Review the CLI [profile](/reference/cli#profile) command page

## Create a Profile

After installation, to execute any of the CLI commands, at least one profile must be created and associated with an authenticated [user](/reference/user) or [service account](/reference/serviceaccount).

To create the profile named `default` and authenticate with a [user](/reference/user) account, follow the
[interactive login - default profile](#interactive-login-default-profile) instructions.

To create a profile using a custom name and authenticate with a [user](/reference/user) account, follow the
[interactive login - custom profile](#interactive-login-custom-profile) instructions.

After logging in, that profile will be marked as the default and used by any future CLI command.

The following default properties are set on the profile during creation:

- [Context](/reference/cli#context)
  - Org: None
  - GVC: None
- [Format](/reference/cli#format)
  - Color: `true`
  - Output: `text`
  - Timestamp: `age`
- [Request](/reference/cli#request)
  - Endpoint: `https://api.cpln.io`
  - Insecure: `false`
  - Timeout: `30`
  - Token: AUTH_TOKEN

To override these values, refer to the [default properties](#default-properties) section.

## Interactive Login - Default Profile

Executing the command:

```
cpln profile login
```

will launch the login page within a browser. If the authentication is successful, a new profile named `default`
will be created (if it doesn't already exist). This login targets only the profile named `default`. After logging in,
this profile will be marked as the default and used by any future CLI command.

## Interactive Login - Custom Profile

To authenticate to a specific profile, executing the command:

```
cpln profile update PROFILE_NAME --login
```

will launch the login page within a browser. If the authentication is successful, a new profile with the given name
will be created (if it doesn't already exist). After logging in, this profile will be marked as the default and used by
any future CLI command.

## Interactive Login - Existing Profile

To authenticate to an existing profile, execute the following command:

```
cpln profile login PROFILE_NAME
```

## Default Properties

The `--org` or `--gvc` options are required on a majority of the CLI commands and are set to an empty string by default. The
default [org](/reference/org), [GVC](/reference/gvc), and other properties can be set by updating your profile.

The following properties can be updated:

- default
  - Default profile (similar to the [set default](#set-default-profile) command)
- org
  - Default [org](/reference/org)
- gvc
  - Default [GVC](/reference/gvc)
- output
  - Default output format (text, json, yaml, json-slim, or yaml-slim)
- color
  - Default colorization of the output (true or false)
- ts
  - Default timestamp format (iso, local, or age)
- max
  - Default max number of records to show (number > 0)
- token
  - Override profile token
- endpoint
  - Default API endpoint
- insecure
  - Override TLS errors (true or false)

Sample Command:

```
cpln profile update PROFILE_NAME --PROPERTY NEW_VALUE
```

Examples:

<CodeGroup>

```text Update One Property
cpln profile update my_profile --org test-org
```

```text Update Multiple Properties
cpln profile update my_profile --org test-org --gvc test-gvc
```

</CodeGroup>

## Set Default Profile

If you have multiple profiles, execute the following command to mark a profile as `default`:

```
cpln profile set-default PROFILE_NAME
```

Future CLI commands will use this profile. If the profile is not authenticated, follow the instructions [here](#interactive-login-custom-profile).

## Remove Profile Default Context (Org/GVC)

To remove the default organization and/or default GVC from a specific profile, pass an empty string as the value.

<CodeGroup>

```text Remove Default Organization
cpln profile update PROFILE_NAME --org ""
```

```text Remove Default GVC
cpln profile update PROFILE_NAME --gvc ""
```

</CodeGroup>

<Warning>

Removing the default organization from a profile will also remove the default GVC. This is because the GVC is tied to the specific organization and may not be applicable to a future default organization.

</Warning>

## Security Token

Executing the command:

```
cpln profile token PROFILE_NAME
```

will show the JWT token for the given profile if it has a valid authentication token. This token can be used to override any of
the CLI commands by using the `--token` option.

## Delete Profile

If a profile is no longer needed, execute the command:

```
cpln profile delete PROFILE_NAME
```

<Warning>The profile and any associated data will be deleted.</Warning>


## guides/cli/workload


### cpln workload connect
**Path**: `guides/cli/workload/connect.mdx`

---
title: cpln workload connect
---

## Overview

The [cpln workload connect](/reference/cli#workload-connect) command is designed to establish a direct remote terminal connection to your workload replica at a specific location, allowing you to interact with the terminal session of the workload replica. This guide outlines how to effectively use the [workload connect](/reference/cli#workload-connect) command, enabling you to perform tasks such as troubleshooting.

## Prerequisites

- [CLI](/reference/cli) installed and [authenticated](/guides/manage-profile) with a default profile, [org](/reference/org) and [gvc](/reference/gvc).
- A running [workload](/reference/workload) in at least one location. Refer to our [create a workload](/guides/create-workload) guide.
- Permissions to interact with the [workload](/reference/workload#permissions).

## Options

### Optional

- `--location`
  - The location associated with the workload deployment (e.g., `aws-us-west-1`). Defaults to the first location fetched from the specified GVC. When specifying, make sure that the specified location is part of the specified GVC.
- `--replica`
  - The replica name associated with the workload deployment. Defaults to the first replica.
- `--container`
  - The container name associated with the workload deployment. Defaults to the first container.
- `shell`, `-s`
  - The shell to use upon connecting to the workload replica. Defaults to `bash`.

## Basic Connect

To initiate a basic connection, you need the workload's name and its deployment location.

#### Retrieve Workload Deployments

```
cpln workload get-deployments WORKLOAD_NAME
```

This command lists the available locations. Identify the location name from the output.

#### Connect to Workload

Example usage:

```
cpln workload connect WORKLOAD_NAME --location LOCATION
```

This command connects to the first replica and container in the specified location.

## Advanced Connect

### Specific Replica

In cases where there are more than one replica in a workload deployment and you would like to connect to a specific one, you can provide the `--replica` option followed by the replicas name.

#### List Replicas

```
cpln workload replica get WORKLOAD_NAME --location LOCATION
```

To override the output format, use the `--output` option followed by the desired format (YAML, JSON, etc.).

#### Connect to a Replica

Example usage:

```
cpln workload connect WORKLOAD_NAME --location LOCATION --replica REPLICA_NAME
```

### Specific Container

Within a workload where numerous containers are configured, regardless if a container is handling traffic or functioning as a sidecar, it is feasible to establish a connection to it by using the `--container` option.

Example usage:

```
cpln workload connect WORKLOAD_NAME --location LOCATION --container CONTAINER_NAME
```

### Specific Shell

Different container environments may require or support different shells environments in order to connect, such as `bash` or `sh`.

To specify the shell, use the `--shell` option.

Example usage:

```
cpln workload connect WORKLOAD_NAME --location LOCATION --shell SHELL_NAME
```


### cpln workload exec
**Path**: `guides/cli/workload/exec.mdx`

---
title: cpln workload exec
---

## Overview

The [cpln workload exec](/reference/cli#workload-exec) command lets you execute a specific command followed by custom arguments in a workload replica at a specific location.

## Prerequisites

- [CLI](/reference/cli) installed and [authenticated](/guides/manage-profile) with a default profile, [org](/reference/org) and [gvc](/reference/gvc).
- A running [workload](/reference/workload) in at least one location. Refer to our [create a workload](/guides/create-workload) guide.
- Permissions to interact with the [workload](/reference/workload#permissions).

## Options

### Required

- `--`
  - Command to execute on replica (e.g., `echo hello world`).

### Optional

- `--stdin`, `-i`
  - Pass stdin to the container. Default: `false`.
- `--tty`, `-t`
  - Stdin is a TTY. Default: `false`.
- `--quiet`, `-q`
  - Only print output from the remote session. Default: `false`.
- `--location`
  - The location associated with the workload deployment (e.g., `aws-us-west-1`). Defaults to the first location fetched from the specified GVC. When specifying, make sure that the specified location is part of the specified GVC.
- `--replica`
  - The replica name associated with the workload deployment. Defaults to the first replica.
- `--container`
  - The container name associated with the workload deployment. Defaults to the first container.

## Basic Usage

#### Retrieve Workload Deployments

```
cpln workload get-deployments WORKLOAD_NAME
```

This command lists available locations. Identify the location name from the output.

#### Usage

Example usage:

```
cpln workload exec WORKLOAD_NAME --location LOCATION -- COMMAND ARG1 ARG2
```

## Advanced Usage

### Specific Replica

In cases where you have more than one replica in a workload deployment and you would like to execute a command in one of them, you can provide the `--replica` option followed by the replicas name.

#### List Replicas

```
cpln workload replica get WORKLOAD_NAME --location LOCATION
```

To override the output format, use the `--output` option followed by the desired format (YAML, JSON, etc.).

#### Execute Within a Specific Replica

Example usage:

```
cpln workload exec WORKLOAD_NAME --location LOCATION --replica REPLICA_NAME -- COMMAND ARG1 ARG2
```

### Specific Container

Within a workload where numerous containers are configured, regardless if a container is handling traffic or functioning as a sidecar, it is feasible to execute a command to it by using the `--container` option.

Example usage:

```
cpln workload exec WORKLOAD_NAME --location LOCATION --container CONTAINER_NAME -- COMMAND ARG1 ARG2
```

### Sending Stdin

To send stdin to a command executed within a workload, use the `-i` or `--stdin` option.

Example usage:

```
cpln workload exec WORKLOAD_NAME -i --location LOCATION --container CONTAINER_NAME -- COMMAND ARG1 ARG2
```

### Starting an Interactive Session

To start an interactive session using the exec command, combine the `-i` and `-t` options (or use `-it`). This allows you to run a shell command within a container interactively.

Example usage:

```
cpln workload exec WORKLOAD_NAME -it -- /bin/bash
```


### cpln workload run
**Path**: `guides/cli/workload/run.mdx`

---
title: cpln workload run
---

## Overview

The [cpln workload run](/reference/cli#workload-run) command lets you run a specific command followed by custom arguments in a new workload instance. The CLI will wait for the new workload instance to be healthy and will then execute the specified command in the first workload replica and first container. The [workload run](/reference/cli#workload-run) command starts an interactive session with the first replica of the workload and execute the specified command.

## Prerequisites

- [CLI](/reference/cli) installed and [authenticated](/guides/manage-profile) with a default profile, [org](/reference/org) and [gvc](/reference/gvc).
- Permissions to interact with [workloads](/reference/workload#permissions).

## Options

### Required

- `--`
  - Command to execute in the first workload replica (e.g., `echo hello world`).

<Info>This option must always be defined at the end of the command.</Info>

### Optional

- `--clone`
  - The designated workload to clone and run the command within its cloned instance.
- `--tag`
  - The tags to append to the new workload instance (e.g., `--tag drink=water`).
- `--image`
  - The image intended to replace the image currently associated with the new workload instance.
- `--interactive`, `--i`
  - Interact directly with the new workload's terminal after command execution. Default: `false`.
- `--remove`, `--rm`
  - Specifying this will perform a cleanup, where it will delete the new workload instance after the command execution.
- `--cpu`
  - Set allocated CPU for the container (e.g., `50m`).
- `--memory`, `--mem`
  - Set allocated memory for the container (e.g., `128Mi`).
- `--container`
  - Specify the container to run the command in, applicable **only** to the containers available within the workload being cloned when using the `--clone` option. Defaults to first container.
- `--command`, `-c`
  - Set container command.
- `--arg`, `-a`
  - Set container args.
- `--shell`, `-s`
  - Shell to use, **only** valid when interactive flag is set to true. Default: `bash`.
- `--location`
  - The location associated with the workload deployment (e.g., `aws-us-west-1`). Defaults to the first location fetched from the specified GVC. When specifying, make sure that the specified location is part of the specified GVC.

## Default Behavior

When specifying the command to execute, the [workload run](/reference/cli#workload-run) command will reate a new [standard](/reference/workload#standard) workload based on the [ubuntu:22.04](https://hub.docker.com/layers/library/ubuntu/22.04/images/sha256-81bba8d1dde7fc1883b6e95cd46d6c9f4874374f2b360c8db82620b33f6b5ca1?context=explore) image, wait for it to be healthy, and will execute the specified command within the workload replica and then exit.

Example usage:

```
cpln workload run -- COMMAND
```

### Override Default Image

Example usage:

```
cpln workload run --image IMAGE_TAG -- COMMAND
```

## Clone & Run Command in a Specific Workload

By specifying the `--clone` option, the specified workload will be cloned with the same specs. The [workload run](/reference/cli#workload-run) command will wait for the new cloned workload instance to be healthy, execute the specified command within the first workload replica, and then exit.

Example usage:

```
cpln workload run --clone WORKLOAD_NAME -- COMMAND
```

### With a Specific Container

If there is more than one running container in the new workload instance and you wish to run a specific command within it, you can provide the name of the container to the `--container` option.

Example usage:

```
cpln workload run --clone WORKLOAD_NAME --container CONTAINER_NAME -- COMMAND
```

## Interact With The Workload

By specifying the `--interactive` option, the remote terminal session will stay open after the specified command is executed.

Example usage:

```
cpln workload run --interactive -- COMMAND
```

### With a Specific Shell

By default, the [workload run](/reference/cli#workload-run) command attempts to initiate an interactive `bash` session; if unavailable, it sequentially tries `zsh`, then `sh`. If all attempts fail, an interactive session cannot be established, and the specified command will not execute.

To override the default shell, specify one with the `--shell` option.

Example usage:

```
cpln workload run --interactive --shell SHELL_NAME -- COMMAND
```

## Perform Cleanup

If you wish for the newly created workload instance to be deleted after the command is executed, pass the `--remove` or the `--rm` option to the [workload run](/reference/cli#workload-run) command.

Example usage:

```
cpln workload run --remove -- COMMAND
```

## Other Examples

### Override CPU & Memory

```
cpln workload run --cpu 75m --memory 150Mi -- ls -al
```

### Override Container Command & Args

```
cpln workload run --command sleep --arg "999d" -- ls -al
```

### Specific Location

```
cpln workload run --location aws-eu-central-1 -- ls -al
```

<Note>
  Make sure the specified location is part of the specified GVC. Otherwise, the workload will never be ready and the command will never
  execute.
</Note>

### Append Tags

```
cpln workload run --tag drink=water -- ls -al
```


## guides


### CLI Quick Start
**Path**: `guides/cli-quick-start.mdx`

---
title: CLI Quick Start
---

## Overview

Control Plane offers a [Command Line Interface](/reference/cli) for all major operating systems. The [CLI](/reference/cli) is an abstraction layer over the Control Plane [API](/api-reference/api) and gives you access to all the features of the platform.

It is recommended to install the [CLI](/reference/cli) in order to perform a handful of operations that are not available from the console (e.g., containerizing a microservice).

This quick start will demonstrate how to:

- Install the [CLI](/reference/cli#install-npm).
- Log in to the [CLI](/reference/cli#login).
- Display the Control Plane resources created in the previous [Quick Start](/quickstart/sample-application).
- Set a default [Org](/reference/org) and [GVC](/reference/gvc) in your [profile](/guides/manage-profile).

## Prerequisites

- [Deploy Your First Workload](/quickstart/sample-application) Quick Start.

## Step One - Install the CLI

The preferred method to install the [CLI](/reference/cli) is using [npm](https://www.npmjs.com/get-npm) with Node.js version 12+. Alternate methods to install the [CLI](/reference/cli) are available [here](/reference/cli#install-binary).

After installing [npm](https://www.npmjs.com/get-npm), open a new shell window and execute the following command to install the [CLI](/reference/cli):

```bash
npm install -g @controlplane/cli
```

After a successful installation, run the following command to view the installed version:

```bash
cpln --version
```

The latest version can be viewed [here](/release-notes#latest-versions) and cross referenced with the output from the --version flag.

## Step Two - Log in to the CLI

The [CLI](/reference/cli) requires you to log in before executing any commands.

Open a new shell and execute this command to log in:

```bash
cpln login
```

The default browser will launch displaying the login page. Select the single sign-on (SSO) provider that is connected to your email address. After a successful log in, the brower can be closed. The shell will display the [profile](/guides/manage-profile) named `default` that was created and mapped to your email address.

## Step Three - Display Control Plane Resources

You can use the [CLI](/reference/cli) to view the resources that were created in the previous [Quick Start](/quickstart/sample-application).

Execute the commands below to view their respective output (substitute ORG_NAME and GVC_NAME for your [Org](/reference/org) and [GVC](/reference/gvc) name):

<CodeGroup>

```bash Get all your Orgs
cpln org get
```

```bash Get all your GVCs
cpln gvc get --org ORG_NAME
```

```bash Get all your Workloads
cpln workload get --org ORG_NAME --gvc GVC_NAME
```

</CodeGroup>

To view all the commands that the [CLI](/reference/cli) offers, run:

```
cpln --help
```

Each command displayed in the `--help` output also has its own `--help` output. To view it, run:

```
cpln COMMAND --help
```

## Step Four - Set a default Org and GVC

Notice that in [step 3](#step-three-display-control-plane-resources) the [GVC](/reference/gvc) and [Workload](/reference/workload) commands required additional flags for the [Org](/reference/org) and [GVC](/reference/gvc).

By setting a default [Org](/reference/org) and/or [GVC](/reference/gvc) on your [profile](/guides/manage-profile), those flags will not be needed in future [CLI](/reference/cli) command calls.

To set a default [Org](/reference/org) or [GVC](/reference/gvc) on your [profile](/guides/manage-profile), run the following command (substitute ORG_NAME and GVC_NAME for your [Org](/reference/org) and [GVC](/reference/gvc) name):

```bash
cpln profile update default --org ORG_NAME --gvc GVC_NAME
```

## Summary

By installing the [CLI](/reference/cli), you have the ability to easily interact with the platform and execute commands quickly.

Visit the [CLI reference](/reference/cli) page for details and examples of each command.

Click the `4. Deploy an Application` button below to learn how to use the [CLI](/reference/cli) to deploy an application from code to a running [Workload](/reference/workload).


### Create a Group
**Path**: `guides/create-a-group.mdx`

---
title: Create a Group
---

## Overview

Follow the steps below to create a [group](/reference/group) within your [org](/reference/org).

Membership in a group for a user account can be directly or dynamically (using a query based on a [tag](/reference/misc#tags)) assigned.

Membership in a group for a service account can only be directly assigned.

## Prerequisites

- Review the [group](/reference/group) reference page
- [Permissions](/reference/policy#permissions) to create a [group](/reference/group)
- Optional:
  - Install the [CLI](/reference/cli)

## Create using the UI Console

1. Create a new group using one of the following methods:
   - Clicking `Groups` in the left menu and click `New`, or
   - Click the `Create` dropdown in the upper right corner and select `Group`
2. Enter a unique name and optional description. Click `Next (Users)`.
3. A list of [users](/reference/user) will be shown that can be selected. A [query](/reference/group#query-rules) can be defined to dynamically assigned users to the group. Click `Next (Service Accts)`.
4. A list of [service accounts](/reference/serviceaccount) will be shown that can be selected. Click `Next (Tags)`.
5. Enter any optional [tags](/reference/misc#tags). Click `Create`.

## [Create using the CLI](#create-cli)

Refer to the [group create](/reference/cli#group-create) command for details and examples on how to create a group using the CLI.

## Next Steps

Groups can be used by [policies](/reference/policy) to grant access permissions to the group members.


### Create a GVC
**Path**: `guides/create-a-gvc.mdx`

---
title: Create a GVC
---

## Overview

Follow the steps below to create a [GVC](/reference/gvc) within your [org](/reference/org).

## Prerequisites

- Review the [GVC](/reference/gvc) reference page
- [Permissions](/reference/policy#permissions) to create a [GVC](/reference/gvc)
- Optional:
  - Install the [CLI](/reference/cli)

## Create using the UI Console

Follow the steps below to create a GVC:

1. Create a new GVC using one of the following methods:

   - For an [org](/reference/org) without any GVCs:
     - After logging in, the `Create GVC` page will be shown, or if you browse to a different page,
     - Click the `Create` dropdown in the upper right corner and select `GVC`
   - For an [org](/reference/org) with at least one GVC:
     - Click the `Create` dropdown in the upper right corner and select `GVC`

2. Enter a unique name, optional description, and select a [domain](/reference/domain). If there are no domains defined, use the `Default`. Custom domains can be added later. Click `Next (Locations)`.
3. Select at least one of the listed cloud providers. Click `Next (Pull Secrets)`
4. The [Docker/ECR/GCP Pull Secrets](/reference/gvc#pull-secrets) that have been configured for your [org](/reference/org) will be listed. If any secrets are shown, select one or more secrets that would be required by your [workloads](/reference/workload) to authenticate to a private registry to pull their images. Click `Next (Tags)`.
5. Enter any optional [tags](/reference/misc#tags). Click `Create`.

Your GVC has been successfully created and is ready to be configured with a [workload](/reference/workload).

## Create using the CLI

Refer to the [GVC create](/reference/cli#gvc-create) command for details and examples on how to create a GVC using the CLI.


### Create a Policy
**Path**: `guides/create-a-policy.mdx`

---
title: Create a Policy
---

## Overview

Follow the steps below to create a [policy](/reference/policy) defining access permissions to any Control Plane resource for any principal ([user](/reference/user), [service account](/reference/serviceaccount), [group](/reference/group), and [identity](/reference/identity)).

## Prerequisites

- Review the [policy](/reference/policy) reference page
- [Permissions](/reference/policy#permissions) to create a [policy](/reference/policy)
- Optional:
  - Install the [CLI](/reference/cli)

## Create using the UI Console

1. Create a new policy by either:
   - Clicking `Policies` in the left menu and click `New`, or
   - Click the `Create` dropdown in the upper right corner and select `Policy`
2. Select Resource Type:
   - Enter a policy name and optional description
   - Select a target resource type
     - Choose one of the resource types that you'd like to control access to
     - You have the option to select specific resources or target all the resources in your [org](/reference/org) by turning on the `Target All` switch
     - If you are targeting all the resources, click `Next` and skip to step 4.
     - Click `Next`
3. Select Specific Resources:
   - Choose one or both of the following methods to select resources:
     - Directly assigned:
       - A list of available resources will be shown and can be selected
     - Dynamically assigned:
       - Using the [tag query](/reference/misc#tags) form, configure the match by rule.
   - Click `Next`
4. Add a Binding:
   - At least one binding is required. Click `Add Binding`.
   - Select one or more permissions. These permissions are specific to the selected resource type.
   - Browse through the principal tabs and select at least one principal. Click `Add`.
   - If required, add additional bindings. Note: The bindings must have a unique set of permissions. Click `Create`.
   - The policy has been created and is now active

## Create using the CLI

Refer to the [policy create](/reference/cli#policy-create) and [policy add-binding](/reference/cli#policy-add-binding) commands for details and examples on how to create a policy and binding using the CLI.

## Summary

Control Plane [policies](/reference/policy) allow for fine-grained authorization to the resources within your [org](/reference/org). By granting to principals only the permissions they need to get their job done, policies limit the information they can view and actions they can perform. Most applications and services running on the platform are mission-critical and authorized principals should only have the access they require.


### Create a Service Account
**Path**: `guides/create-a-service-account.mdx`

---
title: Create a Service Account
---

## Overview

Follow the steps below to create a [service account](/reference/serviceaccount) within your [org](/reference/org).

## Prerequisites

- Review the [service account](/reference/serviceaccount) reference page
- [Permissions](/reference/policy#permissions) to create a [service account](/reference/serviceaccount)
- Optional:
  - Install the [CLI](/reference/cli)

## Create using the UI Console

1. Create a new service account by either:
   - Clicking `Service Accounts` in the left menu and click `New`, or
   - Click the `Create` dropdown in the upper right corner and select `Service Account`
2. Enter a unique name and optional description and click `Next (Tags)`
3. Enter any optional [tags](/reference/misc#tags). Click `Create`.
4. Click the `Keys` link to generate a new token that is used to create a profile
5. Enter a key description and click `Add`. Copy and download the generated key

## Create using the CLI

Refer to the [serviceaccount create](/reference/cli#serviceaccount-create) and [serviceaccount add-key](/reference/cli#serviceaccount-add-key) command for details and examples on how to create a service account using the CLI.

## Next Steps

After creating a service account with a key, it can be used in a [policy](/reference/policy) to grant permissions to any Control Plane resource. Once permissions have been granted, a [browser-less CLI login](/guides/browser-less-cli-login) is performed to authenticate and allow the execution of CLI commands.


### Create an Agent
**Path**: `guides/create-an-agent.mdx`

---
title: Create an Agent
---

## Overview

Follow the steps below to define an [agent](/reference/agent) and generate a bootstrap file that will be used when installing
the agent within your internal environment or at one of the cloud providers.

## Prerequisites

- Review the [agent](/reference/agent) reference page
- [Permissions](/reference/policy#permissions) to create an [agent](/reference/agent)
- Optional:
  - Install the [CLI](/reference/cli)

## Create using the UI Console

1. Create a new agent by either:

   - Clicking `Agents` in the left menu and click `New`, or
   - Click the `Create` dropdown in the upper right corner and select `Agent`

2. Enter a unique name and optional description. Click `Next (Tags)`.
3. Enter any optional [tags](/reference/misc#tags). Click `Create`.
4. The console will display the bootstrap config JSON text that can be copied to the clipboard or downloaded. The `Done` button will not be active until the text is copied or downloaded. Save the text as a file. This file will be used when configuring an agent. Click `Done`.

<Warning>
  Properly save the bootstrap config JSON text. It will not be accessible after closing the modal. If you lose the text, you will need to
  delete and recreate the agent.
</Warning>

## Create using the CLI

1. At a command prompt, execute the following to create an agent:

```bash
cpln agent create --name NEW_AGENT_NAME --org ORG_NAME > bootstrap-config.json
```

2. The output of the command will be the bootstrap config JSON text. Executing the command above will save the text in a file called `bootstrap-config.json`. This file will be used when configuring an agent.

<Tip>

Detailed CLI documentation for the agent command is available [here](/reference/cli#agent).

</Tip>

## Next Steps

Once the bootstrap config file has been generated and saved, follow the [set up an agent](/guides/setup-agent) guide to install and configure an agent:

- [Amazon Web Services (AWS)](/guides/setup-agent#aws)
- [Microsoft Azure](/guides/setup-agent#azure)
- [Google Cloud Platform (GCP)](/guides/setup-agent#gcp)
- [Private Network](/guides/setup-agent#private-network)


### Create an Audit Context
**Path**: `guides/create-an-audit-context.mdx`

---
title: Create an Audit Context
---

## Overview

Follow the steps below to create an [audit context](/reference/auditctx) within your [org](/reference/org).

## Prerequisites

- Review the [audit context](/reference/auditctx) reference page
- [Permissions](/reference/policy#permissions) to create an [audit context](/reference/auditctx)
- Optional:
  - Install the [CLI](/reference/cli)

## Create using the UI Console

1.  Create a new audit context using one of the following methods:
    - Clicking `Audit Contexts` in the left menu and click `New`, or
    - Click the `Create` dropdown in the upper right corner and select `Audit Context`
2.  Enter a unique name and optional description. Click `Next (Tags)`.
3.  Enter any optional [tags](/reference/misc#tags). Click `Create`.

## Create using the CLI

Refer to the [auditctx create](/reference/cli#auditctx-create) command for details and examples on how to create an audit context using the CLI.


### Create an Identity
**Path**: `guides/create-an-identity.mdx`

---
title: Create an Identity
---

## Overview

Follow the steps below to create an [identity](/reference/identity) within your [GVC](/reference/gvc).

## Prerequisites

- Review the [identity](/reference/identity) reference page
- [Permissions](/reference/identity#permissions) to create an [identity](/reference/identity)
- Optional:
  - Install the [CLI](/reference/cli)

## Create using the UI Console

Follow the steps below to create an identity (requires a [GVC](/reference/gvc)):

1.  Create a new identity using one of the following methods:
    - Clicking `Identities` in the left menu and click `New`, or
    - Click the `Create` dropdown in the upper right corner and select `Identity`.
2.  Enter a unique name and optional description. Click `Next (Cloud Access)`.
3.  Select one of the cloud providers and follow the wizard to configure a cloud access rule. The wizard requires at least one
    [cloud account](/reference/cloudaccount) for the chosen provider to be defined. Depending on the use case of this identity, creating a cloud
    access definition is optional. See [Cloud Access](#cloud-access) for additional details. Click `Next (Network Resources)`.
4.  Click `Add Network Resource` and follow the wizard to configure a network resource. The wizard requires at least one [agent](/reference/agent)
    to exist. Each identity can have multiple network resources defined. Depending on the use case of this identity, creating a network
    resource is optional. See [Network Resource](#network-resource) for additional details. Click `Next (Tags)`.
5.  Enter any optional [tags](/reference/misc#tags). Click `Create`.
6.  The identity has been successfully created and the identity info page will be shown. This identity will now be available
    for use within your [workload's identity](/reference/workload#identity) setting.

## Cloud Access

The cloud access portion of an identity defines cloud resource access rules across one account in each of AWS, GCP and Azure. In other words, you can create an identity that allows access to several resources in a particular AWS account and a particular Azure account, but not in two separate Azure accounts.

When defining the policy for a particular cloud provider, Control Plane creates and manages (using the registered [cloud account](/reference/cloudaccount)) the following object at each cloud provider which acts as a "synthetic identity":

- AWS
  - Role
- Azure
  - App registration
- GCP
  - Service Account

The minimum set of permissions required by the [workload](/reference/workload) to call the target cloud resources should be assigned to the cloud access policy.

When [workloads](/reference/workload) call the cloud resource, they call the services by impersonating the "synthetic identity". This "synthetic identity" will only have the permission that were assigned to it.

Having multiple cloud providers configured on an [identity](/reference/identity) using cloud access rules grants the [workload](/reference/workload) the ability to call cloud resources at any cloud provider seamlessly and transparently regardless of where it running.

Below are instructions on how to set up cloud access rules using the console for:

- [AWS](#aws)
- [Azure](#azure)
- [GCP](#gcp)

### AWS

To set up an AWS cloud access policy using the console, click on the AWS icon and the wizard modal will appear.

1. Select one of the registered AWS [cloud accounts](/reference/cloudaccount)
2. Select one of the following methods and click `Next`:

   - Reuse an existing AWS role:
     - A list of roles will be shown.
     - Either select a role from the list or click the `Edit Manually` button and enter a role name. Click `Confirm Manual Input` when done.
     - Verify the role name is correct and click `Done`.
   - Configure a new AWS role with existing policies:
     - A list of available policies will be shown.
     - The policy list can be created by:
       - Selecting at least one role from the list, or
       - Click the `Set Policies Manually` button and manually enter the policy name and click `Add`. Multiple policies can be added manually. Click `Set Policies From List` to return to the existing policies list.
       - Click `Done`.

After setting up the AWS cloud access rule, a summary of the selections will be shown. Verify that the policies selected are correct and at the bottom of the page, click `Save`. If a new AWS role was selected, Control Plane will provision a new role in AWS that will be named the same as the `Object Name` shown in the `Info` page of the [identity](/reference/identity).

### Azure

To set up an Azure cloud access policy using the console, click on the Azure icon and the wizard modal will appear.

1. Select one of the registered Azure [cloud accounts](/reference/cloudaccount).
2. Click `Next`.
3. Construct the role assignments:
   - Click `Select Scope` to show the scope selection wizard. Choose the service, region, type, and scope. Click `Confirm`.
   - Click `Select Roles` to show the list of available roles for the selected scope. Select one or more roles. Click `Confirm`.
   - If additional role assignments are needed, click `Add Assignment` at the top of the modal. Repeat the first two steps.
   - Click `Done`.

After setting up the Azure cloud access policy, a summary of the selections will be shown. Verify that the roles selected are correct and at the bottom of the page, click `Save`. Control Plane will provision a new App registration in Azure that will be named the same as the `Object Name` shown in the `Info` page of the [identity](/reference/identity).

### GCP

To set up a GCP cloud access policy using the console, click on the GCP icon and the wizard modal will appear.

1. Select one of the registered GCP [cloud accounts](/reference/cloudaccount)
2. Select one of the following methods and click `Next`:

   - Reuse an existing GCP service account:
     - A list of service accounts will be shown.
     - Either select a service account from the list or click the `Edit Manually` button and enter a service account name. Click `Confirm Manual Input` when done.
     - Verify the service account name is correct and click `Done`.
   - Configure a new GCP service account:
     - Construct a new binding:
       - Click `Select Resource` to show the resource selection wizard. Choose the service, region, type, and resource. Click `Confirm`.
       - Click `Select Roles` to show the list of available roles for the selected resource. Select one or more roles. Click `Confirm`.
       - If additional bindings are needed, click `Add Binding` at the top of the modal. Repeat the first two steps.
       - Click `Done`

After setting up the GCP cloud access policy, a summary of the selections will be shown. Verify that the roles selected are correct and at the bottom of the page, click `Save`. If a new service account was selected, Control Plane will provision the new Service Account in GCP that will be named the same as the `Object Name` shown in the `Info` page of the [identity](/reference/identity).

## Network Resource

The network resource portion of an [identity](/reference/identity) defines network traversal rules from [workloads](/reference/workload) into specific endpoints in private networks (e.g., a VPC).

Tunneling network traffic from [workloads](/reference/workload) to specific TCP hosts and ports is facilitated using [agents](/reference/agent) deployed within the private network. This capability is referred to as “wormholes”.

To set up a new network resource, click the `Network Resources` link and click `Add Network Resource`.

1. Select a registered [agent](/reference/agent) matching the environment you'd like to access.
2. Enter a unique `name` for this resource.

   <Note>

   This name will be the hostname your [workload](/reference/workload) will use when calling this resource.

   </Note>

3. Choose one of the following resource discovery methods:

   - Fully Qualified Domain Name (FQDN):

     - Enter the FQDN of the internal resource.
     - Optionally, enter the internal IP address that the above FQDN will resolve to.
     - Enter at least one port that the resource exposes.

     <Note>

     When selecting FQDN, the internal resource can be called by the workload using either the FQDN or the `name` entered in step 2. If the internal resource is configured with TLS, the FQDN must be used.

     </Note>

   - IP:

     - Enter at least one IP address.
     - Enter at least one port.

     <Note>

     When selecting IP, the internal resource is called by the workload using the `name` entered in step 2.

     </Note>

<Info>A maximum of **5** ports can be added.</Info>

4. If additional resources are needed, click the `Add Network Resource` button again and repeat the steps above.
5. After setting up the necessary resources, verify that they are correct and at the bottom of the page, click `Save`.

## Create using the CLI

Refer to the [identity create](/reference/cli#identity-create) command for details and examples on how to create an [identity](/reference/identity) using the CLI.


### Create an Org
**Path**: `guides/create-an-org.mdx`

---
title: Create an Org
---

## Prerequisites

- Review the [org](/reference/org) reference page
- [Permissions](#permissions) to create an [org](/reference/org)
- Optional:
  - Install the [CLI](/reference/cli)

## Permissions

To create an org, the `org_creator` or `billing_admin` role must be assigned to a user by a billing admin from the `Org Management & Billing` dashboard.

Follow the steps below to access the Org Management & Billing dashboard and assign the role:

1. Click the profile icon in the upper right corner and select `Org Management & Billing`.
2. Click the `Users` link in the left menu.
3. If the user is not shown in the current users list, enter their email address, select the `org_creator` or `billing_admin` role, and click `Add User`. The user will receive a verification email.
4. If the user is already on the current users list and they don't have the `org_creator` or `billing_admin` role, click the `Edit` button corresponding to the user, select the `org_creator` or `billing_admin` role and click `Confirm`.

## Create using the UI Console

Follow the steps below to create an org:

1. Click the `Create` button in the upper right corner and select `Org`.
2. Enter a unique name, optional description, and any additional org admin email addresses. Click `Next (Tags)`.
3. Enter any optional [tags](/reference/misc#tags) and click `Create`. The user creating the role, and any additional org admins, will automatically be assigned to the `superusers` group.

## Create using the CLI

Refer to the [org create](/reference/cli#org-create) command for details and examples on how to create an org using the CLI.

## Notes

- Orgs are immutable and cannot be renamed or deleted.


### Invite Users
**Path**: `guides/invite-users.mdx`

---
title: Invite Users
---

## Overview

New users can be invited to join the current [org](/reference/org) and optionally added to a [group](/reference/group).

## Invite using the UI Console

1. Click `Users` in the left menu and then click the `Invite` tab at the top.
2. Enter an email address and select a group to assign the user to.
3. Click `Add to Invitation List`.
4. If an email address was entered by mistake, it can be removed by clicking the `Remove` link.
5. After entering all the users to invite, click `Confirm Invitations`. The users will be emailed an onboarding link to join your [org](/reference/org).

The invited users will be placed in the `Pending Invites` table. If an invite was sent by mistake, you can delete the invite by clicking the `Delete` link.

## Invite using the CLI

Refer to the [user invite](/reference/cli#user-invite) command for details and examples on how to invite a user using the CLI.

## Upload Users

A list of users to invite can be uploaded using the console.

A `.csv` file in the following format is required: `USER_EMAIL,GROUP_TO_ASSIGN`

Example:

```
cpln-user@example.com,none
cpln-admin@example.com,superusers
cpln-viewer@gmail.com,viewers
```

### Instructions

1. Click `Users` in the left menu and then click the `Invite` tab at the top
2. Click the `Upload from CSV` button and select the file containing the list of users to invite.
3. Click `Confirm Invitations`. The users will be emailed an onboarding link to join your [org](/reference/org).

The invited users will be placed in the `Pending Invites` table. If an invite was sent by mistake, you can
delete the invite by clicking the `Delete` link.


## guides/cloud-account


### connecting-to-aws-services
**Path**: `guides/cloud-account/connecting-to-aws-services.mdx`

- Cloud Account Creation

  - When registering a cloud account targeting AWS, your AWS administrator will manually create a new AWS role (named `cpln-ORG_NAME`) with the following policies:
    - Create a new policy named `cpln-connector` which has the necessary access to create and manage roles.
    - `ReadOnlyAccess` which "provides read-only access to AWS services and resources".
  - A "trust relationship" is associated with this role that allows the Control Plane AWS account to assume this role.

- Identity Creation

  - When an [identity](/reference/identity) is created targeting AWS, Control Plane will create a new role in AWS that will have the minimum permissions that are required to access the targeted services. When a [workload](/concepts/workload) that is assigned with an [identity](/reference/identity) requests credentials to access AWS services, Control Plane will obtain a temporary access token that impersonates the role and inject it into the [workload](/concepts/workload) granting it access.


### connecting-to-azure-services-with-azure-connector
**Path**: `guides/cloud-account/connecting-to-azure-services-with-azure-connector.mdx`

### Azure Connector

- Cloud Account Creation

  - When registering a cloud account targeting Azure using the console, your organization's Azure administrator will use the Azure CLI to perform the following:
    - Create an `Azure Function App` using an existing resource group and storage account.
    - Download the Control Plane Azure connector code.
    - Deploy the code to the function app.
    - Obtain the URL of the deployed function.
    - Obtain the code/key of the deployed function.
  - After the registration is completed, a secret of type [azure-connector](/reference/secret#azure-connector) will be created. This secret can be reused to create another cloud account (using the same Function App) or if an existing cloud account was inadvertently deleted.

- Functionality

  - The Function App that is deployed has a function called `iam-broker`. This function is called by Control Plane to obtain and inject the access token on behalf of the calling workload.
  - The Function App is set as an `Owner` of the subscription. This role assignment is needed to create the managed identities.

- Identity Creation

  - When an [identity](/reference/identity) is created targeting Azure resources, a managed identity is assigned to the function so that the function can act on its behalf. This [identity](/reference/identity) will only have the minimum permissions that are required to access the targeted services. When an [identity](/reference/identity) is assigned to a [workload](/concepts/workload) that requests access to an Azure resource, Control Plane will obtain a temporary access token that impersonates the roles and inject it into the [workload](/concepts/workload) granting it access.

- Pricing

  - The App Function runs as a managed service and is subject to charges against your Azure subscription.
  - Please visit the [Azure Function Pricing](https://azure.microsoft.com/en-us/pricing/details/functions/)
    page to view the current pricing.

- Compromised Code

  - If the Function App code has been compromised, perform the following:

    - From the Azure portal:
      - In the search bar, enter `Function App` and click the first result.
      - Click the app to update and click `Functions`.
      - Click `iam-broker` and then click `Function Keys`.
      - For the `default` Function Key, click `Renew key value`. A confirmation modal will be displayed, click `Renew`.
      - After the new key has been generated, click the link `Hidden value. Click to show value`.
      - Copy the value of the new code to the clipboard.
    - From the Control Plane console:
      - Click `Secrets` in the left menu and select the `azure-connector` secret that belongs to the cloud account (it will be named
        CLOUD_ACCOUNT_NAME-access).
      - Click the `Edit Data` button and then click the eye icon.
      - Update the `Code` property with the value of the new code by pasting it from the clipboard.

  - Until a valid code has been updated, Control Plane will not be able to manage workload [identities](/reference/identity).


### connecting-to-azure-services-with-azure-sdk
**Path**: `guides/cloud-account/connecting-to-azure-services-with-azure-sdk.mdx`

- Cloud Account Creation
  - When registering a cloud account targeting Azure using the Azure SDK, an Azure Service Principal is created by your Azure administrator using the Azure CLI. The output of the Azure CLI command are credentials that are uploaded, stored securely, and assigned to the cloud account.
  - The name of this service principal is the name of your [org](/reference/org) prefixed with `cpln-` (i.e., cpln-ORG_NAME).
  - The only Azure API permission required by this principal is `Application.ReadWrite.OwnedBy` (which belongs to the Microsoft Graph API).
  - By granting this permission, the cloud account will be able to create/manage App registrations and query available Azure scopes and roles during the creation of an [identity](/reference/identity).

<Info>

The permissions `Application.ReadWrite.OwnedBy` "allows the app to create other applications, and fully manage those applications (read, update, update application secrets and delete), without a signed-in user. It cannot update any apps that it is not an owner of".

For every [identity](/reference/identity) created, Control Plane creates an App registration for which it generates short-lived credentials and injects them into your [workload](/concepts/workload) using the native cloud providers identity interface. No matter which cloud your workload is running, Control Plane ensures that the identity information is conveyed correctly to the consumed services. Control Plane mints tokens for the [identity](/reference/identity) bound to the workloads.

</Info>

- Identity Creation

  - When creating an [identity](/reference/identity), [cloud access](/reference/identity#cloud-access-universal-cloud-identity) rules targeting Azure can be defined which specify the minimum access needed by the identity. When the [identity](/reference/identity) is saved in the console, the Azure cloud account will leverage the service principal to create a new App registration with the configured access.
  - Any [workload](/concepts/workload) can be configured to use this [identity](/reference/identity) and will have access to the defined resources.

- Expired / Compromised Credentials

  - If the service principal credentials that were assigned to the cloud account expires or have been compromised, perform the following:

    - From the Azure portal:
      - Click `Azure Active Directory` and click `App registrations` in the left menu.
      - Click `All applications` and then click the app registration named `cpln-ORG_NAME`.
      - Click `Certificates & secrets` and then click `New client secret` and follow the wizard.
      - Copy the value of the new secret to the clipboard.
      - Delete the old secret.
    - From the Control Plane console:
      - Click `Secrets` in the left menu and select the `azure-sdk` secret that belongs to the cloud account (it will be named CLOUD_ACCOUNT_NAME-access).
      - Click the `Edit Data` button and then click the eye icon.
      - Update the `clientSecret` property with the value of the new secret by pasting it from the clipboard.

  - Until a valid secret value has been updated, Control Plane will not be able to manage workload [identities](/reference/identity).


### connecting-to-gcp-services
**Path**: `guides/cloud-account/connecting-to-gcp-services.mdx`

- Cloud Account Creation

  - When registering a cloud account targeting GCP, your GCP administrator will add the Control Plane GCP service account as a member of your GCP account with the following roles:
    - `Viewer`
    - `Service Account Admin`
    - `Service Account Token Creator`
  - The Control Plane GCP service account is in the format: `cpln-ORG_NAME@ENV.iam.gserviceaccount.com`.

- Identity Creation

  - When an [identity](/reference/identity) is created targeting GCP, Control Plane will create a new `Service Account` in your GCP account that will have the minimum permissions that are required to access the targeted services.
  - When a [workload](/concepts/workload) that is assigned with an [identity](/reference/identity) requests credentials to access GCP services, Control Plane will obtain a temporary access token that impersonates the service account and inject it into the [workload](/concepts/workload) granting it access.
  - If the [identity](/reference/identity) created connects with a particular GCP service, the Control Plane GCP service account will need to be granted the `Admin` role for that service.
    - For example, if the [identity](/reference/identity) will be using Cloud Store, the `cpln-ORG_NAME@ENV.iam.gserviceaccount.com` service account needs to have the `Storage Admin` role granted to it. By adding this role, Control Plane will be able to grant temporary access token to the workload when reading/writing to a storage bucket.
    - Control Plane will not be able to assign roles similar to `Compute Network User` because the `Compute Admin` was not assigned to the `cpln-ORG_NAME@ENV.iam.gserviceaccount.com` service account.

<Tip>

If your workload [identities](/reference/identity) will be using a lot of GCP services, instead of granting the `Admin` role for each service, it will be easier to grant the `cpln-ORG_NAME@ENV.iam.gserviceaccount.com` service account the `Owner` role.

</Tip>


### Create a Cloud Account
**Path**: `guides/cloud-account/create-a-cloud-account.mdx`

---
title: Create a Cloud Account
---

## Overview

Creating a [cloud account](/reference/cloudaccount) consists of:

- Creating a [cloud account](/reference/cloudaccount) within Control Plane.
- Configuring permissions at the cloud provider granting access to the [cloud account](/reference/cloudaccount).

Follow the steps below to create a [cloud account](/reference/cloudaccount) within your [org](/reference/org).

## Prerequisites

- Review the [cloud account](/reference/cloudaccount) reference page.
- [Permissions](/reference/policy#permissions) to create a [cloud account](/reference/cloudaccount).
- Optional:
  - Install the [CLI](/reference/cli).

## Create using the UI Console

1. Create a new cloud account by either:
   - Clicking `Cloud Accounts` in the left menu and click `New`, or
   - Click the `Create` dropdown in the upper right corner and select `Cloud Account`.
2. Enter a unique name and optional description.
3. From the `Cloud Provider` dropdown, select the provider you are targeting.
   - The UI will show instruction on how to obtain the ID for your account at the selected cloud provider.
4. Copy and paste the ID into the textbox beneath the instructions. Click `Next (Configuration)`.
5. Detailed instructions will be shown that must be followed to grant Control Plane the necessary permissions within the cloud provider.
6. After completing the instructions, click the checkbox and click `Next (Tags)`.
7. Enter any optional [tags](/reference/misc#tags). Click `Create`.
8. Your cloud account has been successfully created and connected to the cloud provider.

## Create using the CLI

The CLI offers three commands to create a cloud account corresponding to each cloud provider:

| Cloud Provider | CLI Command                                                                |
| :------------- | :------------------------------------------------------------------------- |
| AWS            | [cpln cloudaccount create-aws](/reference/cli#cloudaccount-create-aws)     |
| Azure          | [cpln cloudaccount create-azure](/reference/cli#cloudaccount-create-azure) |
| GCP            | [cpln cloudaccount create-gcp](/reference/cli#cloudaccount-create-gcp)     |

Executing the command below, for each provider, will show detailed instruction on how to create a cloud account:

<CodeGroup>

```bash AWS
cpln cloudaccount create-aws --org ORG_NAME --how
```

```bash Azure
cpln cloudaccount create-azure --org ORG_NAME --how
```

```bash GCP
cpln cloudaccount create-gcp --org ORG_NAME --how
```

</CodeGroup>

The instructions shown from the `--how` option will include using both the cloud provider's UI and CLI.

## Reference

Refer to the [cloud account](/reference/cloudaccount) reference page for additional details.


### disconnecting-aws
**Path**: `guides/cloud-account/disconnecting-aws.mdx`

- Removing an AWS Cloud Account
  - If you no longer require Control Plane to create identities targeting AWS:
    - Delete all cloud access rules targeting AWS from existing workload [identities](/reference/identity). This will delete any associated roles.
    - Delete the cloud account.
    - Your AWS administrator will need to remove the `cpln-connector` policy and the `cpln-ORG_NAME` role.


### disconnecting-azure
**Path**: `guides/cloud-account/disconnecting-azure.mdx`

- Removing an Azure Cloud Account for Azure SDK

  - If you no longer require Control Plane to create identities targeting Azure:

    - Delete all cloud access rules targeting Azure from existing workload [identities](/reference/identity). This will delete any associated app registrations.
    - Delete the cloud account.
    - Delete the [azure secret](/reference/secret#azure-sdk) that was mapped to the cloud account (named: CLOUD_ACCOUNT-access).
    - Your Azure administrator will need to delete the Service Principal from Azure by running the following Azure CLI command:

    ```bash
    az ad sp delete --id http://cpln-ORG_NAME
    ```


- Removing an Azure Cloud Account for Azure Connector

  - If you no longer require Control Plane to create identities targeting Azure:

    - Delete all cloud access rules targeting Azure from existing workload [identities](/reference/identity). This will delete any user assigned identities.
    - Delete the cloud account.
    - Delete the [azure connector secret](/reference/secret#azure-connector) that was mapped to the cloud account (named: CLOUD_ACCOUNT-access) if it is not being used by another Cloud Account.
    - Your Azure administrator will need to delete the Function App from the Azure portal or by running the following Azure CLI command:

    ```bash
    az functionapp delete --name FUNCTION_APP_NAME --resource-group AZURE_RESOURCE_GROUP
    ```


### disconnecting-gcp
**Path**: `guides/cloud-account/disconnecting-gcp.mdx`

- Removing a GCP Cloud Account
  - If you no longer require Control Plane to create identities targeting GCP:
    - Delete all cloud access rules targeting GCP from existing workload [identities](/reference/identity). This will delete any associated service account.
    - Delete the cloud account.
    - Remove the Control Plane user from your GCP account.


## guides/configure-resources


### Centralized Metrics Management
**Path**: `guides/configure-resources/centralized-metrics-management.mdx`

---
title: Centralized Metrics Management
---

## Overview

To access metrics from multiple ORGs using a centralized Grafana, it is necessary to add a data source for each [Org](/reference/org). This method is also applicable for integrating external Prometheus data sources with Control Plane's Grafana, enabling centralized metrics management.

In this guide, we will demonstrate adding the Prometheus data source from `org-2` to the Grafana instance of `org-1`. This integration will enable the observation of metrics from both `org-1` and `org-2` using the Grafana interface of `org-1`.

**Note**: Replace `org-1` and `org-2` with the actual names of your organizations.

### Follow the steps below

#### In `org-2`

1. Log in to `org-2`, and create a new Service Account named `grafana-data-source`.
2. Create a new **key** for the `grafana-data-source` Service Account that is just created and save it.
3. Create a **policy** named `grafana-data-source` that enables `readMetrics` for the above Service Account.

```yaml YAML
kind: policy
name: grafana-data-source
description: grafana-data-source
tags: {}
bindings:
  - permissions:
      - readMetrics
    principalLinks:
      - /org/org-2/serviceaccount/grafana-data-source
target: all
targetKind: org
```

#### In `org-1`

1. Log in to `org-1`, and navigate to Grafana by going to **Metrics** in the [Control Plane Console](https://console.cpln.io/console/).
2. Proceed to `Configuration` (available on the sidebar) > **Data Sources**.
3. Click on `Add new data source` and then select `Prometheus` as the type of the data source.
4. Complete the configuration:
   a. Name: Use a descriptive name. For example, the name of the target organization, `org-2`.
   b. URL: `https://metrics.cpln.io/metrics/org/org-2` (Note: Replace `org-2` with the actual organization's name).
   c. Add a custom HTTP Header for `authorization` with the value: `Bearer <YOUR-TOKEN-HERE>`. Replace `<YOUR-TOKEN-HERE>` with the token from the `grafana-data-source` created in the previous steps. Then, click **Save & Test**.

After these steps, you should be able to select the `org-2` data source when using the `Explore` feature in the `org-1` Grafana.

**Import Dashboard for Multiple Sources**

5. In your `org-1` Grafana, create a dashboard named `Multi Source Metrics Overview Cloud` to view metrics from various data sources. This is achieved by importing the dashboard.
   1. Download the dashboard JSON file from [this link](https://grafana.com/api/dashboards/20378/revisions/1/download).
   2. Import the downloaded dashboard into Grafana in `org-1`.

You can now select `org-2` as the data source in the `Multi Source Metrics Overview Cloud` dashboard you imported into `org-1`. Additional data sources, including those external or from other organizations, can be added by following the instructions in steps 1-4 under `org-1`.


### Configure a CDN
**Path**: `guides/configure-resources/configure-cdn.mdx`

---
title: Configure a CDN
---

Configuring a Content Delivery Network (CDN), such as [Cloudflare](https://cloudflare.com), protects and accelerates your [Workload](/reference/workload) running at Control Plane.

The configuration of various CDN providers is similar in concept. In this guide, you will find the steps on how to configure a CDN with [Cloudflare](#cloudflare-configuration-steps) and [Amazon CloudFront](#amazon-cloudfront-configuration-steps).

## Cloudflare Configuration Steps

### Prerequisites

- Review the [Configure a Domain](/guides/configure-domain) guide.
- An account at Cloudflare.
- Your Domain's DNS is hosted at Cloudflare.
- Your Workload is configured and in a `Ready` state.

### Step One - Domain Set Up and Certificate Generation at Cloudflare

**From the Cloudflare UI, perform the following:**

#### Domain Set Up

- From the DNS management page for your domain, add a new `CNAME` record.
  - For the `Name` field, enter the desired target subdomain.
  - For the `Target` field, enter the `Canonical Endpoint` URL from the [Workload's](/reference/workload) Info page.
  - Toggle on the `Proxied` switch.

#### Certificate Generation Set Up

- From the SSL/TLS page, select the `Full (strict)` radio box.
- Click on the `Origin Server` submenu link.
  - Create a new origin certificate for your domain with the following settings. This certificate will be added as a [TLS Secret](/reference/secret#tls) at Control Plane.
    - Select `Generate private key and CSR with Cloudflare`.
    - Select the Private key type: `RSA (2048)`.
    - The default list of hostnames shouldn't have to be changed and will contain the `*.DOMAIN` and `DOMAIN` hostnames.
    - Choose a long Certificate Validity such as 15 years.
    - **NOTE: It is your responsibility to ensure the certificate mapped to your domain at Control Plane is valid.**
    - Click `Create`. The next page will display the certificate and private key. You may save these as separate text files or leave the page open and copy/paste the values when creating the [TLS Secret](/reference/secret#tls) at Control Plane in the next step.

### Step Two - Certificate Set Up at Control Plane

- Using the certificate and private key from the previous step, create a new [TLS Secret](/reference/secret#tls) at Control Plane by performing the following:
  - Click `Secrets` from the left side menu.
  - Click the `New` button at the top.
  - Enter a `Name` for the secret and select the secret type `TLS`.
  - Either upload or paste the respective certificate and private key file in the proper textbox. The TLS Chain can be left empty since this certificate is self-signed.
  - Click `Create`. This secret will be used when configuring your domain in the next step.

### Step Three - Domain Set Up at Control Plane(#step-3)

Follow the steps below to configure your Domain at Control Plane.

**Note: If a subdomain is being configured, the APEX domain will need to be [verified](/guides/configure-domain#step-one-apex-domain-verification).**

- Click `Domains` from the left side menu.
- Click the `New` button at the top.
- Enter the `Fully Qualified Domain Name (FQDN)` of your Domain.
- Click `Next (Spec)`.
- Select `CNAME` for the `DNS Mode`.
- Select and configure the desired `Routing Mode`.
- Toggle on the `Configure TLS` switch.
- Toggle on the `Use Custom Server Certificate` and select the [TLS Secret](/reference/secret#tls) created in the step above.
- Click `Next (DNS)`.
- This page will display any DNS records that are required to be added for your domain. After adding the records, it will take a few minutes to propagate. Click the checkbox and click `Create`.

<Note>
After following the steps above, it will take a few minutes for the updates to propagate throughout the Internet.

Once fully configured, your Workload will be accessible, via the CDN, using the subdomain configured in the first step.

</Note>

## Amazon CloudFront Configuration Steps

### Prerequisites

- An AWS account.
- Access to edit DNS setting for your Domain.
- Your Workload is configured and in a `Ready` state.

### Step One - Request a public certificate

Request a public certificate with [AWS Certificate Manager (ACM)](https://us-east-1.console.aws.amazon.com/acm/home?region=us-east-1#/certificates/request) in `N. Virginia` region using the setting below.

1. A public TLS certificate is required for your domain. Use the following settings:
   - Domain Names: `subdomain.mydomain.com` or `*.mydomain.com`
   - Validation Method: `DNS Validation`
   - Key Algorithm: `RSA 2048`

<Note>The certificate must be in the US East (N. Virginia) Region (us-east-1).</Note>

2. Access the newly created certificate on the [ACM](https://us-east-1.console.aws.amazon.com/acm/home?region=us-east-1#/certificates/list). Validate the certificate by creating the records in your DNS service as described.

<Frame>
  <img src="/public/images/guides/configure-resources/configure-cdn/ssl_validation_screenshot.png" />
</Frame>

### Step Two - Create CloudFront distribution

1. Go to [CloudFront distributions page](https://us-east-1.console.aws.amazon.com/cloudfront/v4/home#/distributions) and click on `Create Distribution`
2. Configure the `Origin Domain` to the public endpoint of your workload. Use one of the following methods, depending on whether you are using a [**BYOK location**](/byok/overview) or a **managed locations (standard)**:

   - For **managed locations (standard)** only:
     Use the `Canonical Endpoint` URL from the [Workload's Info page](/reference/workload) as `Origin Domain`, formatted as follows: `cloudfront-httpbin-0ac6x9wrgpj00.cpln.app`.

     <Frame>
       <img src="/public/images/guides/configure-resources/configure-cdn/canonical-endpoint.png" />
     </Frame>

   - For [**BYOK locations**](/byok/overview) only:
     Locate the public endpoint on your Workload's _Deployments_ page. Use this address as the `Origin Domain` value in CloudFront, formatted as follows: `nginx3-7mhf5d3qcsrqt.eksctl-byok-aws-west2.controlplane.us`.

     <Frame>
       <img src="/public/images/guides/configure-resources/configure-cdn/byok-ep.png" />
     </Frame>

3. Edit the `Alternate domain name` for your domain. In the format: `subdomain.mydomain.com`.  
   Then select the `Custom SSL certificate` created in _Step one_ from the list.

   <Frame>
     <img src="/public/images/guides/configure-resources/configure-cdn/cname.png" />
   </Frame>

4. You must select `Cache policy` and complete the rest of the configuration as needed.
5. Click on `Create distribution` and wait for a few minutes to changes to apply.

By now, you should have CloudFront distribution ready.

<Frame>
  <img src="/public/images/guides/configure-resources/configure-cdn/distribution.png" />
</Frame>

### Step Three - Configure DNS

Create a CNAME record in your DNS service (such as Route53), that will match the _Alternate domain name_ in CloudFront distribution created in Step two:

- Type: CNAME
- Name: nginx3
- Data: dddddddd.cloudfront.net

### Step Four - Configuring Firewall to restrict access via CloudFront

- In order to ensure that it's not possible to directly access the workload's endpoint without going through the CloudFront CDN first, configure the firewall settings for the workload to allow ingress for CloudFront [list of ip ranges](https://d7uri8nf7uskq.cloudfront.net/tools/list-cloudfront-ips). You can refer to [this example workload YAML file](https://cpln-public-bucket.s3.amazonaws.com/nginx3-workload-cloudfront-example.yaml) and copy the CIDR range directly from this manifest.

- **BYOK Only**: If you have created inbound rules on the Security Group of the Load Balancers, either directly or using the Actuator configuration [INGRESS_FIREWALL_CIDR_LIST](/byok/settings/actuator), you will need to update the Security Group configuration with CloudFront CIDR list range to enable CloudFront access to the workloads. **Important**: To support this setting, ensure that your quota for `Inbound or outbound rules per security group` under `Amazon Virtual Private Cloud (Amazon VPC)` values for at least **530** rules. Visit [Service Quotas](https://console.aws.amazon.com/servicequotas/home/dashboard) in the AWS console for your region to request a quota increase if necessary.


### Rate Limiting
**Path**: `guides/configure-resources/rate-limiting.mdx`

---
title: Rate Limiting
---

Rate limiting can be added to [Workloads](/reference/workload) by configuring an endpoint which serves the Envoy Rate Limit project. This endpoint receives a rate limit request from a configured Workload and decides if the request should be limited.

Follow the steps below to configure your [Workload](/reference/workload) with a
rate limiting policy.

## Prerequisites

- An existing [Workload](/reference/workload) that requires rate limiting.
- Review the Rate Limiting project's [README](https://github.com/envoyproxy/ratelimit).

## Configuration Steps

Envoy's Rate Limit project is deployed as a [Workload](/reference/workload) at Control Plane and requires a local Redis [Workload](/reference/workload).

Follow the steps below to download and apply a YAML manifiest file which will deploy, create, and configure:

- The Rate Limit [Workload](/reference/workload).
- The Redis [Workload](/reference/workload).
- An [opaque secret](/reference/secret#opaque) containing the rate limiting definition.
- A [Workload Identity](/reference/identity) for the Rate Limit Workload.
- A [Policy](/reference/policy) allowing the Rate Limit Workload to reveal the secret.

### Step One - Configure the Rate Limiting Workload

- Download and review the [YAML manifest file](https://raw.githubusercontent.com/controlplane-com/examples/main/examples/rate-limiting/rate-limiting.yaml) that will be applied.
- Using the UI or [CLI](/reference/cli):
  - Create a [GVC](/reference/gvc) named `ratelimit`. If you choose a different GVC name, update the YAML manifest file accordingly.
  - Within that GVC, use the [cpln apply](/guides/cpln-apply) command to deploy the manifest file.

<Tip>

The latest `envoyproxy/ratelimit` deployment can be obtained [here](https://hub.docker.com/r/envoyproxy/ratelimit/tags?page=1&ordering=last_updated).

The downloaded YAML manifest file uses the image `envoyproxy/ratelimit:5b6e65da`. If there is a newer tag, it can be substituted in the YAML file before executing the `cpln apply` command.

</Tip>

### Step Two - Customize the Config File

The rate limit config file is stored as an [opaque secret](/reference/secret#opaque) named `ratelimit-config` that was created when applying the YAML manifest file.

The configuration that was deployed with the manifest file sets a limit of 10 requests per minute for any request that contains an `authorization` header (see sample config below).

To adjust the rate limit per your requirments, use the UI or CLI to edit the `ratelimit-config` secret using the pattern referenced [here](https://github.com/envoyproxy/ratelimit#configuration).

#### Sample Config

```yaml YAML
domain: cpln
descriptors:
  - key: authorization
    rate_limit:
      unit: minute
      requests_per_unit: 10
```

<Note>

After saving the updated secret, it's recommended to perform a `Force Redeploy` of the `ratelimit` Workload to reload the config file.

</Note>

### Step Three - Configure Rate Limiting on a Workload

Add the following [tags](/reference/misc#tags) to enable rate limiting on the desired [Workload](/reference/workload).

- `cpln/rateLimitAddress`
  - **Required**
  - Use the `Global Endpoint` of the Rate Limiting [Workload](/reference/workload) that was configured in [step one](#step-one-configure-the-rate-limiting-workload). This endpoint
    can be obtained by browsing to the `Info` page of the `ratelimit` Workload. Do not include the `https://` scheme.
- `cpln/rateLimitScheme`
  - Optional.
  - Default is: `https:`.
- `cpln/rateLimitPort`
  - Optional.
  - Default is: `443`.
- `cpln/rateLimitDomain`
  - Optional.
  - Default is: `cpln`.
  - This value corresponds to the domain entry within the config file that was configured in [step 2](#step-two-customize-the-config-file).
- `cpln/rateLimitDescriptors`
  - Optional. Default is: `authorization`.
  - Allowed values: `authorization`, `host`, `port`.
  - This value corresponds to the descriptor entry within the config file that was configured in [step 2](#step-two-customize-the-config-file).

After saving these tags and the Workload has deployed successfuly, the rate limits defined within the config file will be enforced. If a client hits the limit, an HTTP 429 (Too Many Requests) response will be returned.


### Resource Protection
**Path**: `guides/configure-resources/resource-protection.mdx`

---
title: Resource Protection
---

The Control Plane platform will prevent the deletion of resources with the `cpln/protected` [tag](/reference/misc#tags) set to `true`.

This mechanism gives you an added layer of protection against accidental deletion of critical resources such as workloads, secrets, etc.

To delete a resource with a `cpln/protected` tag set to `true`, change the value from `true` or remove the tag. Only then will the platform allow you to proceed with the deletion.

## Using the Console UI

- Add Tag

  From nearly any resource within the Console UI, follow these steps to add the protected tag:

  1. Click the `Tags` link.
  2. Click the `Add` button.
  3. In the blank row that was added:

     - Enter `cpln/protected` for the `Key`.
     - Enter `true` for the `Value`.

  4. Click `Save`.

- Remove Tag

  From nearly any resource within the Console UI, follow these steps to remove the protected tag:

  1. Click the `Tags` link.
  2. Click the `Remove` link corresponding to the row that contains the `cpln/protected` tag.
  3. Click `Save`.

## Using the CLI

Nearly every CLI command has the `tag` subcommand.

Follow the examples below that target a workload to add and remove the `cpln/protected` tag. Substitute `workload` with the target resource.

<CodeGroup>

```text Add tag
cpln workload tag WORKLOAD_NAME --tag cpln/protected=true --gvc GVC_NAME --org ORG_NAME
```

```text Remove Tag
cpln workload tag WORKLOAD_NAME --remove cpln/protected --gvc GVC_NAME --org ORG_NAME
```

</CodeGroup>


### Service-to-Service Calls
**Path**: `guides/configure-resources/service-to-service.mdx`

---
title: Service-to-Service Calls
---

## Overview

The [internal firewall](/reference/workload#internal) rules for a [workload](/reference/workload) can be configured to allow inbound access from other [workloads](/reference/workload) in the same [org](/reference/org).

Allowing this type of access decreases the latency of your [workloads](/reference/workload) by making the request in the most direct path possible and increases security by validating the client certificate of the remote workload. Calling the endpoint of a service follows a specific URL [syntax](#service-endpoint-syntax) that is comprised of the [workload](/reference/workload) name and [GVC](/reference/gvc) name.

## Prerequisites

- [Permissions](/reference/policy#permissions) to edit a [workload](/reference/workload).
- Optional:
  - [CLI](/reference/cli) installed.

## Internal Firewall

The [internal firewall](/reference/workload#internal) settings are part of the firewall options of a [workload](/reference/workload) and can be set to one of the following types:

- `None`
  - No access is allowed to this [workload](/reference/workload) from other [workloads](/reference/workload).
- `Same GVC`
  - [Workloads](/reference/workload) running in the same [GVC](/reference/gvc) are allowed to access this [workload](/reference/workload).
- `Same Org`
  - [Workloads](/reference/workload) running in the same org are allowed to access this [workload](/reference/workload).
- `Specific Workloads`
  - Only specific [workloads](/reference/workload) listed in `inboundAllowWorkload`, including workloads from other GVC's,
    are allowed access to this workload.
  - With this rule selected, the [workload](/reference/workload) can be set to allow replicas of itself to access itself.
    Calling a
    workload using `localhost` doesn't require this setting and will force the request to
    the current workload. By using this setting and sending the request using the [service endpoint syntax](#service-endpoint-syntax),
    the request will be routed to all replicas instead of only the local one.

Only the ports listed in the workload containers array will be made accessible to other workloads.

<Note>Internal workload to workload traffic that spans GVC's may also span locations and will incur egress charges.</Note>

## Service Endpoint Syntax

Once inbound access has been allowed on a [workload](/reference/workload), the following syntax is used when calling the [workload](/reference/workload) from another [workload](/reference/workload):

```text Syntax
http://WORKLOAD_NAME.GVC_NAME.cpln.local[:PORT]
```

- The `PORT` is optional, the first port listed in the target workloads container array will be used as the default port for `http` requests.
- Internal communications work with `GRCP`, `HTTP`, `HTTP2`, and `TCP`.
- Requests are initiated using plain text communication. A sidecar service will initiate TLS on behalf of the workload.
- Control Plane enforces Mutual-TLS for all internal workload-to-workload communications.
- Headers may optionally be used on the receiving workload to verify that the communication was encrypted.
- Only the ports listed in the workload containers array will be made accessible to other workloads.

## Setup Internal Firewall using the UI Console

To configure the internal firewall rules using the console:

1. Click `Workloads` in the left menu and click the [workload](/reference/workload) to be configured.
2. Click `Firewall Config` and scroll to the `Internal` section.
3. Click the `Inbound Allow Type` dropdown and select the inbound access for this [workload](/reference/workload).
4. Click the `Save` button at the bottom of the page.

After clicking save, the rule will be enforced within a minute and a new deployment of the [workload](/reference/workload) will be queued.

## Setup Internal Firewall using the CLI

To modify the internal firewall rule with the CLI, use the [workload edit](/reference/cli#workload-edit) command.

1. Running the following command will open the default text editor and show the metadata (in YAML) for the [workload](/reference/workload):

```bash
cpln workload edit WORKLOAD_NAME --org ORG_NAME --gvc GVC_NAME
```

2. Scroll down to the section `internal` under the `firewallConfig` section
3. Update the `inboundAllowType` property to one of the following (case sensitive) values:
   - `none`
   - `same-gvc`
   - `same-org`
   - `workload-list`

If `workload-list` is selected, update the `inboundAllowWorkload` property with the names of the allowed workloads using the format:

```text Format
/org/ORG_NAME/gvc/GVC_NAME/workload/WORKLOAD_NAME
```

<Note>

If you want to allow the [workload](/reference/workload) the ability to call itself, the `WORKLOAD_NAME` will be the same as the name of the [workload](/reference/workload).

</Note>

4. Save the file. If the save is successful, the new rules will be applied within a minute and a deployment of the [workload](/reference/workload) will be queued.

## Quick Start

A quick start demonstrating service-to-service calls is available [here](/quickstart/quick-start-5-service-to-service-calls).


## guides/create-resources


### Create a Workload
**Path**: `guides/create-resources/create-workload.mdx`

---
title: Create a Workload
---

## Overview

Follow the steps below to create a [workload](/reference/workload) within your [GVC](/reference/gvc).

## Prerequisites

- Review the [workload](/reference/workload) reference page
- [Permissions](/reference/policy#permissions) to create a [workload](/reference/workload)
- Optional:
  - Install the [CLI](/reference/cli)

## Create using the UI Console

Follow the steps below to create a workload (requires a [GVC](/reference/gvc)):

1.  Create a new workload using one of the following methods:
    - Clicking `Workloads` in the left menu and click `New`, or
    - Click the `Create` dropdown in the upper right corner and select `Workload`
2.  Enter a unique name and optional description. Click `Next (Container 1)`.
3.  Set up your container. Browse through each tab and configure as required. Click [here](/reference/workload#containers) for additional details. Click `Next (/reference/identity)`.
4.  Select from the list of available [identities](/reference/identity). If you do not have any [identities](/reference/identity) defined, the default (No Identity), will be the only option. Click `Next (Options)`.
5.  Configure the options for the workload. Click [here](/reference/workload#options) for additional details. Click `Next (Firewall)`.
6.  Configure the firewall options for the workload. Click [here](/reference/workload#firewall-configuration) for additional details. Click `Next (Tags)`.

<Tip>

Depending on the requirements of your container, the firewall options can be configured to allow either or both inbound and outbound requests.

If your container will be accepting requests from the Internet, verify that the `All Inbound Requests Allowed` switch is turned on or enter the expected CIDR's.

If your container requires Internet access, verify that the `All Outbound Requests Allowed` switch is turned on or enter the expected CIDR's or hostnames in their respective textboxes.

</Tip>

7.  Enter any optional [tags](/reference/misc#tags). Click `Create`.
8.  Your workload has been successfully created and the workload summary page will be shown. After a few moments, if the image was successfully deployed, the `Workload Health` status will show `Healthy`. The `Global Endpoint` link can be clicked and will open in a new browser.

## Create using the CLI

Refer to the [workload create](/reference/cli#workload-create) command for details and examples on how to create a [workload](/reference/workload) using the CLI.


## guides/domain


### Configure a Domain
**Path**: `guides/domain/configure-a-domain.mdx`

---
title: Configure a Domain
---

## Overview

Follow the steps below to configure a custom [Domain](/reference/domain) within your [Org](/reference/org).

## Prerequisites

- Review the [Domain](/reference/domain) reference page.
- [Permissions](/reference/policy#permissions) to configure a [Domain](/reference/domain).
- Access to a domain name and the ability to update its DNS records.
- Optional:
  - Install the [CLI](/reference/cli).

## Step One - APEX Domain Verification

Follow step one in the [domain quick start](/quickstart/quick-start-2-custom-domain#step-one-register-your-apex-domain) to create and verify the apex domain name using the Console UI.

The CLI can also be used to create the apex domain for verification and routing configuration. See the [sample manifiest files](#apex-verification-only) below.

Refer to the [Domain Verification](/reference/domain#domain-verification) section within the
Domain reference page for additional details.

## Step Two - Create Domain

A [Domain](/reference/domain) can be created using the following methods:

- [Console UI](#create-using-the-ui-console)
- [CLI](#create-using-the-cli)
- [Terraform Provider](https://registry.terraform.io/providers/controlplane-com/cpln/latest/docs/resources/domain)

### Create using the UI Console

Follow step two in the [domain quick start](/quickstart/quick-start-2-custom-domain#step-two-review-routing-modes) for detailed instruction on how to create and configure your domain name using the console UI.

### Create using the CLI

A Domain can be created / updated using the [CLI's apply](/guides/cpln-apply) command.

Below are a few sample Domain manifests (in YAML) that can be used as input to the [CLI's apply](/guides/cpln-apply) command.

After updating and saving the manifests to a local file, execute the following command to apply:

```
cpln apply -f FILE_NAME.yaml --org ORG_NAME
```

<Warning>
  Before using the [CLI's apply](/guides/cpln-apply) command, the [TXT DNS records](#required-dns-records) must exist and be propagated
  **only** for the apex domain. The DNS entries for the subdomain will not be verified on creation. Routing and certificate generation will
  not occur until the records have been added, propagated, and the target workload is in a ready state and can serve requests.
</Warning>

#### APEX Verification Only

Configure Domain for APEX Verification

- Substitute `example.com` with your domain.

```yaml YAML
kind: domain
name: example.com
description: example.com
spec:
  dnsMode: cname
```

#### APEX Verification and Path Based Routing

Configure Domain for APEX Verification and Path Based Routing.

- Substitute `example.com` with your domain, GVC_NAME, and WORKLOAD_NAME
- The example YAML manifest below assumes there is a workload named WORKLOAD_NAME serving requests on port 4200 in the GVC named GVC_NAME.

```yaml YAML
kind: domain
name: example.com
description: example.com
tags: {}
spec:
  acceptAllHosts: false
  dnsMode: cname
  ports:
    - number: 443
      protocol: http2
      routes:
        - port: 4200
          prefix: /
          workloadLink: //gvc/GVC_NAME/workload/WORKLOAD_NAME
```

#### APEX Verification and Subdomain Based Routing

Configure Domain for APEX Verification and Subdomain Based Routing.

- Substitute `example.com` with your domain, GVC_NAME, and TLS_SECRET
- Notice that the `dnsMode` is set to `cname` and a TLS secret is required.

```yaml YAML
kind: domain
name: example.com
description: example.com
tags: {}
spec:
  dnsMode: cname
  gvcLink: //gvc/GVC_NAME
  ports:
    - number: 443
      tls:
        serverCertificate:
          secretLink: //secret/TLS_SECRET
```

#### Subdomain and Path Based Routing

Configure a subdomain for path based routing.

- Substitute `sub.example.com` with your domain, GVC_NAME, and WORKLOAD_NAME.
- The example YAML manifest below assumes there is a workload named WORKLOAD_NAME in the GVC named GVC_NAME.

```yaml YAML
kind: domain
name: sub.example.com
description: sub.example.com
tags: {}
  spec:
  dnsMode: cname
  ports:
    - routes:
        - prefix: /
          workloadLink: //gvc/GVC_NAME/workload/WORKLOAD_NAME
```

#### Subdomain and Subdomain Based Routing

Configure a subdomain for subdomain based routing.

- Substitute `sub.example.com` with your domain and GVC_NAME.
- All workloads within the GVC will have endpoints created with the subdomain in the format: `https://WORKLOAD_NAME.sub.example.com/`.

```
kind: domain
name: sub.example.com
description: sub.example.com
tags: {}
spec:
  dnsMode: ns
  gvcLink: //gvc/GVC_NAME
```

#### Setting Custom Headers

Set custom headers on any domain route.

- Substitute `sub.example.com` with your domain, GVC_NAME, and WORKLOAD_NAME.
- Substitute HEADER with your header, VALUE with your value. You may add headers as well.
- The example YAML manifest below assumes there is a workload named WORKLOAD_NAME in the GVC named GVC_NAME.

```yaml YAML
kind: domain
name: sub.example.com
description: sub.example.com
tags: {}
  spec:
  dnsMode: cname
  ports:
    - routes:
        - prefix: /
          workloadLink: //gvc/GVC_NAME/workload/WORKLOAD_NAME
          headers: 
            request:
              set:
                HEADER: VALUE
```

#### Complete Domain YAML Manifest

Use the manifest YAML templates below to create a Domain per your requirements.

<Note>
The examples above use the minimum properties required to create/update a domain based on your requirements.

The complete YAML manifest templates below contain both the required and optional properties.

**Notes:**

- `dnsMode` can either be `cname` (for path based) or `ns` (for subdomain based). For an apex domain, it must be `cname`.
- `acceptAllHosts` will only be active if the dedicated load balancer is enabled on the GVC.
- For the routes configued for path based routing, the `hostPrefix` will only be active if the dedicated load balancer is enabled on the GVC **and** the `acceptAllHosts` propert is set to `true`.

</Note>

- Path Based Routing

```yaml YAML
kind: domain
name: sub.domain.com
description: sub.domain.com
tags: {}
spec:
  acceptAllHosts: false
  dnsMode: cname
  ports:
    - cors:
        allowCredentials: true
        allowHeaders:
          - '*'
        allowMethods:
          - '*'
        allowOrigins:
          - exact: '*'
        exposeHeaders:
          - '*'
        maxAge: 24h
      number: 443
      protocol: http2
      routes:
        - hostPrefix: example
          port: 4200
          prefix: /example
          replacePrefix: /v1/example
          workloadLink: //gvc/GVC_NAME/workload/WORKLOAD_NAME_01
          headers:
            request:
              set:
                EXAMPLE_HEADER: EXAMPLE_VALUE
        - regex: /user/.*/profile
          workloadLink: //gvc/GVC_NAME/workload/WORKLOAD_NAME_02
        - prefix: /
          workloadLink: //gvc/GVC_NAME/workload/WORKLOAD_NAME_03
      tls:
        cipherSuites:
          - ECDHE-ECDSA-AES256-GCM-SHA384
          - ECDHE-ECDSA-CHACHA20-POLY1305
          - ECDHE-ECDSA-AES128-GCM-SHA256
          - ECDHE-RSA-AES256-GCM-SHA384
          - ECDHE-RSA-CHACHA20-POLY1305
          - ECDHE-RSA-AES128-GCM-SHA256
          - AES256-GCM-SHA384
          - AES128-GCM-SHA256
        clientCertificate:
          secretLink: //secret/TLS_SECRET_CLIENT_CERTIFICATE
        minProtocolVersion: TLSV1_2
        serverCertificate:
          secretLink: //secret/TLS_SECRET_SERVER_CERTIFICATE
```

- Subdomain Based Routing

```yaml YAML
kind: domain
name: sub.example.com
description: sub.example.com
tags: {}
spec:
  acceptAllHosts: true
  dnsMode: ns
  gvcLink: //gvc/GVC_NAME
  ports:
    - cors:
        allowCredentials: false
        allowHeaders:
          - '*'
        allowMethods:
          - '*'
        allowOrigins:
          - exact: '*'
        exposeHeaders:
          - '*'
        maxAge: 24h
      number: 443
      protocol: http2
      tls:
        cipherSuites:
          - ECDHE-ECDSA-AES256-GCM-SHA384
          - ECDHE-ECDSA-CHACHA20-POLY1305
          - ECDHE-ECDSA-AES128-GCM-SHA256
          - ECDHE-RSA-AES256-GCM-SHA384
          - ECDHE-RSA-CHACHA20-POLY1305
          - ECDHE-RSA-AES128-GCM-SHA256
          - AES256-GCM-SHA384
          - AES128-GCM-SHA256
        clientCertificate:
          secretLink: //secret/TLS_SECRET_CLIENT_CERTIFICATE
        minProtocolVersion: TLSV1_2
        serverCertificate:
          secretLink: //secret/TLS_SECRET_SERVER_CERTIFICATE
```

## Required DNS Records

To successfully add a [Domain](/reference/domain) to your [Org](/reference/org), DNS records are required to be added.

The values in the sample below might not correspond to the entries necessary for your domain. Use the values that are presented
during the creation of the domain.

When created the domain with the console UI, the final step will display the DNS records that need to be added.

These records will need to be sent to the network administrator in charge of handling the domain's DNS configuration.

**Examples:**

<Accordion title="Apex Domain - CNAME Mode Only">

| RECORD/HOST | TYPE | TTL | VALUE       |
| :---------- | :--- | :-- | :---------- |
| \_cpln      | TXT  | 600 | ORG_ID_GUID |

</Accordion>

<Accordion title="Subdomain (e.g., sample.domain.com) - CNAME Mode (Path Based Routing)">

| RECORD/HOST   | TYPE  | TTL | VALUE              |
| :------------ | :---- | :-- | :----------------- |
| \_cpln-sample | TXT   | 600 | ORG_ID_GUID        |
| sample        | CNAME | 600 | GVC_ALIAS.cpln.app |

**Note:** The GVC_ALIAS can be obtain from the console UI by clicking on the GVC and it will be displayed on the `Info` page. Using the CLI, executing the command `cpln gvc get GVC_NAME` will output the alias.

</Accordion>

<Accordion title="Subdomain (e.g., sample.domain.com) - NS Mode (Subdomain Based Routing)">

| RECORD/HOST   | TYPE | TTL  | VALUE          |
| :------------ | :--- | :--- | :------------- |
| \_cpln-sample | TXT  | 600  | ORG_ID_GUID    |
| sample        | NS   | 1800 | ns1.cpln.cloud |
| sample        | NS   | 1800 | ns2.cpln.cloud |
| sample        | NS   | 1800 | ns1.cpln.live  |
| sample        | NS   | 1800 | ns2.cpln.live  |

</Accordion>

<Note>

In the examples above, the TXT record for the subdomain is **only** required if the domain is created in an Org that doesn't contain the apex domain.
ORG_ID_GUID should be set to the`id` value of the Org object.
The record `_cpln-sample` is generated from the last segment of the domain, `_cpln-${lastSegment}`.
In the case of an apex domain, the TXT record to add is `_cpln`.

The TXT record can include the ID of multiple Orgs in cases
where the domain is allowed to be used in multiple Orgs.

The verification record can exist at any segment of the Domain.

For example, the subdomain, two.sample.domain.com can be verified using **any** of the following TXT records:

- \_cpln-two.sample.domain.com
- \_cpln-sample.domain.com
- \_cpln.domain.com

</Note>

<Tip>

To obtain the ORG_ID_GUID, run the CLI command: `cpln org get ORG_NAME --output json`.

The output of the command will display all the properties of the [Org](/reference/org) object. Use the value of the `id` key for the TXT value.

</Tip>

<Note>

After the DNS records have been created, the propagation time for the changes to take effect depends on the cache setting of your domain's DNS Start of Authority (SOA) record.

Once the records are fully propagated, any DNS changes to your subdomain will be reflected within a few seconds.

</Note>

## Configure a Content Delivery Network (CDN) Domain

Refer to the [Configure a CDN](/guides/configure-cdn) guide.

## Advanced Mode

When editing a domain within the console UI, the following options are available when clicking `Advanced Mode`:

### Dedicated Load Balancing

Refer to the following pages for details on enabling dedicated load balancing:

- Configuring the [GVC for dedicated load balancing.](/reference/gvc#dedicated-load-balancer)
- After enabling, these [additional domain configuration options](/reference/domain#dedicated-load-balancer-options) will be available for configuration.

### Additional Setting

- The [accept all hosts](/reference/domain#accept-all-hosts) setting (`acceptAllHosts` in the above example manifest) can be enabled when dedicated load balancing is enabled.
- [Add additional ports](/reference/domain#external-port) configured with other supported protocols (TCP, etc.) when using a dedicated load balancer.

  - For each port, configure [TLS Settings](/reference/domain#tls-settings) which includes setting the TLS version, forwarding client certificates, using custom server certificates, and allowed cipher suites.

  - For each port, configure custom [CORS](/reference/domain#cors-settings) settings.

- When using Path Based Routing:
  - Additional [routes](/reference/domain#path-based-routing) can be added with unique prefixes and, optionally, a replace prefix.
  - When dedicated load balancing is enabled, a [host prefix](/reference/domain#host-prefix) (`hostPrefix` in the above example manifest) can be optionally defined.


## guides/gitops


### Environment Promotion
**Path**: `guides/gitops/environment-promotion.mdx`

---
title: Environment Promotion
---

As a best practice, each deployment environment (development, staging, production, etc.) should map to a Control Plane [Org](/reference/org).

The primary benefit of having each environment under a separate [Org](/reference/org) is that definitions of different [GVCs](/reference/gvc) and [workloads](/reference/workload) can be applied to different [Orgs](/reference/org) without the need to include an environment name in any object.

For example, in the development [Org](/reference/org), you could apply nearly the same YAML manifest files (used by [cpln apply](/guides/cpln-apply)) as the production [Org](/reference/org) with different content for your secrets.

During the promotion process, the [image](/reference/image) that was built for development can be referred to by other [workloads](/reference/workload) in the same [Org](/reference/org) and across [Orgs](/reference/org). This is a great time saver for lengthy build processes.

## Promotion using GitHub Actions

By leveraging the functionality of [GitHub Actions](https://docs.github.com/en/actions), promoting code changes from one environment to another is as easy as committing/pushing your code and opening/merging pull requests.

This [example](https://github.com/controlplane-com/promotion-demo) project contains three GitHub Actions (in the `./.github/workflows` directory) that perform the following:

1. On a pull request (or updates to an existing pull request) to the `main` branch, the application is containerized and pushed to the dev [Org's](/reference/org) private [image registry](/reference/image). The [GVC](/reference/gvc) and `Review Workload` is created/updated by applying the YAML contents of the files `./cpln/cpln-gvc.yaml` and `./cpln/cpln-workload.yaml`. The name of the `Review Workload` will be prefixed by the name of the branch that created the pull request.
2. When a pull request is accepted and the code is merged to the `main` branch, a `dev` [workload](/reference/workload) is updated (or created if it doesn't exists) in the dev [Org](/reference/org) by applying the same files as step 1, except that the [workload](/reference/workload) name is prefixed with `dev`. This allows the application to be reviewed and tested before being pushed to the production [Org](/reference/org).
3. The promotion to the `stage` and `prod` environment is accomplished by manually executing the `Deploy-To-Stage-or-Prod` workflow and selecting the target environment. The target [GVC](/reference/gvc) and [Workload](/reference/workload) in the production [Org](/reference/org) is updated (or created if it doesn't exists) by applying the YAML contents of the files `./cpln/cpln-gvc-prod.yaml` and `./cpln/cpln-workload.yaml`. The main difference between the two [GVC](/reference/gvc) files is that the `prod` version contains the `Pull Secret` that is needed to pull the [image](/reference/image) from the dev [Org](/reference/org) and the `stage` and `prod` [workloads](/reference/workload) refers to the [image](/reference/image) that was pushed to the development [Org](/reference/org).

## Review Workload

The above example demonstrates the concept of a **Review Workload**. This [workload](/reference/workload) allows for review and testing of the application before being promoted to upstream [workloads](/reference/workload). The deployment of the **Review Workload** occurs when a pull request from a feature branch to the `main` branch is opened. The application will only be promoted to the `dev` [workload](/reference/workload) if the pull request is closed and merged.

## Permissions

To control which users have the ability to perform sensitive actions, such as merging a pull request, you can utilize the built-in capabilities of GitHub by creating a custom repository role.

Review these [instructions](https://docs.github.com/en/enterprise-cloud@latest/organizations/managing-peoples-access-to-your-organization-with-roles/managing-custom-repository-roles-for-an-organization) on how to create a role.

## Notes

- The example above demonstrates promoting code across four environments (review and development in one [Org](/reference/org), and staging and production in a separate [Org](/reference/org)). Of course, you can arrange each environment within its own [Org](/reference/org), or mix multiple environments within an [Org](/reference/org) as shown in the example. There is no limit to the number of [Orgs](/reference/org) / environments that can be created. This example can be adapted to suit your unique deployment requirements.
- For more complex applications, each environment's [GVC](/reference/gvc) / [workload](/reference/workload) should be configured with its own:

  - [Domain](/reference/domain)
  - [Pull Secrets](/reference/gvc#pull-secrets)
  - [Environment Variables](/reference/workload#environment-variables)


### CI/CD Examples
**Path**: `guides/gitops/overview.mdx`

---
title: CI/CD Examples
---

Below are CI/CD examples for [GitHub](https://github.com), [GitLab](https://gitlab.com), [BitBucket](https://bitbucket.org), and [CircleCI](https://circleci.com). The examples illustrate using pipelines to automate the build, test and deploy phases. Two examples per source control system are provided. One using [Terraform](https://registry.terraform.io/providers/controlplane-com/cpln/latest/docs) and the other using the [CLI](/reference/cli). The `README.md` in the examples provide instructions for using the respective pipeline. These examples are provided as a starting point and your own unique delivery and/or deployment requirements will dictate the steps needed in your situation.

## Terraform

Control Plane provides a Terraform plugin allowing you to build your Control Plane infrastructure declaratively. The following examples include the plugin installation instructions, containerizing and pushing an app to the org’s private [image registry](/reference/image) and a sample Terraform configuration file defining a [GVC](/reference/gvc) and a [workload](/reference/workload).

### Examples

- [GitHub](https://github.com/controlplane-com/github-actions-example-terraform)
- [GitLab](https://gitlab.com/controlplane-com/gitlab-pipeline-example-terraform)
- [Bitbucket](https://bitbucket.org/controlplane-com/bitbucket-pipeline-example-terraform)

<Note>

- The GitHub and Bitbucket example uses the [Terraform Cloud](https://app.terraform.io/) to store the state file.

- The GitLab example leverages their [managed Terraform state backend](https://docs.gitlab.com/ee/user/infrastructure/terraform_state.html) to store the state file.

</Note>

## CLI

The [CLI apply](/reference/cli#apply) command creates and updates Control Plane resources. The command can be used in a pipeline to manage the deployment of an application. It takes as an input a JSON or YAML file containing the properties of the resource to manage.

The command can accept a YAML file containing multiple resources. Each resource must be separated using `---`. If a resource has a reference to another resource (e.g., a [workload](/reference/workload) refers to a [GVC](/reference/gvc)), the referenced resource must be defined in its own file and processed in order.

If the name of an exisiting resource is changed, the `cpln apply` command will create a new resource. Any orphaned resources will need to be manually deleted.

The examples below include installation of the [CLI](/reference/cli), containerizing and pushing an application to the org's private repository. The examples contain two sample YAML files. One that manages a GVC, and one for a workload.

### Examples

- [GitHub](https://github.com/controlplane-com/github-actions-example-cli)
- [GitLab](https://gitlab.com/controlplane-com/gitlab-pipeline-example-cli)
- [Bitbucket](https://bitbucket.org/controlplane-com/bitbucket-pipeline-example-cli)
- [CircleCI](https://github.com/controlplane-com/circle-ci-pipeline-example-cli)
- [Google Cloud Build](https://github.com/controlplane-com/google-cloud-build-example-cli)

<Tip>

Samples of existing resources can be exported using the console or the CLI. These samples can assist when defining resources for your application.

Using the console, after selecting a resource, there will be an `Export` pull down button in the upper right corner. Select JSON or YAML to download the file.

Using the CLI's `get` command for each resource, the `-o` flag can output the resource as JSON or YAML.

For example: `cpln gvc get GVC_NAME -o yaml-slim --org ORG_NAME`

</Tip>


## guides/image


### copy-an-image
**Path**: `guides/image/copy-an-image.mdx`

## Copy an image

Using the [CLI](/reference/cli#image-copy), to copy an image from one org to another, execute the following command:

```
cpln image copy IMAGE_NAME:TAG --to-name IMAGE:TAG --to-org TARGET_ORG --to-profile TARGET_ORG_PROFILE
```


### Pull an image
**Path**: `guides/image/pull-an-image.mdx`

---
title: Pull an image
---

## Overview

Control Plane can pull container images from public or private Docker compatible repositories. [Pull secrets](/concepts/gvc#pull-secrets) are required when pulling images from private repositories or from another Control Plane [Org](/reference/org). When using the Control Plane built-in private [image registry](/reference/image) provided for your [Org](/reference/org), a [pull secret](/concepts/gvc#pull-secrets) is not required.

## Prerequisites

- The user following the steps below must be a member of the [superusers group](/reference/group#built-in-groups) or have the following [permissions](/reference/policy#permissions) within a [policy](/reference/policy):

  - [Secrets](/reference/secret)
    - create
    - use
  - [GVC](/reference/gvc)
    - edit
    - create (if a GVC needs to be created)
  - [Workload](/reference/workload)
    - edit
    - create (if a workload needs to be created)

- Optional:
  - [CLI](/reference/cli) installed

## Pull From Public Repositories

Use the following formats when pulling from a public repository:

1. Amazon ECR: `public.ecr.aws/REGISTRY-ALIAS/IMAGE_NAME:TAG`
2. Docker Hub: `IMAGE_NAME:TAG`
3. GCR: `gcr.io/REGISTRY/IMAGE_NAME:TAG`
4. GitHub Container Registry: `ghcr.io/OWNER/IMAGE_NAME:TAG`

## Pull From Private Repositories

### Step 1 - Create a Pull Secret

<Note>

- If pulling an image from the Control Plane private [image registry](/reference/image) provided for your [Org](/reference/org), skip to [step 3](#step-3-configure-workload).

- If pulling an image from another Control Plane [Org](/reference/org), continue with this step.

</Note>

1. Create a new pull secret by either:
   - Clicking `Secrets` in the left menu and clicking `New`, or
   - Using the `Create` dropdown in the upper right corner and selecting `Secret`.
2. Enter a unique name and an optional description.
3. From the `Secret Type` dropdown, select one of the following:
   - Create a new [Docker](/reference/secret#docker) secret for images stored at:
     - [Another Org's private repository at Control Plane](/reference/secret#control-plane).
     - [Docker Hub](/reference/secret#docker-hub).
     - [Azure Container Registry](/reference/secret#azure-container-registry).
     - [GitHub Container Registry](/reference/secret#github-container-registry).
   - Create a new [Amazon ECR](/reference/secret#ecr) secret for images stored at:
     - Amazon ECR.
   - Create a new [GCR](/reference/secret#google-cloud-platform-gcp) secret for images stored at:
     - GCR.
4. After entering the secret content, click `Next (Tags)`.
5. Enter any optional [tags](/reference/misc#tags). Click `Create`. The secret has been successfully created.

<Tip>

If you wish, the CLI can be used instead of the console.

See [secret create-docker](/reference/cli#secret-create-docker), [secret create-gcp](/reference/cli#secret-create-gcp)

</Tip>

### Step 2 - Associate with a GVC

1. Click `GVC` in the left menu and click the `Pull Secrets` link.
2. Click the `Add` button, select the secret created in [step 1](#step-1-create-a-pull-secret) and click `OK`.
3. Click `Save`. The secret is now associated with the [GVC](/reference/gvc) as a [Pull Secret](/concepts/gvc#pull-secrets).

### Step 3 - Configure Workload

1. Refer to the [Create a Workload](/guides/create-workload) guide and [workload](/reference/workload) reference page to create/manage your workload.
2. For the step where the image name is entered, follow the syntax below for the target registry:

   Registry:

   - Control Plane (Same Org): `/org/ORG_NAME/image/IMAGE_NAME:TAG` or `//image/IMAGE_NAME:TAG`
   - Control Plane (Cross Org): `ORG_NAME.registry.cpln.io/IMAGE_NAME:TAG`
   - Amazon ECR: `AWS_ACCOUNT_ID.dkr.ecr.REGION.amazonaws.com/IMAGE_NAME:TAG`
   - Azure CR: `REGISTRY.azurecr.io`
   - Docker: `IMAGE_NAME:TAG`
   - GCR: `gcr.io/IMAGE_NAME:TAG`
   - GitHub Container Registry: `ghcr.io/OWNER/IMAGE_NAME:TAG`

3. After creating or saving the [workload](/reference/workload), a new deployment will be queued. Click on the `Deployments` link to view the deployment status. If there is an error (i.e. authentication failed), it will be display under each deployment.


### Push an Image
**Path**: `guides/image/push-an-image.mdx`

---
title: Push an Image
---

## Overview

Follow the steps below to push an [image](/reference/image) to your [org's](/reference/org) private [image registry](/reference/image).

When configuring a [workload](/reference/workload) using the UI, the list of available [images](/reference/image) stored in your private [image registry](/reference/image) can be viewed by pressing `CTRL+I` on your keyboard.

An [image](/reference/image) can be pushed by using either [Docker](#push-docker), the [CLI](#push-cpln), or any Docker compatible client.

## Prerequisites

- Review the [image](/reference/image) reference page.
- [Minimum Policy](/reference/image#minimum-policy) to push an [image](/reference/image).
- Install [Docker](https://www.docker.com) and the [CLI](/reference/cli).

## Push using Docker

### Step 1 - Set up Docker authentication (Required)

Executing the command below will update the local Docker profile to use the CLI to authentication to your private registry when performing the push.

```bash
cpln image docker-login --org ORG_NAME
```

<Tip>

The cpln [profile](/guides/manage-profile) named `default` will be used by Docker when authenticating to the private registry before the pushing
the image. If a different profile is required for authentication, set the `CPLN_PROFILE` environment variable to the desired profile name.

</Tip>

### Step 2 - Build a new image using Docker and a Dockerfile (Optional)

If you have an existing [image](/reference/image), skip to [step 3](#step-3-tag-an-existing-image-optional).

Executing the command below will [containerize](https://docs.docker.com/engine/reference/commandline/build/) your application using the defined [Dockerfile](https://docs.docker.com/engine/reference/builder/). The [image](/reference/image) generated will be tagged in the format required to push it to your private registry.

```bash
docker build -t ORG_NAME.registry.cpln.io/IMAGE[:TAG] .
```

<Tip>

When building on a system architecture which is not amd64 (such as an M1/M2 Mac), use the following docker command:

`docker build --platform=linux/amd64 -t ORG_NAME.registry.cpln.io/IMAGE[:TAG] .`

</Tip>

### Step 3 - Tag an existing image (Optional)

Executing the command below will [tag](https://docs.docker.com/engine/reference/commandline/tag/) an existing local [image](/reference/image) in the format required to push it to your private registry.

**Required Image Name Format:** `ORG_NAME.registry.cpln.io/IMAGE[:TAG]`

If your [image](/reference/image) is already tagged in this format, skip to [step 4](#step-4-push-image-to-your-private-registry).

```bash
docker tag SOURCE_IMAGE[:TAG] ORG_NAME.registry.cpln.io/IMAGE[:TAG]
```

### Step 4 - Push image to your private registry

Executing the command below will authenticate and push the [image](/reference/image) to your private [image registry](/reference/image).

```bash
docker push ORG_NAME.registry.cpln.io/IMAGE[:TAG]
```

Depending on the size of the [image](/reference/image) and its dependencies, it might take a few minutes for the push to complete.

### Step 5 - Use image in a workload

Once an [image](/reference/image) has been successfully pushed to your [org's](/reference/org) private [image registry](/reference/image), it can be referred to by a [workload's container](/reference/workload#containers).

When setting up a [workload](/reference/workload), the list of available [images](/reference/image) stored in your private [image registry](/reference/image) can be viewed and selected by pressing `CTRL+I` on your keyboard.

## Push using cpln

Another method to push an [image](/reference/image) to your private registry is by using the CLI's [image build](/reference/cli#image-build) command.

### Option 1: Using buildpacks

Executing the command below will:

- Automatically build the [image](/reference/image) using [buildpacks](https://buildpacks.io/). No [Dockerfile](https://docs.docker.com/engine/reference/builder/) is required.
- Tag it with the required format.
- and push it to your private [image registry](/reference/image).

Buildpacks will crawl the application code and try to generate the [image](/reference/image). If it is unable to automatically generate the [image](/reference/image), you will need to use [option 2](#option-2-using-a-dockerfile).

```bash
cpln image build --name IMAGE:TAG --push --org ORG_NAME
```

### Option 2: Using a Dockerfile

Executing the command below is similar to [option 1](#option-1-using-buildpacks), but will build the [image](/reference/image) using Docker and will follow the instructions in the [Dockerfile](https://docs.docker.com/engine/reference/builder/).

```bash
cpln image build --dockerfile PATH_TO_DOCKERFILE/Dockerfile --name IMAGE:TAG --push --org ORG_NAME
```

## Authentication using a Service Account

In situations where the [CLI](/reference/cli) cannot be used, authentication to your private [image registry](/reference/image) is achieved by using a [Service Account](/guides/create-service-account).

Use the following parameters to authenticate using Docker or any Docker compatible client:

- Registry Server Hostname: `ORG_NAME.registry.cpln.io`
- Username: `'<token>'`
   <Note>The username is the literal string `'<token>'` (See example below).</Note>
- Password: `Service Account Key`
  <Note>Refer to the [Create a Service Account](/guides/create-service-account) guide for instructions on how to generate a new key.</Note>

<Tip>

The Service Account Key is a sensitive value and should be stored securely/encrypted.

If the key is compromised, it can be deleted and a new one generated.

</Tip>

### Example using Docker

```bash
echo $SERVICE_ACCOUNT_KEY | docker login ORG_NAME.registry.cpln.io -u '<token>' --password-stdin
```

After successfully authenticating to your private [image registry](/reference/image), the [service account](/reference/serviceaccount) will be able push images based on a defined [Policy](/reference/policy). Refer to the [Image Policy](/reference/image#minimum-policy) reference page for instructions on how to configure the minimum policy necessary to push images.

## Next Steps

Once an [image](/reference/image) has been successfully pushed to your [org's](/reference/org) private [image registry](/reference/image), it can be referred to by a [workload's container](/reference/workload#containers).

When setting up a [workload](/reference/workload), the list of available [images](/reference/image) stored in your private [image registry](/reference/image) can be viewed and selected by pressing `CTRL+I` on your keyboard.

## Reference

Refer to the [image build](/reference/cli#image-build) command for additional details.


### update-an-image
**Path**: `guides/image/update-an-image.mdx`

## Update an Image

Using the [CLI](/reference/cli), to update the image a container is pulling, execute the following command:

```bash
cpln workload update WORKLOAD_NAME --set spec.containers.CONTAINER_NAME.image=IMAGE:TAG --gvc GVC_NAME --org ORG_NAME
```

<Note>

Use the convention `//image/IMAGE:TAG` to reference an image residing within the current Org's private repository.

</Note>


## guides/setup-an-agent


### AWS
**Path**: `guides/setup-an-agent/aws.mdx`

---
title: AWS
---

## AWS

### Overview

Follow the steps below to install and configure an [agent](/reference/agent) within your Amazon Web Services (AWS) environment.

### Prerequisites

- Review the [Agent](/reference/agent) reference page.
- [Amazon Web Services](https://aws.amazon.com/) (AWS) account.

### Step One - Create an Agent

Follow the [Create an Agent](/guides/agent) guide to define an agent and generate the bootstrap config file that will be used in
[step two](#step-two-launch-an-agent-in-aws).

### Step Two - Launch an agent in AWS

1. Log in to the [AWS Console](https://console.aws.amazon.com).
2. Click this [link](https://aws.amazon.com/marketplace/pp/prodview-dq5cug2iej46m) to be directed to the `Control Plane Secure Communications Agent` within the AWS Marketplace.
   - For the `ARM`s version of the agent, [click here](https://aws.amazon.com/marketplace/pp/prodview-fvvtn73sdxxos).
3. Click the `Continue to Subscribe` button in the upper right corner.
4. After reading the terms and conditions, click the `Accept Terms`.
5. After the subscription has loaded, click the `Continue to Configuration` button in the upper right corner.
6. Click the `region` pull-down and select the region where your AWS resources reside.
7. Click the `Continue to Launch` button in the upper right corner.
8. Click the `Choose Action` pull-down and select `Launch through EC2`. Click the `Launch` button.
9. The `Launch an instance` wizard will be displayed.
10. Under the `Name and tag` section, enter the agent's name. (e.g., `cpln-agent`).
11. Under the `Instance type` section, select an applicable instance type.

<Tip>
  Refer to the [Agent Sizing Guidance](/reference/agent#agent-sizing-guidance) page for additional details on which instance type to select.
</Tip>

12. `Optional:` Under the `Key pair(login)` section, select or create a new key pair to
    enable SSH access to the agent. A key pair is necessary only for accessing the
    agent during troubleshooting.

<Tip>
If you do not have an AWS key-pair created, the console will help you to create one.

Since the agent instance will never need to be connected to (except for troubleshooting),
you may proceed without a key-pair.

</Tip>

13. Under the `Network setting` section, review the details and verify that the selected VPC is the same as the AWS resource you are trying to access.

<Tip>
For the agent to properly connect to the Control Plane servers, it requires outbound Internet access.

Verify that the `Auto-assign Public IP` option is set to `Enable`.

If your requirements do not allow the instance to have a public IP, please review the section
`How do instances without public IP addresses access the Internet` in this [AWS FAQ](https://aws.amazon.com/vpc/faqs/).

Either create or select an existing security group. The security groups belonging to the resources that the agent will need to
have access to will require to have the security group belonging to the agent added to its list of allowed inbound traffic.

Initially, remove the checkbox for the "Allow SSH from" property. SSH access is only necessary for troubleshooting purposes. Control Plane will never need to connect directly to the agent.

</Tip>

14. Under the `Configure storage` section, click the `Advanced` link and expand the volume property. Modify the `Delete on termination`
    dropdown to `Yes`. This will ensure the associated volume is removed if the agent is terminated, thereby preventing any orphaned volumes.

15. Expand the `Advanced details` section. Scroll to the bottom and paste the contents
    of the JSON payload (from the bootstrap config file) generated in [step one](#step-one-create-an-agent) within the `User data` textbox.
    Please review the other properties in this section to check if any default values need to be modified.

16. Click `Launch instance` in the lower right corner.

17. After a brief moment, the instance will launch and be ready to process requests.

### Next Steps

Now that you have an agent configured and running, it can be used within an [identity](/reference/identity) to allow your
[workload](/reference/workload) to connect to your internal AWS resources.


### Azure
**Path**: `guides/setup-an-agent/azure.mdx`

---
title: Azure
---

## Azure

### Overview

Follow the steps below to install and configure an [agent](/reference/agent) within your Microsoft Azure environment.

### Prerequisites

- Review the [Agent](/reference/agent) reference page
- [Microsoft Azure](https://azure.com) account

### Step One - Create an Agent

Follow the [Create an Agent](/guides/agent) guide to define an agent and generate the bootstrap config file that will be used in
[step two](#step-two-launch-an-agent-in-azure).

### Step Two - Launch an agent in Azure

1. Log in to the [Azure Console](https://portal.azure.com).
2. From the Azure homepage, click the `Marketplace` icon.
3. In the Marketplace search bar, enter:

```
Control Plane Secure Communications Agent
```

4. Press `Enter`.
5. When clicking the `Create` dropdown, select `gen-1`.
6. Use these recommended settings for the `Create a virtual machine` wizard:

- Basic
  - Subscription: Choose the appropriate subscription.
  - Resource Group: Choose the appropriate resource group. If necessary, create a new one.
  - Virtual machine name: Enter `Control-Plane-Agent-01`. If installing multiple agents, increment the number.
  - Region: Select a region closest to your other Azure resources.
  - Availability options: Select `No infrastructure redundancy required`. Use a different option for your environment if you are running in production.
  - Image: Leave as `gen-1`.
  - Size: An instance with at least 2 vCPUs and 4 GiB of memory is recommended for optimal performance.
  - Authentication type: Select `SSH public key`.
  - Username: Leave as `azureuser`.
  - SSH public key source: Choose the appropriate key. If necessary, create a new one.
  - Key pair name: Select appropriate key, or if creating a new one, use the default or update the key name.
  - Public inbound ports: Select `None`. The agent does not need any inbound ports open.
  - Click `Next: Disks`.
- Disks
  - OS disk type: Select `Premium SSD`.
  - Encryption type: Select `(Default) Encryption at-rest with a platform-managed key`.
  - Click `Next: Networking`.
- Networking
  - Virtual network: Choose an appropriate network or use the new network that will be created.
  - Subnet: Choose appropriate network or use the default.
  - Public IP: Select `None`.
  - NIC network security group: Select `Basic`.
  - Public inbound ports: Select `None`.
  - Click `Next: Management`.
- Management
  - Enable basic plan for free: Enabled.
  - Boot diagnostics: Select `Enable with managed storage account`.
  - Enable OS guest diagnostics: Disabled.
  - System assigned managed identity: Disabled.
  - Enable auto-shutdown: Disabled.
  - Patch orchestration options: Select `Image default`.
  - Click `Next: Advanced`.
- Advanced
  - Custom data: Paste the JSON text generated from [Step One](#step-one-create-an-agent-2) into the textbox.
  - Click `Next: Tags`.
- Tags
  - Optional: Enter any necessary tags.
  - Click `Next: Review + create`.
- Review + create
  - Review all the settings and enter any missing values.
  - Click `Create`.
  - If you requested to create a new key pair, a modal will pop-up requesting to download the private key. Click `Download private key and create resource`.

The agent virtual machine will begin the deployment process. After a few moments, the agent will be running, connecting to the Control Plane servers, and ready to process requests.

### Next Steps

Now that you have an agent configured and running, it can be used within an [identity](/reference/identity) to allow your
[workload](/reference/workload) to connect to your internal Azure resources.


### GCP
**Path**: `guides/setup-an-agent/gcp.mdx`

---
title: GCP
---

## GCP

### Overview

Follow the steps below to install and configure an [agent](/reference/agent) within your Google Cloud Platform (GCP) environment.

### Prerequisites

- Review the [Agent](/reference/agent) reference page
- [Google Cloud Platform (GCP)](https://cloud.google.com/) account.

### Step One - Create an Agent

Follow the [Create an Agent](/guides/agent) guide to define an agent and generate the bootstrap config file that will be used in
[step two](#step-two-launch-agent-in-gcp).

### Step Two - Launch agent in GCP

- Using the Google Cloud SDK

1. Install the latest [SDK](https://cloud.google.com/sdk/docs/install).
2. If necessary, log in using `gcloud init`.
3. Execute the command in the note below. Ensure that the instance will be deployed in the same VPC and region as your GCP resources. Use a unique `INSTANCE_NAME` and the bootstrap file `(AGENT_NAME-bootstrapConfig.json)` that was created in [step one](#step-one-create-an-agent-3).

```
gcloud compute instances create **INSTANCE_NAME** --image controlplane-agent-1875-1559894088-47d5d1215 --image-project cpln-build --metadata-from-file=user-data=**AGENT_NAME-bootstrapConfig.json**
```

<Tip>
Refer to the [Agent Sizing Guidance](/reference/agent#agent-sizing-guidance) page for additional details on which machine type to select.

Add the flag `--machine-type=MACHINE_TYPE` to the command above to select a different type. Otherwise, the default type is `n1-standard-1`.

</Tip>

4. After a few moments, the command will return and show the status of the deployed instance.
5. The agent will now be running, connecting to the Control Plane servers, and ready to process requests.

### Step Three - Configure Firewall

By default, the GCP firewall rules open the common SSH, RDP, and ICMP ports to the world and allows all internal ports within the VPC. The agent does not need any of these ports open.

At a minimum, the agent needs to be able to connect to your GCP resources and the Internet.

### Next Steps

Now that you have an agent configured and running, it can be used within an [identity](/reference/identity) to allow your [workload](/reference/workload) to connect to your internal GCP resources.

## Private Network

### Overview

Follow the steps below to install and configure an [agent](/reference/agent) within your private network.

### Prerequisites

- Review the [Agent](/reference/agent) reference page.
- Install the [CLI](/reference/cli).
- Install [Docker](https://docs.docker.com/engine/install/)

### Step One - Create an Agent

Follow the [Create an Agent](/guides/agent) guide to define an agent and generate the bootstrap config file that will be used in
[step two](#step-two-launch-agent-locally).

### Step Two - Launch agent locally

1. Open a new shell and execute the following command. Use the bootstrap file that was created in [step one](#step-one-create-an-agent-4).

```
cpln agent up --bootstrap-file=PATH/AGENT_NAME-bootstrapConfig.json
```

<Tip>

If you are using Windows, follow these instructions:

- Configure Docker to **not** use the WSL 2 based engine.
- Run the `cpln` command above using a Windows command prompt and not using WSL.

</Tip>

2. The agent will now be running, connecting to the Control Plane servers, and ready to process requests.

### Next Steps

Now that you have an agent configured and running, it can be used within an [identity](/reference/identity) to allow your [workload](/reference/workload) to connect to your local resources.

<Tip>
  When running an agent locally, it is running within a local Docker container. When configuring an [identity network
  resource](/reference/identity#network-resources-cloud-wormhole), you must use the IP of the network adapter that Docker installed on the
  local machine.
</Tip>


### Kubernetes Cluster
**Path**: `guides/setup-an-agent/k8s.mdx`

---
title: Kubernetes Cluster
---

## Kubernetes (k8s) Cluster

### Overview

Follow the steps below to install and configure an [agent](/reference/agent) within your k8s cluster.

### Prerequisites

- Review the [Agent](/reference/agent) reference page.
- Install the [CLI](/reference/cli).

### Step One - Create an Agent

Follow the [Create an Agent](/guides/agent) guide to define an agent and generate the bootstrap config file that will be used in
[step two](#step-two-launch-agent-within-a-k8s-cluster).

### Step Two - Launch agent within a K8s cluster

1. Open a new shell and execute the following command. Update tokens as necessary. Use the bootstrap file that was created in [step one](#step-one-create-an-agent-5).

```
cpln agent manifest --bootstrap-file bootstrap.json --namespace NAMESPACE --replicas 2 --cluster CLUSTER_ID > manifest.yaml

# inspect/modify the manifest file manually, if needed.
kubectl apply -f manifest.yaml
```

`cpln` will generate the manifest.yaml file that will deploy two replicas of the agent to the namespace of your choice (`NAMESPACE` in the example). The parameter `--cluster CLUSTER_ID` will be added to the agent's status which is used as a hint to know which cluster an agent has been deploy to.

It is recommended to use --replicas=2 for high availability (HA).

On startup, the agent will generate a public/private key-pair which is persisted as a k8s secret. In this scenario, the agents run under a k8s service account, which can create/modify secrets in its own namespace. If this is a concern, the agent can be configured to run in a dedicated namespace.

2. The agent will now be running, connecting to the Control Plane servers, and ready to process requests.

### Next Steps

Now that you have an agent configured and running, it can be used within an [identity](/reference/identity) to allow your [workload](/reference/workload) to connect to your local resources.


### Private Network
**Path**: `guides/setup-an-agent/private.mdx`

---
title: Private Network
---

## Private Network

### Overview

Follow the steps below to install and configure an [agent](/reference/agent) within your private network.

### Prerequisites

- Review the [Agent](/reference/agent) reference page.
- Install the [CLI](/reference/cli).
- Install [Docker](https://docs.docker.com/engine/install/)

### Step One - Create an Agent

Follow the [Create an Agent](/guides/agent) guide to define an agent and generate the bootstrap config file that will be used in
[step two](#step-two-launch-agent-locally).

### Step Two - Launch agent locally

1. Open a new shell and execute the following command. Use the bootstrap file that was created in [step one](#step-one-create-an-agent-4).

```
cpln agent up --bootstrap-file=PATH/AGENT_NAME-bootstrapConfig.json
```

<Tip>

If you are using Windows, follow these instructions:

- Configure Docker to **not** use the WSL 2 based engine.
- Run the `cpln` command above using a Windows command prompt and not using WSL.

</Tip>

2. The agent will now be running, connecting to the Control Plane servers, and ready to process requests.

### Next Steps

Now that you have an agent configured and running, it can be used within an [identity](/reference/identity) to allow your [workload](/reference/workload) to connect to your local resources.

<Tip>
  When running an agent locally, it is running within a local Docker container. When configuring an [identity network
  resource](/reference/identity#network-resources-cloud-wormhole), you must use the IP of the network adapter that Docker installed on the
  local machine.
</Tip>


## intro


### What is Control Plane?
**Path**: `intro/whatis.mdx`

---
title: What is Control Plane?
---

## Overview

Control Plane is a hybrid platform enabling cloud architects to combine the services, regions, and computing power of Amazon Web Services (AWS), Google Cloud Platform (GCP), Microsoft Azure and any other public or private cloud to provide developers with a flexible yet unbreakable global environment for building backend apps and services.

On Control Plane, microservices can run simultaneously on any combination of cloud compute and consume any combination of cloud services without embedded credentials. The platform handles identity conveyance and authorization uniformly, utilizing best-practices/least privilege principles consistently and securely.

## Based on Kubernetes

While Kubernetes orchestrates workloads within a single cluster, Control Plane orchestrates an unlimited number of hardened, security-isolated Kubernetes clusters in all the regions of the major clouds. You can easily add additional Kubernetes clusters running in any cloud as custom `Bring Your Own Kubernetes (BYOK)` regions. You can use Control Plane without in-depth knowledge of Kubernetes and its associated technologies but, if you have already deployed your own clusters, the platform augments and expands your existing Kubernetes infrastructure.

## Why run on Control Plane?

Rather than restricting architects to a corner of the cloud, Control Plane enables architects to build a resilient, easy-to-use combination of clouds and cloud resources.

Some of the attributes which set Control Plane apart include:

* **Multi-Region and Multicloud Compute**: With Control Plane, your workloads run agnostically across any combination of geographic regions and cloud providers (AWS, Azure, GCP or any other public and private clouds). Kubernetes clusters hosted anywhere can be easily added to Control Plane. This enables you to switch clouds or add clouds with a few clicks.

* **Any Cloud Backing Service**: Microservices running on Control Plane have native access to ANY service on ANY cloud (e.g., BigQuery on GCP, AD on Azure, SQS on AWS) without embedding credentials by using [Universal Cloud Identity](/reference/identity#cloud-access-universal-cloud-identity-universal-cloud-identity). This enables you to easily mix and match services from multiple clouds by virtually unifying the networking and identity and authorization policies across all supported clouds. Control Plane’s [Cloud Wormhole](/reference/identity#network-resources-cloud-wormholes-cloud-wormhole) functionality enables your microservice to access native AWS, Azure, and GCP services within and across VPCs. Using [Cloud Wormhole](/reference/identity#network-resources-cloud-wormholes-cloud-wormhole), workloads can also access endpoints behind firewalls on-prem and even on the developer's laptop during development.

* **Best-of-Breed DevOps Stack**: Control Plane integrates the best of the cloud-native ops stack for metrics, logging, secrets management, software-defined VPN, geo-intelligent DNS and more. You can also easily integrate the tools of your choice.

* **Uniform Access Control**: Control Plane provides advanced, consistent, yet easy-to-use fine-grained authorization controls. These controls are identical whether administering Control Plane itself or your custom workloads. Your workloads get an out-of-the-box fine-grained authorization "dial tone" that uniformly handles simple and complex use cases alike.

* **Built In Audit Trail**: Control Plane exposes a tamper-proof audit trail facility for both the Control Plane actions you take as well as for custom workloads. Your code writes to a configured localhost port, and your audit events are correctly captured and secured. The audit data is indexed and can efficiently be searched programmatically from your user interface.

* **Efficient Cloud Cost**: Cloud consumption is elastically optimized on Control Plane to run with the exact resources required and nothing else, enabling you to derive the benefits of serverless without rearchitecting your microservices. Whether your app has a Dockerfile or not, regardless of whether you designed the app to run serverless, the platform runs your microservice with elastic scalability - from zero to any scale you specify.

* **Unified Interface**: The cloud platforms differ substantially from one another in their APIs, CLIs, and UIs. Each has its specialized, often convoluted interface surface, with its unique and steep learning curve. Control Plane offers a symmetrical UI, API, and CLI which enable you to deploy and run in **any** cloud. It enables developers to deploy and manage workloads uniformly to multiple clouds simultaneously, from a single, intuitive and consistent interface, making workload deployment and day-2 operations a breeze.

**The result: Enhanced performance for the end-user.**

Control Plane utilizes advanced, redundant health monitoring and geographically-distributed DNS infrastructure. The platform automatically re-routes traffic to healthy regions and clusters. It removes unhealthy and unreachable nodes from rotation, so the end-users measured availability and latency are optimal. A user from one part of the world experiences ultra-low-latency responses, while a user on the other side of the planet experiences similar \~20-30 ms latency.

Control Plane enables you to utilize the full range of services and computing power your application requires from any number of clouds while delivering your users uniform and predictable performance.


## objects


### 'Agent'
**Path**: `objects/agent.mdx`

---
title: 'Agent'
---

## Overview

In situations where your [workload](/objects/workload) needs to consume services from endpoints within a VPC or another private network, you would use a wormhole **agent**.

Control Plane's wormhole technology securely connects your workloads to any TCP or UDP endpoints in VPCs and other private networks, including on-prem data centers and even on a developer's laptop. You establish a wormhole by running an agent VM (agent for short) inside the private network to which you are connecting your workloads.

Control Plane offers agents for both private networks and cloud providers. The agent is installed and configured within the location where it can access the applications or services that your workload requires. It does this by establishing a secure and persistent connection to publicly hosted Control Plane servers. Requests from your workload are tunneled to the agent which performs the request and then tunnels the response back. This flow occurs in a performant manner and is transparent to the workload.

Agents are scoped to an [org](/reference/org) and are used in conjunction with [identities](/reference/identity) to set up [network resources](/reference/identity#network-resources-cloud-wormhole).

## High Availability (HA)

Agents run in active-passive mode. If an active agent misses a set amount of heartbeats, it is considered offline and replaced by a redundant agent.

The recommended method to configure a highly available agent deployment is by using an instance group (also called an autoscaling group on AWS or a VMSS/virtual machine scale set on Azure).

The autoscaling group template must be configured in the same way as a single VM in terms of cloud configuration, network settings, etc. As the agent's functionality is not CPU intensive, that metric cannot be used to scale instances up and down. Instead, use a fixed sized group set to a minimum of 2 and a maximum of the number of zones used within your infrastructure.

## Guides

- [Create an Agent](/guides/create-an-agent)
- Setup an Agent
  - [AWS](/guides/setup-an-agent/aws)
  - [Azure](/guides/setup-an-agent/azure)
  - [GCP](/guides/setup-an-agent/gcp)
  - [Private Network](/guides/setup-an-agent/private)
  - [Kubernetes Cluster](/guides/setup-an-agent/k8s)
- [Agent Sizing Guidance](/guides/agent-sizing-guidance/index)
  - [AWS](/guides/agent-sizing-guidance/aws)
  - [GCP](/guides/agent-sizing-guidance/gcp)
- [Guide for Workload but requires an agent](/guides/agent-sizing-guidance/index)
- [Guide for identity but requires an agent](/guides/agent-sizing-guidance/index)
- [Any guide that utilizes an agent](/guides/agent-sizing-guidance/index)

## Permissions

The permissions below are used to define [policies](/reference/policy) together with one or more of the four
[principal types](/concepts/principal_types):

| Permission | Description                 | Implies                                 |
| :--------- | :-------------------------- | :-------------------------------------- |
| create     | Create new agents           |                                         |
| delete     | Delete service agents       |                                         |
| edit       | Modify existing agents      | view                                    |
| manage     | Full access                 | create, delete, edit, manage, use, view |
| use        | Use an agent in an identity | view                                    |
| view       | Read-only access            |                                         |

## API Reference

Click to see [API Agent Reference](/api-reference/agent)

## CLI Reference

Click to see [CLI Agent Reference](/references/cli/agent)

## Terraform Reference

Click to see [Terraform Agent Resource](/references/terraform/resources/cpln_gvc)

Click to see [Terraform Agent Data Source](/references/terraform/data-sources/cpln_gvc)


### 'Audit Context'
**Path**: `objects/audit-context.mdx`

---
title: 'Audit Context'
---

## Overview

Control Plane exposes a tamper-proof audit trail service for both Control Plane and custom workload actions.

To use this feature, a unique **Audit Context** needs to be created for your workload.

The audit context named `cpln` already exists to audit the actions that occur while using Control Plane.

Please refer to the [audit trail](/reference/audittrail) reference page for additional details on how to query the audit trail and how to securely capture actions for your workloads.

## Default `cpln` audit context

TODO

## Guides

- [Understand and Use Default `cpln` Audit Context](/guides/create-an-audit-context) TODO
- [Create an Audit Context](/guides/create-an-audit-context)
- [Writing Audit Records From a Workload](/guides/audit/writing-audit-records-from-a-workload)

## Permissions

The permissions below are used to define [policies](/reference/policy) together with one or more of the four
[principal types](/concepts/principal_types):

| Permission | Description              | Implies                                           |
| :--------- | :----------------------- | :------------------------------------------------ |
| create     | Create new contexts      |                                                   |
| edit       | Modify existing contexts | view                                              |
| manage     | Full access              | create, edit, manage, readAudit, view, writeAudit |
| readAudit  | Read from this context   | view                                              |
| view       | Read-only view           |                                                   |
| writeAudit | Write to this context    | view                                              |

## API Reference

Click to see [API Audit Context Reference](/api-reference/auditctx)

## CLI Reference

Click to see [CLI Audit Context Reference](/references/cli/auditctx)

## Terraform Reference
TODO

Click to see [Terraform Audit Context Resource](/references/terraform/resources/cpln_auditctx)

Click to see [Terraform Audit Context Data Source](/references/terraform/data-sources/cpln_auditctx)


### 'Cloud Account'
**Path**: `objects/cloud-account.mdx`

---
title: 'Cloud Account'
---

## Overview

A **cloud account** is a mapping between your [org](/reference/org) and a cloud provider. When creating a cloud account, instructions are provided on how to create a bridge account at the cloud provider with minimum access permissions. This bridge account is used by Control Plane to query and manage the necessary resources at the cloud provider on behalf of your [org](/reference/org).

Cloud accounts are scoped to an [org](/reference/org) and are used in conjunction with [identities](/reference/identity) to set up [cloud access](/reference/identity#cloud-access-universal-cloud-identity) rules.

Your [workload](/concepts/workload) can then be associated with an [identity](/reference/identity) and will then have the ability to call any of the allowed cloud provider resources transparently without any additional set up.

For example, if your application uses AWS S3 for storage and Azure Cosmos DB for its database, your workload will be able to access both no matter which [location](/reference/location) the workload is deployed to. The [workload](/concepts/workload) calls each resource as if it had a direct connection and the [identity](/reference/identity) will route the request seamlessly to the proper location.

# Supported cloud providers

TODO list gcp aws azure and ngs here, give brief information, explain for other servers, they can use an agent and refer to the guides

## Azure Details

When registering a cloud account targeting Azure, you can choose from the following methods:

- [Azure SDK](#azure-sdk)
  - Access tokens are minted using an Azure Service Principal.
- [Azure Connector](#azure-connector)
  - An [Azure Function App](https://azure.microsoft.com/en-us/services/functions/)
    acts as a bridge that calls internals Azure APIs to obtain access tokens.

<Tip>

During the creation of an Azure cloud account, the Azure CLI generates credentials that are used by Control Plane when connecting to Azure to provision apps or user identities that will be used by workload identities. These credentials are uploaded and stored securely as an [Azure-SDK secret](/reference/secret#azure-sdk) or [Azure-Connector secret](/reference/secret#azure-connector) and can be viewed by clicking `Secrets` from the left menu in the console after creating an Azure cloud account.

</Tip>

## Guides

- [Create a Cloud Account](/guides/cloud-account/create-a-cloud-account)
- AWS
  - [Connecting to AWS Services](/guides/cloud-account/connecting-to-aws-services)
  - [Disconnecting AWS](/guides/cloud-account/disconnecting-aws)
- Azure
  - [Connecting to Azure Services with Azure SDK](/guides/cloud-account/connecting-to-azure-services-with-azure-sdk)
  - [Connecting to Azure Services with Azure Connector](/guides/cloud-account/connecting-to-azure-services-with-azure-connector)
  - [Disconnecting Azure](/guides/cloud-account/disconnecting-azure)
- GCP
  - [Connecting to GCP Services](/guides/cloud-account/connecting-to-gcp-services)
  - [Disconnecting GCP](/guides/cloud-account/disconnecting-gcp)
- NGS
  - [Connecting to NGS Services](/guides/cloud-account/connecting-to-ngs-services) TODO
  - [Disconnecting NGS](/guides/cloud-account/disconnecting-ngs) TODO


## Permissions

The permissions below are used to define [policies](/reference/policy) together with one or more of the four
[principal types](/concepts/principal_types):

| Permission | Description                    | Implies                                    |
| :--------- | :----------------------------- | :----------------------------------------- |
| browse     | Browse account contents        | view                                       |
| create     | Create new cloud accounts      |                                            |
| delete     | Delete existing cloud accounts |                                            |
| edit       | Modify existing cloud accounts | view, browse                               |
| manage     | Full access                    | browse, create, delete, edit, manage, view |
| view       | Read-only access               |                                            |

TODO

## API Reference

Click to see [API Agent Reference](/api-reference/agent)

## CLI Reference

Click to see [CLI Agent Reference](/references/cli/agent)

## Terraform Reference

Click to see [Terraform Agent Resource](/references/terraform/resources/cpln_gvc)

Click to see [Terraform Agent Data Source](/references/terraform/data-sources/cpln_gvc)


### 'Domain'
**Path**: `objects/domain.mdx`

---
title: 'Domain'
---

## Overview

[Workloads](/concepts/workload) managed at Control Plane can be configured to serve requests using any domain name you own.

Domains are scoped to an [Org](/reference/org) and are associated with **one** [GVC](/reference/gvc). The domain can then be configured to handle requests for one or multiple [Workloads](/concepts/workload) within that [GVC](/reference/gvc).

Domains that are configured at Control Plane are automatically secured using TLS certificates, load balanced, and DNS geo-routed to the nearest healthy [location](/reference/location) assigned to the [GVC](/reference/gvc).

## Default Domain Names

If a Domain is not mapped to a [GVC](/reference/gvc), the default domain names provided to [Workloads](/concepts/workload) are:

// TODO mention here that gvc mapped domain is a legacy method, can have it's own section here

- Canonical endpoints (Global): `cpln.app` // TODO explain it is `{workloadName}-{gvcAlias}.cpln.app`
- Individual location endpoints: `controlplane.us` // TODO explain it is `{workloadName}-{gvcAlias}.{location}.controlplane.us`

## Domain Verification

An apex domain, also known as a root domain, refers to a domain name that does not have any subdomain prefix (e.g., **example.com**).

Even if the apex domain isn't served at Control Plane, it needs to be created and configured for verification. This verification is done by adding a TXT record to DNS.

Once the apex domain is verified, subdomains can be added to the same [Org](/reference/org) without needing the TXT record verification step.

If multiple [Orgs](/reference/org) are creating subdomains using the same apex domain, the apex domain verification only needs to be performed in one of the Orgs, but subdomains in Orgs that don't have the apex domain will require a TXT record be added to DNS for verification.

<Tip>As a best practice, create the apex domain in the Org designated for your production environment.</Tip>

// TODO show examples in a table

## Hostname Behavior

// TODO explain and give examples, why don't we have HOST variable when we connect to a replica?

The hostname (`HOST`) environment variable that will be set on a running workload will be based on the type of Workload and which domain was used for the request.

For **serverless** workloads, even if the request was served using a custom domain, the hostname will be the canonical name.

For **standard** or **stateful** workloads, the hostname will be set to the name of domain used for the request.

## Routing Modes

Control Plane provides two routing modes for directing requests to your domain:

1. [Path Based Routing](#path-based-routing)
2. [Subdomain Based Routing](#subdomain-based-routing)

### Path Based Routing

Path based routing allows requests to a specific path prefix be routed to a specific workload. Multiple paths can be defined, but there must be at least one path.

This is accomplished by adding a **CNAME** record to DNS.

Advantages of using Path Based routing:

- You maintain full control of DNS for the domain.
- CDN / WAF Compatible.

**Example URL endpoints:**

- If the domain `sub.example.com` is configured to point to the GVC that contains `workload_one` and `workload_two`. The path `workload_one` can be configured to route requests to `workload_one` and the path `workload_two` can be configured route requests to `workload_two`.
  - **https://sub.example.com/workload_one**
  - **https://sub.example.com/workload_two**

<Note>All path prefix values must be unique and there must be at least one path defined.</Note>

#### Path Prefix Replacement

A path prefix can be configured to be replaced when forwarding the request to the [Workload](/concepts/workload).

**For example:** A request to the URL `https://sub.example.com/users/` can have the path prefix `/users/` replaced with the path prefix `/v2/users/`
when forwarding the request internally to the target [Workload](/concepts/workload).

<Note>This does not work for regex-based paths</Note>

#### Root Path Prefix

The `/` path will match any unmatched path prefixes for the subdomain.

#### Path Order

The order of the path prefix list is adjustable. When a request to the Domain is received, the first match will be processed.

<Note>

When combining the `/` path prefix with other path prefixes, the `/` path will automatically be placed last in the list because it matches
ALL requests.

</Note>

#### Port Selection

Each route can have a port assigned which will route requests to the respective port at the running workload.

For **serverless** workloads, assigning the port is optional since only one port can serve traffic.

For **standard** and **stateful** workloads that serve traffic on multiple ports, specific ports can be assigned on a route. If no port is assigned, external requests will be routed to the first port configured on the container. TODO does this mean we actually have an ordered list in the ports?

<Note>

When a domain is serving path based requests, the [domain port protocol](#protocol) must be compatible with the selected protocol of the
port configured on the container. (i.e., HTTP2 is compatible with HTTP2 and GRPC, HTTP is compatible with HTTP, etc.)

</Note>

// TODO create a table for above compatibilities

// TODO for all examples above, create tables

### Regex Based Routing

Instead of specifying routes based on a path prefix, paths can be specified using [regex](https://github.com/google/re2/wiki/Syntax).

**For example:** A path regex can be specified as: `/user/.*/profile` to match routes like: `/user/bob/profile` or `/user/mary/profile`

<Note>If at least one regex path is found, routes will not be sorted.</Note>

### Subdomain Based Routing

Subdomain based routing allows a domain to be mapped to all workloads in a [GVC](/reference/gvc).

The is accomplished by adding **NS** records to DNS which delegate DNS to Control Plane for this domain **only**.

Advantages of using Subdomain routing:

- Best choice when a unique DNS subdomain is required for each workload.
- One-time configuration.
- Works for all current and future workloads in a GVC.

**Example URL endpoints:**

- If the domain `sub.example.com` is configured to the GVC that contains workloads named `workload_one` and `workload_two`, Control Plane will create
  the following subdomains and route requests to the respective workloads:
  - **https://workload_one.sub.example.com**
  - **https://workload_two.sub.example.com**

// TODO make above a table

## APEX Domain Considerations

- An apex domain (e.g., **example.com**) can serve requests to Workloads using
  either [path based](#path-based-routing) or [subdomain based](#subdomain-based-routing) routing.

- If subdomain based routing is desired, a [Custom Server Certificate](#custom-server-certificate) must be configured.

- If your DNS provider does not allow apex domains to point to a CNAME record, a service such as [CloudFront](https://docs.aws.amazon.com/cloudfront/index.html) or [Cloudflare](https://cloudflare.com) must be used to proxy the apex domain to Control Plane.

<Tip>

These DNS providers **do not** allow apex domains to have a CNAME record:

- GoDaddy
- Route53

</Tip>

## Port Configuration

Using the UI console, the port configuration section can be accessed when editing a domain and using `Advanced Mode`.

// TODO remove, do not mention ui

### External Port

Typically, TLS requests to a configured domain are served on the standard TLS port 443.

Refer to the [dedicated load balancer](#dedicated-load-balancer-options) section on which external ports can be used if dedicated load balancing is enabled.

### Protocol

The following protocols are supported:

1. **HTTP2**
1. **HTTP**
1. **TCP** (when using a [dedicated load balancer](#dedicated-load-balancer-options))

### TLS Settings

The default TLS protocol version is **1.2**. The minimum TLS protocol version is **1.0**.

The minimum version should be set as high as possible and all modern browsers support the default of **1.2**.

#### Cipher Suites

// TODO explain or reference what these are, give maybe also prefixed groups for different purposes

The following cipher suites are added by default and can be removed / re-added:

1. ECDHE-ECDSA-AES256-GCM-SHA384
1. ECDHE-ECDSA-CHACHA20-POLY1305
1. ECDHE-ECDSA-AES128-GCM-SHA256
1. ECDHE-RSA-AES256-GCM-SHA384
1. ECDHE-RSA-CHACHA20-POLY1305
1. ECDHE-RSA-AES128-GCM-SHA256
1. AES256-GCM-SHA384
1. AES128-GCM-SHA256

Additional ciphers which can be added:

1. DES-CBC3-SHA
1. ECDHE-RSA-AES128-SHA
1. ECDHE-RSA-AES256-SHA
1. AES128-SHA
1. AES256-SHA

If you need additional cipher suites, please contact support on Slack or email [support@controlplane.com](mailto:support@controlplane.com).

<Tip>

If there is an attempt to disable the TLS settings on a domain, it will always revert to the default configuration unless the domain is using a non-standard port and a non-HTTP protocol (e.g., using TCP with a [dedicated load balancer](#dedicated-load-balancer-options)).

</Tip>

// TODO for above, there can also be a compatibility table here

#### Client Certificate Forwarding

Client certificates included in a request to a Domain can be configured to be forwarded to the destination [Workload](/concepts/workload).

The `x-forwarded-client-cert` (XFCC) HTTP header will contain the client certificate details.

The certificate authority PEM, stored as a [TLS Secret](/reference/secret#tls), can be associated with the Domain and used to verify the authority of the client certificate. The only verification performed checks that the CN of the PEM matches the Domain (i.e., **CN=\*.DOMAIN**).

If a certificate authority PEM is not associated with a Domain, no verification is performed.

CRL lists are not verified / checked, but they can be checked by the [Workload](/concepts/workload) by keeping a list of allowed or revoked client certificate hashes. When a request is received by the [Workload](/concepts/workload), the hash field in the XFCC header can be checked against the allowed or revoked list and an allow / deny decision can be made.

To generate the certificate hash, execute the following command:

```bash
openssl x509 -noout -fingerprint -sha256 -inform pem -in MyClientCert.pem | awk -F= '{print $2}' | tr -d ':' | tr '[:upper:]' '[:lower:]'`
```

<Tip>

Verify that the CA certificate includes the correct x509 key usage fields (critical, digitalSignature, keyEncipherment) + extendedKeyUsage = serverAuth and that the CN of the client certificate matches the domain name selected.

</Tip>

#### Custom Server Certificate

A Custom Server Certificate can be assigned to a Domain by selecting an exisiting [TLS secret](/reference/secret#tls).

This certificate is used when configuring:

1. An apex domain that is configured with [subdomain based routing](#subdomain-based-routing).
2. A domain that is fronted by a proxy (such as CloudFlare).
3. A domain that prefers not to use a certificate generated by Control Plane.

<Tip>

If a custom server certificate is configured on a domain, it is the responsibility of the user to ensure that the certificate is valid and not expired.

</Tip>

### CORS Settings

**CORS** stands for **Cross-Origin Resource Sharing**. It is a mechanism that allows web browsers to securely make requests to a different domain or origin than the one from which the web page was served.

By default, web browsers enforce a policy called the Same-Origin Policy, which restricts JavaScript code running in a web page from making requests to a different domain. CORS provides a way to relax this policy and enable cross-origin requests, but in a controlled and secure manner.

When a web page makes a cross-origin request, the server needs to include specific CORS headers in its response to indicate which origins are allowed to access its resources. These headers include information such as the allowed methods, allowed headers, and whether credentials (such as cookies or HTTP authentication) can be included in the request.

CORS helps to prevent malicious scripts from performing unauthorized actions on behalf of a user, while still allowing legitimate cross-origin requests between trusted domains. It plays a crucial role in enabling modern web applications to interact with APIs and services hosted on different domains.

The following are CORS properties that are configurable on the domain. Depending on the application being served, these setting could be configured from the application.

The following CORS properties can be configured:

- **Allow Credentials**
  - Determines whether the client-side code (typically running in a web browser) is allowed to include credentials (such as cookies, HTTP authentication, or client-side SSL certificates) in cross-origin requests.
- **Max Age**
  - Maximum amount of time, in seconds, that a preflight request result can be cached by the client browser. (Default: 24 hours)
- **Allow Origins**
  - Determines which origins are allowed to access a particular resource on a server from a web browser.
    - Examples:
      - Wildcard Origin: `*`
      - Specific Origin: `https://example.com`
- **Allow Methods**
  - Specifies the HTTP methods (such as GET, POST, PUT, DELETE, etc.) that are allowed for a cross-origin request to a specific resource.
- **Allow Headers**
  - Specifies the custom HTTP headers that are allowed in a cross-origin request to a specific resource.
- **Expose Headers**
  - Specifies which response headers are exposed to the client-side code (typically running in a web browser) in a cross-origin request.

## Dedicated Load Balancer Options

When a GVC has the dedicated load balancer option enabled, additional settings are available for any domains using it.

See the [GVC dedicated load balancer](/reference/gvc#dedicated-load-balancer) reference page for additional details.

### NumTrustedProxies

This gives control over the number of trusted proxies that are configured in front of Control Plane.

Changing it, controls the source ip address used for request logging, firewall settings and for the X-Envoy-External-Address header passed to workloads.

If set to 1, then the last address in an existing X-Forwarded-For header will be used in place of the source client IP address.

If set to 2, then the second to last address in an existing X-Forwarded-For header will be used in place of the source client IP address.

When set to 2, any request where the XFF header does not have at least two addresses or does not exist then the source client IP address will be used instead.

### Custom Ports

The following external ports may be configured instead of only `443` and `80`.

- 1443
- 3000
- 3001
- 3002
- 3003
- 3004
- 5912
- 8443
- 8444
- 50051
- 50052

Please contact support on Slack or email [support@controlplane.com](mailto:support@controlplane.com) if you need to use a port that is not listed here.

### Configuration Options

When a dedicated load balancer is enabled on a GVC, the domains that are configured to serve workloads within that GVC will have the following options that can be configured:

1. [Accept All Hosts](#accept-all-hosts)
1. [Host Prefix](#host-prefix)

#### Accept All Hosts

`Accept All Hosts` configures the domain to allow all traffic (i.e. wildcard support) to the configured workloads, regardless of what the Host header or SNI is for the request.

#### Host Prefix

For domains using [Path Based Routing](#path-based-routing) the `Host Prefix` will be enabled and can be used for each path when the domain has the `Accept All Hosts` property enabled.

This option allows forwarding traffic for different host headers to specific workloads.

// TODO , for the above two, give examples

## Guides

- [Configure a Domain](/guides/domain/configure-a-domain)

## Permissions

The permissions below are used to define [policies](/reference/policy) together with one or more of the four
[principal types](/concepts/principal_types):

| Permission | Description                                        | Implies                                 |
| :--------- | :------------------------------------------------- | :-------------------------------------- |
| create     | Create new domain                                  |                                         |
| delete     | Delete a domain                                    |                                         |
| edit       | Modify existing domains (only tags can be changed) | view, use                               |
| manage     | Full access                                        | create, delete, edit, manage, use, view |
| use        | Allow a principal to use this domain               | view                                    |
| view       | Read-only access                                   |                                         |

TODO

## API Reference

Click to see [API Agent Reference](/api-reference/agent)

## CLI Reference

Click to see [CLI Agent Reference](/references/cli/agent)

## Terraform Reference

Click to see [Terraform Agent Resource](/references/terraform/resources/cpln_gvc)

Click to see [Terraform Agent Data Source](/references/terraform/data-sources/cpln_gvc)


### 'Group'
**Path**: `objects/group.mdx`

---
title: 'Group'
---

## Overview

A group is a membership collection that can contain [users](/reference/user) and [service accounts](/reference/serviceaccount). It is one of the [principal types](/concepts/principal_types) of an [org](/reference/org).

// TODO add principal page and refer to it from here

Membership in a group for a user account can be assigned directly or dynamically using a query based on a [tag](/reference/misc#tags) (key/value pair) that has been labeled on a user.

Membership in a group for a [service account](/reference/serviceaccount) can only be assigned directly.

Groups can be used by [policies](/reference/policy) to grant access permissions to the group members.

## Built-in Groups

Each [org](/reference/org) has the following built-in groups:

| Group Name | Description                                               |
| :--------- | :-------------------------------------------------------- |
| superusers | Built-in group for all administrators of the organization |
| viewers    | Built-in group for read-only access                       |

## Group Notes

Groups can contain an unlimited amount of [users](/reference/user) or [service accounts](/reference/serviceaccount).

Group membership can be assigned directly or dynamically (using a [query](#query-rules) based on any [tags](/reference/misc#tags) that are labeled on a [user](/reference/user)). [Service Accounts](/reference/serviceaccount) can only be assigned directly.

For example, a [query](#query-rules) can be created to dynamically assign all the users that log in using `microsoft.com` by using the built-in tag key `firebase/sign_in_provider` Equals `microsoft.com`.

// TODO add a section for identity matcher

// TODO make a page for query and tags separately, refer to a guide from here on how to use it

## Query Rules

// TODO create a common concepts section and explain things like principals, queries, etc.

To dynamically assign users to a group, a query can be defined which consists of the following:

- One or more [tags](/reference/misc#tags) (key/value pairs) using one of the operators: `Equals` / `Exists` / `Not Exists`
- One of the following query filters:
  - `All`: All [tag](/reference/misc#tags) items should match
  - `Any`: Any of the [tags](/reference/misc#tags) should match
  - `None`: None of these [tags](/reference/misc#tags) should match

## Guides

- [Create a Group](/guides/create-a-group)

## Permissions

The permissions below are used to define [policies](/reference/policy) together with one or more of the four
[principal types](/concepts/principal_types):

| Permission | Description            | Implies                            |
| :--------- | :--------------------- | :--------------------------------- |
| create     | Create new groups      |                                    |
| delete     | Delete a group         |                                    |
| edit       | Modify existing groups | view                               |
| manage     | Full access            | create, delete, edit, manage, view |
| view       | Read-only view         |                                    |

## API Reference

Click to see [API Agent Reference](/api-reference/agent)

## CLI Reference

Click to see [CLI Agent Reference](/references/cli/agent)

## Terraform Reference

Click to see [Terraform Agent Resource](/references/terraform/resources/cpln_gvc)

Click to see [Terraform Agent Data Source](/references/terraform/data-sources/cpln_gvc)


### 'GVC'
**Path**: `objects/gvc.mdx`

---
title: 'GVC'
---

## Overview

A Global Virtual Cloud ([GVC](/reference/gvc)) defines a set of cloud providers and their [locations](/reference/location). TODO mention byok locations here

When creating a GVC you are in essence building an uber-cloud that is comprised of the specified [locations](/reference/location). [Workloads](/concepts/workload) are deployed to the GVC which are then served from all the [locations](/reference/location) specified.

Each [org](/reference/org) can have multiple GVCs, each with its own unique set of [locations](/reference/location).

A [domain name](/reference/domain) can be assigned to a GVC. Callers can reach [workloads](/concepts/workload) using the assigned [domain name](/reference/domain).

## Benefits

- GVCs enable your [workload](/concepts/workload) to be deployed with ease to multiple cloud providers and locations
  - You choose the provider (AWS, Azure, and GCP) and their different locations
  - Select [locations](/reference/location) that are close to your end-users
  - Select the [locations](/reference/location) that fulfill the requirements of your workloads
  - Ensure maximum availability if a cloud provider has an occasional outage
- You get granular controls to define the scaling characteristics of your [workload](/concepts/workload)
TODO dedicated load balancer
TODO pull secrets
TODO envoy-auth

## Domain Name 

TODO mention that this is legacy

Each GVC can be set to use one of the fully qualified [domain names](/reference/domain) that have been mapped to an [org](/reference/org).

The selected [domain name](/reference/domain) will be used by all [workloads](/concepts/workload) when serving their containers.

The default domain name `cpln.app` will be used if an [org](/reference/org) does not have any domains configured, or if you do not select a [domain name](/reference/domain).

## envoy-auth section

TODO add section for envoy auth separately, and refer to it from here and the workload

## Pull Secrets

Pull secrets are [secrets](/reference/secret) that are assigned to a GVC and used by [workloads](/concepts/workload) when authentication is required for pulling an image from a private registry. Only the [Docker](/reference/secret#docker), [Amazon ECR](/reference/secret#ecr), and [GCP](/reference/secret#google-cloud-platform-gcp) [secret](/reference/secret) types are supported.

<Tip>If the image was pushed to the Control Plane registry for the same [org](/reference/org), no secret is required.</Tip>

Multiple pull secrets can be assigned to a GVC. A [workload's container](/concepts/workload) will use the appropriate secret when pulling the image from a private registry. If there are multiple secrets, the container will cycle through each one.

If authentication fails, the deployment will not be updated and the image pull will have an exponential backoff retry starting at 10 seconds until 5 minutes (e.g., 10 seconds, 20 seconds, 40 seconds, etc.).

## Switching between GVCs

// TODO remove and make it a guide

Using the console, if an [Org](/reference/org) has multiple GVCs, there will be an angle bracket `>` to the right of the current GVC name in the left menu. Click the bracket to show and select a GVC.

## GVC Namespace

The GVC namespace is used when constructing the canonical endpoint and individual location endpoints to avoid naming collision between workloads with the same name in different GVCs. The namespace is also used when performing [service-to-service](/guides/service-to-service) calls.

## GVC Locations

The cloud provider [locations](/reference/location) that [workloads](/concepts/workload) will be served from are mapped to a GVC. At least one location is required. The global and canonical endpoints will use DNS to route the request to the nearest healthy location.

<Note>Adding or removing a location will immediately provision or deprovision it from all workloads, respectively.</Note>

The available [locations](/reference/location) are scoped to an org and can be enabled/disabled globally. Any changes to the location at the org will be propagated to all GVCs using that location.

## Dedicated Load Balancer

When a dedicated load balancer is enabled on a GVC, all inbound traffic is routed through a custom cloud load balancer for each enabled location. Enabling/disabling this option can cause a brief period when connectivity fails during the period of DNS propagation.

Additional charges apply when custom load balancing is enabled.

Any [domains](/reference/domain) configured to route traffic to this GVC will also leverage the custom load balancer.

The following additional [domain](/reference/domain#dedicated-load-balancer-options) settings are available when using a custom load balancer:

1. [Custom Ports](/reference/domain#custom-ports) : Allows domains to route TCP traffic and can be configured on a variety of ports.
1. [Accept All Hosts](/reference/domain#accept-all-hosts) : Allows the domain to accept traffic for any hostname.

## Tracing

OpenTelemetry traces are supported and can be configured with the native `Control Plane` tracing provider or sent to an OpenTelemetry collector endpoint by using the `OpenTelemetry` tracing provider.

### Control Plane Tracing Provider

The Control Plane tracing provider is the default method for collecting OpenTelemetry traces. They will be accessible for exploration using Grafana by accessing `Metrics` in the sidebar menu of the Console.

To enable traces using the Console, navigate to your GVC, click on `Tracing`, and choose `Control Plane` as the metric provider. Then, configure the sampling percentage and, optionally, the Custom Tags.

Here is an example of a GVC with enabled tracing:

```yaml YAML
kind: gvc
name: online-boutique
spec:
  staticPlacement:
    locationLinks:
      - //location/aws-eu-central-1
      - //location/azure-eastus2
      - //location/gcp-us-west1
  tracing:
    provider:
      controlPlane: {}
    customTags: {}
    sampling: 100
```

### OpenTelemetry Tracing Provider

Similarly, traces can be sent to an OTEL collector endpoint using the `OpenTelemetry` tracing provider.

For details, see the [Online Boutique](https://github.com/controlplane-com/examples/blob/main/examples/online-boutique/README.md) example.

## Pull Secrets

Pull secrets are [secrets](/reference/secret) that are assigned to a GVC and used by [workloads](/concepts/workload) when authentication is required when pulling an image from a private registry.

Only [Docker](/reference/secret#docker), [Amazon ECR](/reference/secret#ecr), and [GCP](/reference/secret#google-cloud-platform-gcp) secrets types are supported for pull secrets.

<Tip>

If the image was pushed to the Control Plane registry for the same [Org](/reference/org), no pull secret is required when a workload pulls from the image from the same Org.

</Tip>

Multiple pull secrets can be assigned to a GVC. A [workload's container](/reference/workload/containers) will use the appropriate secret when pulling the image from a private registry. If there are multiple secrets, the container will cycle through each one.

If authentication fails, the deployment will not be updated and the image pull will have an exponential backoff retry starting at 10 seconds and ending at 5 minutes (e.g., 10 seconds, 20 seconds, 40 seconds, etc.).

## Environment Variables

TODO make its own page

You may set environment variables at the GVC level, which can then be inherited by any of the GVC's workloads. To inherit GVC environment variables, a container must have its `inheritEnv` property set to true. For more information about how environment variables work in Control Plane, please see the environment variables section of the [workload reference](/reference/workload#environment-variables) page.

## Sticky Sessions

Add the following [tags](/reference/misc#tags) and desired values to a GVC to enable sticky sessions for **ALL** [Workloads](/concepts/workload) within the GVC:

1. `cpln/sessionCookie`
   - The name of the session cookie.
2. `cpln/sessionDuration`
   - The Golang duration for the maximum session length (e.g., 300s, 30m, etc.).
   - Review this [link](https://pkg.go.dev/time#ParseDuration) for the proper Golang duration string format.

Once these tags are set, soft session affinity based on a cookie will consistently route requests to the same replica. The affinity to a particular replica will be lost if the replica restarts.

### How to add Tags using the UI

TODO remove

1. Browse to the [Console UI](https://console.cpln.io/) and select the desired GVC.
2. Click the `Tags` link in the middle context menu.
3. Click `Edit Tags`.
4. Enter the string `cpln/sessionCookie` in the `Tag Key` text box and enter the desired cookie name in the `Tag Value` text box. Click `Add Tag`.
5. Enter the string `cpln/sessionDuration` in the `Tag Key` text box and enter the desired duration in the `Tag Value` text box. Click `Add Tag`.
6. Click `Save`.

### How to add Tags using the CLI

TODO remove

Execute the following CLI command (substitute the GVC_NAME, ORG_NAME, COOKIE_NAME, DURATION tokens) to add the requires Tags to a GVC:

```bash
cpln gvc tag GVC_NAME --tag cpln/sessionCookie=COOKIE_NAME --tag cpln/sessionDuration=DURATION --org ORG_NAME
```

## Export GVC

TODO remove and make it a guide

Using the console UI, when a GVC is selected, an `Export GVC` link is available which will save (as a local multi-document YAML manifest file) the GVC and all associated resources ([Identities](/reference/identity), [Volume Sets](/reference/volumeset) and [Workloads](/concepts/workload)).

Links to other resources are relative within the exported file. This allows the file to be easily used to backup and restore an entire GVC. It can also be used when promoting to other [Orgs](/reference/org).

The export doesn't contain any referenced [Orgs](/reference/org) resources, such as, [Secrets](/reference/secret), [Cloud Accounts](/reference/cloudaccount), and [Agents](/reference/agent). These resources would need to be exported separately.

## Guides

- [Create a GVC](/guides/create-a-gvc)

## Permissions

The permissions below are used to define [policies](/reference/policy) together with one or more of the four
[principal types](/concepts/principal_types):

| Permission | Description          | Implies                            |
| :--------- | :------------------- | :--------------------------------- |
| create     | Create new gvcs      |                                    |
| delete     | Delete existing gvcs |                                    |
| edit       | Modify existing gvcs | view                               |
| manage     | Full access          | create, delete, edit, manage, view |
| view       | Read-only access     |                                    |

## API Reference

Click to see [API Agent Reference](/api-reference/agent)

## CLI Reference

Click to see [CLI Agent Reference](/references/cli/agent)

## Terraform Reference

Click to see [Terraform Agent Resource](/references/terraform/resources/cpln_gvc)

Click to see [Terraform Agent Data Source](/references/terraform/data-sources/cpln_gvc)


### 'Identity'
**Path**: `objects/identity.mdx`

---
title: 'Identity'
---

## Overview

**Identity** (also known as a workload identity) is one of the four Control Plane [principal types](/concepts/principal_types) (users, service accounts, groups, and identities).

A [workload](/concepts/workload) needing to consume cloud resources from one or more cloud providers (e.g., AWS, Azure, and GCP) without storing credentials or needing to communicate to endpoints within a private network - must be assigned an **identity**.

An **identity** is a named object that allows an authorized administrator to define:

### Cloud Access (Universal Cloud Identity)

- Least-privilege access rules allowed on cloud resources across cloud providers. There can only be one account each being referenced from a particular identity. In other words, you can have one account in Azure and one account in GCP, but not two different accounts in GCP in the same identity. You define access policy granted to the identity within the three clouds, of course, you can use one, two or three clouds, depending on what the workload needs access to.

TODO is ngs considered a cloud? if so, make it four instead of three clouds. Mention ngs here anyway.

TODO visit all pages and remove references when mentioning other objects, it's too much, maybe add a related objects section and then add the reference there.

### Network Resources (Cloud Wormhole)

- Network traversal rules from [workloads](/concepts/workload) into specific endpoints in private networks (e.g., a VPC). These rules connect an [agent](/reference/agent) in a private network to the Control Plane fabric allowing [workloads](/concepts/workload) to selectively access TCP endpoints inside private networks where [agents](/reference/agent) are installed and running.

## TODO explain the default access rights on cpln of a workload without identity

## TODO explain it is also needed for access to secrets

## TODO add a label here for rest of the explanation

An **identity** is scoped to a [GVC](/reference/gvc) and can be assigned to multiple [workloads](/concepts/workload) within the same [GVC](/reference/gvc) needing the same cloud resources and network access.

A [workload](/concepts/workload) can be assigned exactly one **identity**. An **identity** is only required when a [workload](/concepts/workload) needs to consume cloud resources without embedding credentials and/or when a [workload](/concepts/workload) needs to consume resources in a private network such as a VPC. If neither is required, a [workload](/concepts/workload) can operate **without** assigning it an **identity**.

Once configured, an **identity** assigned to a [workload](/concepts/workload) enables it to:

- Access specific resources of AWS, Azure, and/or GCP
- Tunnel [workload](/concepts/workload) network requests to specific TCP endpoints within VPCs or other private networks. (Tunneling network traffic from [workloads](/concepts/workload) to specific TCP hosts and ports is facilitated using [agents](/reference/agent). This capability is referred to as “wormholes”.)

<Warning>

Identities are powerful Control Plane resources that can be granted any permission to your cloud environment. The ability to create identities should only be given to administrators by using a [policy](/reference/policy).

</Warning>

## Guides

- [Create an Identity](/guides/create-an-identity)

## Permissions

The permissions below are used to define [policies](/reference/policy) together with one or more of the four
[principal types](/concepts/principal_types):

| Permission | Description                                                | Implies                                 |
| :--------- | :--------------------------------------------------------- | :-------------------------------------- |
| create     | Create new identities                                      |                                         |
| delete     | Delete existing identities                                 |                                         |
| edit       | Modify existing identities                                 | view                                    |
| manage     | Full access                                                | create, delete, edit, manage, use, view |
| use        | Refer to this identity from other entities (workload, etc) | view                                    |
| view       | Read-only access                                           |                                         |

## API Reference

Click to see [API Agent Reference](/api-reference/agent)

## CLI Reference

Click to see [CLI Agent Reference](/references/cli/agent)

## Terraform Reference

Click to see [Terraform Agent Resource](/references/terraform/resources/cpln_gvc)

Click to see [Terraform Agent Data Source](/references/terraform/data-sources/cpln_gvc)


### 'Image'
**Path**: `objects/image.mdx`

---
title: 'Image'
---

## Overview

An [image](https://www.docker.com/resources/what-container) is a "lightweight, standalone, executable package of software that includes everything needed to run an application: code, runtime, system tools, system libraries, and settings".

Control Plane offers its users their own hosted private image registry. Your application will be packaged and stored as an image and will be served by a [Workload](/concepts/workload).

When configuring the source of the [Workload's](/concepts/workload) container image, you have the option of using either an external private/public image registries, such as [Docker Hub](https://hub.docker.com/), or the internal private image registry offered by the platform.

The [CLI](/reference/cli#image-build) contains the functionality to build and push your application to your private image registry.

## Benefits

The benefits of using your Org's private image registry are:

- No [Pull Secrets](/reference/secret) are required when configuring your workload.
- Minimizes latency when pulling the image into your container.
- Requires access permissions when pushing/pulling from outside the platform (e.g. using `Docker push/pull`).

## TODO Limits section

Mention the size limit for each layer, or a total limit if there is one, also any limit about the count of images. Limitation of causing egress with pulling images from outside.

## Minimum Policy

### Push

At a minimum, the `create` permission must be bound to the principal pushing an image to an org's private registry.

Using the console UI, follow these steps to create a least privileged [policy](/reference/policy) which will allow a principal to push an image:

1. Click `Policies` in the left menu bar and click the `New` button at the top of the form.
2. Enter a policy name, select `image` from the Target Kind pulldown, and enable the `Target All Images` button. Click the `Next` button.
3. Click `Add Binding`.
4. Select the `create` permission. Select the principal type that will be pushing the image from the top menu bar and select the principal. Click `Add`.
5. Click `Create`.

The policy is now active and the principal has the ability to push images to the org's private registry.

### Pull

At a minimum, the `pull` permission must be bound to a principal pulling an image from an org's private registry.

Unless the [policy](/reference/policy) targets all images, a [query](/reference/cli#query) must be created with the image names (without the tag) that the principal is allowed to pull. That [query](/reference/cli#query) uses the `property` parameter and can only be created/updated using [cpln apply](/guides/cpln-apply) or the CLI's [cpln profile](/reference/cli#policy) command.

Below is a sample JSON manifest used as input to `cpln apply`.

**Notice that the `property` parameter is equal to `repository`.**

Update the `POLICY_NAME`, `ORG_NAME`, `USER_EMAIL`, `SERVICE_ACCOUNT_NAME`, and `IMAGE_NAME` tokens.

The `principalLinks` can refer to a user or service account.

```json JSON
{
  "kind": "policy",
  "name": "POLICY_NAME",
  "description": "",
  "tags": {},
  "origin": "default",
  "bindings": [
    {
      "permissions": ["pull"],
      "principalLinks": ["/org/ORG_NAME/user/USER_EMAIL", "/org/ORG_NAME/serviceaccount/SERVICE_ACCOUNT_NAME"]
    }
  ],
  "targetKind": "image",
  "targetLinks": [],
  "targetQuery": {
    "kind": "image",
    "fetch": "items",
    "spec": {
      "match": "all",
      "terms": [
        {
          "op": "=",
          "property": "repository",
          "value": "IMAGE_NAME"
        }
      ]
    }
  }
}
```

Once the policy is active, the principal will have the ability to pull images using any Docker compatible tool (e.g., `docker pull ...`).

## Guides

- [Pull an Image](/guides/image/pull-an-image)
- [Push an Image](/guides/image/push-an-image)
- [Copy an Image](/guides/image/copy-an-image)
- [Update an Image](/guides/image/update-an-image)

## Permissions

The permissions below are used to define [policies](/reference/policy) together with one or more of the four
[principal types](/concepts/principal_types):

| Permission | Description                                              | Implies                                  |
| :--------- | :------------------------------------------------------- | :--------------------------------------- |
| create     | Create new image. You can push if you can create images. | pull                                     |
| delete     | Delete                                                   |                                          |
| edit       | Modify existing image (only tags can be changed)         | view                                     |
| manage     | Full access                                              | create, delete, edit, manage, pull, view |
| pull       | Image can be pulled                                      | view                                     |
| view       | Read-only access                                         |                                          |

## API Reference

Click to see [API Agent Reference](/api-reference/agent)

## CLI Reference

Click to see [CLI Agent Reference](/references/cli/agent)

## Terraform Reference

Click to see [Terraform Agent Resource](/references/terraform/resources/cpln_gvc)

Click to see [Terraform Agent Data Source](/references/terraform/data-sources/cpln_gvc)


### 'IP Set'
**Path**: `objects/ipset.mdx`

---
title: 'IP Set'
---

## Overview

An ipSet reserves a public IP address for each location configured within a Global Virtual Cloud
([GVC](gvc)). The public IP address is stored in the object’s status. When a new location is added to a
[GVC](gvc), a new IP address is automatically created if one does not already exist for that location.
To prevent ongoing charges, IP addresses must be explicitly released once they are no longer needed.

// TODO mention that it is a one to one match with a single workload, so it generates ip address for workload's locations

TODO how would it work with byok locations?

## Binding

An IP Set can be linked to a [workload](workload) through its `spec.link` property. When linking to a [workload](workload), the workload must have [direct load balancer](workload/direct-load-balancer) enabled. A [workload](workload) MUST link to an IP Set via its [direct load balancer](workload/direct-load-balancer). The IP Set will only function if the cross-linking is properly configured ([workload](workload) and IP Set link to each other).

### Linking to Workload from IP Set
``` json
{
  "type": "ipSet",
  "name": "example",
  "spec": {
    "link": "/org/example-org/gvc/example-gvc/workload/example-workload",
    "locations": [
      {
        "name": "aws-us-west-2",
        "retentionPolicy": "keep"
      }
    ]
  }
}
```

### Linking to IP Set from Workload
``` json
{
  "spec": {
    "containers": [
      {
        "name": "advanced-options-example",
        "args": [],
        "cpu": "50m",
        "env": [],
        "image": "kennethreitz/httpbin:latest",
        "memory": "128Mi",
        "port": 8080
      }
    ],
    "loadBalancer": {
      "direct": {
        "enabled": true,
        "ipSet": "/org/example-org/ipset/example",
        "ports": [
          {
            "externalPort": 443,
            "protocol": "TCP",
            "containerPort": 8080
          }
        ]
      }
    }
  }
}
```

## Releasing
To delete an IP address from a location, you can set the `retentionPolicy` field
for the specific location to `"free"`.

<Note>
  An IP address will not be released unless it is no longer in use (no workload is
  linked, gvc location not active, etc.)
</Note>

### Example
``` json
{
  "type": "ipSet",
  "name": "example",
  "spec": {
    "link": "/org/example-org/gvc/example-gvc/workload/example-workload",
    "locations": [
      {
        "name": "aws-us-west-2",
        "retentionPolicy": "free"
      }
    ]
  }
}
```

## Status

Once the IP Set is initialized, its status will be updated with the new IP address(es).

### Example
``` json
{
  "type": "ipSet",
  "name": "example",
  "spec": {
    "link": "/org/example-org/gvc/example-gvc/workload/example-workload",
    "locations": [
      {
        "name": "aws-us-west-2",
        "retentionPolicy": "keep"
      }
    ]
  },
  "status": {
    "ipAddresses": [
      {
        "name": "aws-us-west-2",
        "ip": "10.20.30.40",
        "id": "eipalloc-0a1b2c3d4e5f67890",
        "state": "bound",
        "created": "2024-07-30T14:18:36.327Z"
      }
    ]
  }
}
```

## Guides

- [Name](/guides)

## Permissions

The permissions below are used to define [policies](/reference/policy) together with one or more of the four
[principal types](/concepts/principal_types):

| Permission | Description                 | Implies                                 |
| :--------- | :-------------------------- | :-------------------------------------- |
| create     | Create new ip sets          |                                         |
| delete     | Delete ip sets              |                                         |
| edit       | Modify existing resources   | view                                    |
| manage     | Full access                 | create, delete, edit, manage, view      |
| view       | Read-only access            |                                         |

## API Reference

Click to see [API Agent Reference](/api-reference/agent)

## CLI Reference

Click to see [CLI Agent Reference](/references/cli/agent)

## Terraform Reference

Click to see [Terraform Agent Resource](/references/terraform/resources/cpln_gvc)

Click to see [Terraform Agent Data Source](/references/terraform/data-sources/cpln_gvc)


### 'Kubernetes'
**Path**: `objects/kubernetes.mdx`

---
title: 'Kubernetes'
---

## Overview

Might refer to self-hosted section directly?

## Guides

- [Name](/guides)

## Permissions

The permissions below are used to define [policies](/reference/policy) together with one or more of the four
[principal types](/concepts/principal_types):

| Permission | Description                 | Implies                                 |
| :--------- | :-------------------------- | :-------------------------------------- |
| create     | Create new agents           |                                         |
| delete     | Delete service agents       |                                         |
| edit       | Modify existing agents      | view                                    |
| manage     | Full access                 | create, delete, edit, manage, use, view |
| use        | Use an agent in an identity | view                                    |
| view       | Read-only access            |                                         |

## API Reference

Click to see [API Agent Reference](/api-reference/agent)

## CLI Reference

Click to see [CLI Agent Reference](/references/cli/agent)

## Terraform Reference

Click to see [Terraform Agent Resource](/references/terraform/resources/cpln_gvc)

Click to see [Terraform Agent Data Source](/references/terraform/data-sources/cpln_gvc)


### 'Location'
**Path**: `objects/location.mdx`

---
title: 'Location'
---

## Overview

Locations show the available geographical locations for each of the following cloud providers:

- Amazon Web Services (AWS)
- Google Cloud Platform (GCP)
- Microsoft Azure

Locations are scoped to an [org](/reference/org) and the [org](/reference/org) administrator can turn off/on the locations that are permitted when configuring a [GVC](/reference/gvc).

By default, all locations are enabled. If a location is disabled, any [workloads](/concepts/workload) within that location will be removed. Further, if a location is enabled, all [workloads](/concepts/workload) will be provisioned to that location.

<Note>

If a company is restricted for legal or compliance reasons to only use certain cloud providers, disabling those providers will ensure that workloads will not be deployed to those providers.

</Note>

## Locations

Control Plane can enable any cloud provider location.

If a location is not shown, please email [support@controlplane.com](mailto:support@controlplane.com) with the provider and location and it will be provisioned.

## BYOK Locations

BYOK (Bring Your Own Kubernetes) enables you to add new locations by registering your own Kubernetes clusters as locations in the Control Plane. 
For a guide on how to create new BYOK locations and further details, [refer to the BYOK documentation](/byok/overview).

## Built-in Tags

Each location has the following built-in [tags](/reference/misc#tags):

- `cpln/city=VALUE`
- `cpln/country=VALUE`
- `cpln/continent=VALUE`

## Guides

- [Name](/guides)

## Permissions

The permissions below are used to define [policies](/reference/policy) together with one or more of the four
[principal types](/concepts/principal_types):

| Permission | Description                              | Implies                         |
| :--------- | :--------------------------------------- | :------------------------------ |
| create     | Create new locations                     |                                 |
| edit       | Modify existing locations                | view                            |
| manage     | Full access                              | create, edit, manage, use, view |
| use        | Use this location for workload placement | view                            |
| view       | Read-only access                         |                                 |

## API Reference

Click to see [API Agent Reference](/api-reference/agent)

## CLI Reference

Click to see [CLI Agent Reference](/references/cli/agent)

## Terraform Reference

Click to see [Terraform Agent Resource](/references/terraform/resources/cpln_gvc)

Click to see [Terraform Agent Data Source](/references/terraform/data-sources/cpln_gvc)


### 'Policy'
**Path**: `objects/policy.mdx`

---
title: 'Policy'
---

## Overview

A policy governs resource access within an [org](/reference/org) to a set of principals. It enables fine-grained authorization rules to define the minimum amount of permissions required when accessing resources of the platform.

TODO in general use the word "kind" here instead of resource, also use item instead of resource in docs too. Have a page for defining cpln terms (query, spec, status, kind, context, profile, token etc)

A policy consists of:

- A resource, and
- One or more bindings

### Resource

A resource is a Control Plane object (e.g., [secret](/reference/secret), [workload](/concepts/workload), [GVC](/reference/gvc), etc.).

A policy can be configured to target all or specific resources within your [org](/reference/org).

For example, a policy can target all the [GVCs](/reference/gvc) within your [org](/reference/org), or specifically GVC A and GVC B.

Specific resources can be assigned directly or dynamically (using a [query](/reference/misc#tags)).

### Bindings

A binding is a mapping between:

- A set of permissions (e.g., create, delete, etc.), and
- Principal membership

The [set of permissions](/reference/policy#permissions) that can be assigned to a policy are unique to each resource.

Principals can be [users](/reference/user), [groups](/reference/group), [service accounts](/reference/serviceaccount), and [identities](/reference/identity).

## Examples

- Allow a [user](/reference/user) or [group](/reference/group) access to the console
- Allow a [service account](/reference/serviceaccount) to execute CLI commands
- Allow an [identity](/reference/identity) access to reveal a secret. The [identity](/reference/identity) can then be associated with a [workload](/concepts/workload). The workload's containers will have permissions to access the [secret](/reference/secret) and use it as an environment variable.

## Resource Permissions

Each resource has a set of permissions that can be assigned to a policy.

Expand the dropdown below and click on a resource to view their assignable permissions.

<Accordion title="Resources">

After clicking on a link, expand the `Examples` dropdown to view the list.

- [Agent](/reference/cli#agent-permissions)
- [Audit Context](/reference/cli#auditctx-permissions)
- [Cloud Account](/reference/cli#cloudaccount-permissions)
- [Domain](/reference/cli#domain-permissions)
- [Group](/reference/cli#group-permissions)
- [GVC (Global Virtual Cloud)](/reference/cli#gvc-permissions)
- [Identity](/reference/cli#identity-permissions)
- [Image](/reference/cli#image-permissions)
- [Location](/reference/cli#location-permissions)
- [Org](/reference/cli#org-permissions)
- [Policy](/reference/cli#policy-permissions)
- [Quota](/reference/cli#quota-permissions)
- [Secret](/reference/cli#secret-permissions)
- [Service Account](/reference/cli#serviceaccount-permissions)
- [User](/reference/cli#user-permissions)
- [Volume Set](/reference/cli#volumeset-permissions)
- [Workload](/reference/cli#workload-permissions)

</Accordion>

## Built-in Policies

Each [org](/reference/org) has the following built-in policies for each resource (agent, GVC, etc.):

| Policy Name         | Description                                                    | Target    | Permission | Group                               | Service Account                                          |
| :------------------ | :------------------------------------------------------------- | :-------- | :--------- | :---------------------------------- | :------------------------------------------------------- |
| superusers-RESOURCE | Built-in policy granting full access to the superusers group   | All Items | manage     | [superusers](/reference/group#built-in-groups) | [controlplane](/reference/serviceaccount#built-in-service-accounts) |
| viewers-RESOURCE    | Built-in policy granting read-only access to the viewers group | All Items | view       | [viewers](/reference/group#built-in-groups)    | none                                                     |


## Guides

- [Create a Policy](/guides/create-a-policy)

## Permissions

The permissions below are used to define [policies](/reference/policy) together with one or more of the four
[principal types](/concepts/principal_types):

| Permission | Description              | Implies                            |
| :--------- | :----------------------- | :--------------------------------- |
| create     | Create new policies      |                                    |
| delete     | Delete existing policies |                                    |
| edit       | Modify existing policies | view                               |
| manage     | Full access              | create, delete, edit, manage, view |
| view       | Read-only view           |                                    |

## API Reference

Click to see [API Agent Reference](/api-reference/agent)

## CLI Reference

Click to see [CLI Agent Reference](/references/cli/agent)

## Terraform Reference

Click to see [Terraform Agent Resource](/references/terraform/resources/cpln_gvc)

Click to see [Terraform Agent Data Source](/references/terraform/data-sources/cpln_gvc)


### 'Quota'
**Path**: `objects/quota.mdx`

---
title: 'Quota'
---

## Overview

The quotas page will display the currently used and allowed allocation of Control Plane resources for your [org](/reference/org).

Current resources with a quota:

TODO update this list

| Resource           | Description                                |
| :----------------- | :----------------------------------------- |
| agents             | Max number of agents                       |
| domains            | Max number of domains                      |
| identities-per-gvc | Max number of workload identities in a gvc |
| workloads-per-gvc  | Max numbers of workloads in a gvc          |

If your [org](/reference/org) requires additional resources, please email [support@controlplane.com](mailto:support@controlplane.com)

TODO show user feedback of UI in a guide and refer to it here

## Guides

- [Name](/guides)

## Permissions

The permissions below are used to define [policies](/reference/policy) together with one or more of the four
[principal types](/concepts/principal_types):

| Permission | Description            | Implies                    |
| :--------- | :--------------------- | :------------------------- |
| create     | Create new quotas      |                            |
| edit       | Modify existing quotas | view                       |
| manage     | Full access            | create, edit, manage, view |
| view       | Read-only access       |                            |

## API Reference

Click to see [API Agent Reference](/api-reference/agent)

## CLI Reference

Click to see [CLI Agent Reference](/references/cli/agent)

## Terraform Reference

Click to see [Terraform Agent Resource](/references/terraform/resources/cpln_gvc)

Click to see [Terraform Agent Data Source](/references/terraform/data-sources/cpln_gvc)


### 'Secret'
**Path**: `objects/secret.mdx`

---
title: 'Secret'
---

## Overview

Secrets are used to store strongly-encrypted information. All secrets can be injected into containers through the use of [environment variables](/reference/workload#environment-variables).

In addition to optionally being injected into containers as [environment variables](/reference/workload#environment-variables), secrets are also used for:

1. Image registry ([Docker](#docker), [ECR](#ecr), and [GCP](#google-cloud-platform-gcp)) pull secrets, enabling workloads in a [GVC](/reference/gvc) to pull images from private repositories.
2. Enabling Control Plane to manage policies in Azure, using the [Azure SDK](#azure-sdk) and [Azure Connector](#azure-connector) secret type.

<Note>

A [workload identity](/reference/identity) **MUST** be granted the [reveal permission](#reveal-permission) on a secret to have its value injected at runtime.

</Note>

## Secret Types

- [Amazon Web Services (AWS)](#amazon-web-services-aws)
- [Azure SDK](#azure-sdk)
- [Azure Connector](#azure-connector)
- [Docker](#docker)
- [Dictionary](#dictionary)
- [ECR](#ecr)
- [Google Cloud Platform (GCP)](#google-cloud-platform-gcp)
- [Keypair](#keypair)
- [Opaque](#opaque)
- [NATS Account](#nats-account)
- [TLS](#tls)
- [Username & Password](#username-and-password)

### Amazon Web Services (AWS)

The AWS secret type enables a [workload](/concepts/workload) to consume services from AWS. It is used in cases where an [identity](/reference/identity) isn't used.

For example, when an Org does not wish to create a [cloud account](/reference/cloudaccount), or to create cloud access policy as part of an [identity](/reference/identity) definition.

The recommended approach to consuming services from AWS is not to use a AWS secret, but rather to:

1. Create a [cloud account](/reference/cloudaccount).
2. Create an [identity](/reference/identity).
3. Defining a cloud access policy for the AWS account as part of the identity.

In cases where an Org wishes to not leverage the [identity](/reference/identity) feature, in order to use an AWS secret, simply read the secret from the environment variable and convey its set of values to AWS using any AWS API you wish.

The AWS secret schema consists of:

- Secret Key
- Access Key
- Role ARN (Optional)
- External ID (Optional)

For an existing AWS user, these values are obtained from the [AWS IAM Dashboard](https://console.aws.amazon.com/iam/home).

Refer to [these instruction](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_users_create.html) to create a new AWS IAM user in your AWS account.

### Azure SDK

- Used to store [Azure SDK](/reference/cloudaccount#azure-sdk) credentials.
- When creating a [Cloud Account using the Azure SDK](/reference/cloudaccount#azure-sdk), a JSON file is generated containing the credentials. This file is uploaded and automatically stored as an Azure-SDK secret.

- Sample Azure-SDK secret content:

  ```json JSON
  {
    "subscriptionId": "2cd2674e-4f89-4a1f-b420-7a1361b46ef7",
    "tenantId": "292f5674-78b0-488b-9ff8-6d30d77f38d9",
    "clientId": "649746ce-d862-49d5-a5eb-7d5aad90f54e",
    "clientSecret": "CONFIDENTIAL"
  }
  ```

- If the client secret has been compromised or needs to be updated, the content of the secret can be updated using the console or CLI and will be used by the associated Cloud Accounts.

### Azure Connector

- Used to store [Azure Function App](/reference/cloudaccount#azure-connector) credentials.
- When creating a [Cloud Account using the Azure Connector](/reference/cloudaccount#azure-connector), the `deployment URL` and `code` will be saved.
- These values can be updated using the console or the [CLI](/reference/cli#secret-update).

### Docker

The Docker secret type is used when a [container](/reference/workload/containers) pulls an [image](/reference/workload#images) from a private Docker compatible repository, such as a Org's private repository at Control Plane, [Docker Hub](https://hub.docker.com/), or [Azure Container Registry](https://docs.microsoft.com/en-us/azure/container-registry/).

An authorized user then assigns a secret of this type to a [GVC Pull Secret](/reference/gvc#pull-secrets).

[Workloads](/concepts/workload) in the [GVC](/reference/gvc) can then pull their image using the secret.

The contents of a Docker secret follows this syntax:

```json JSON
{
  "auths": {
    "REPOSITORY_URL": {
      "username": "USERNAME",
      "password": "PASSWORD"
    }
  }
}
```

#### Control Plane

To create a Docker secret targeting a private repository hosted at Control Plane, a [Service Account](/reference/serviceaccount) at the source Org, bound with the [pull permission](/reference/image#pull) is required.

Example:

```json JSON
{
  "auths": {
    "ORG_NAME.registry.cpln.io": {
      "username": "<token>",
      "password": "SERVICE_ACCOUNT_KEY"
    }
  }
}
```

<Note>

The `username` is the literal string `<token>`.

</Note>

#### Docker Hub

To create a Docker secret targeting Docker Hub, a Docker username and password (which has permissions to pull the images) are required.

There are two ways to create the secret content:

1. `Username & Password` Keys

   Example:

   ```json JSON
   {
     "auths": {
       "https://index.docker.io/v1/": {
         "username": "USERNAME",
         "password": "PASSWORD"
       }
     }
   }
   ```

2. `auth` Key

   - When using a password, the value of the `auth` key is the base64 encoded result of the string `USERNAME:PASSWORD`.

   Example:

   ```json JSON
   {
     "auths": {
       "https://index.docker.io/v1/": {
         "auth": "BASE_64_ENCODING(USERNAME:PASSWORD)"
       }
     }
   }
   ```

   - When using a [Docker Access Token](https://docs.docker.com/docker-hub/access-tokens/), the value of the `auth` key is the base64 encoded result of the string `USERNAME:DOCKER_ACCESS_TOKEN`.

   Example:

   ```json JSON
   {
     "auths": {
       "https://index.docker.io/v1/": {
         "auth": "BASE_64_ENCODING(USERNAME:DOCKER_ACCESS_TOKEN)"
       }
     }
   }
   ```

  <Tip>

    When performing the base64 encoding, remember to include the colon ( : ) when concatenating the username and password/token.

    The `base64` utility can be used to easily encode the string.

    Example: `echo -n USERNAME:PASSWORD | base64`

  </Tip>

#### Azure Container Registry

To create a Docker secret targeting the [Azure Container Registry](https://docs.microsoft.com/en-us/azure/container-registry/), the following properties are required:

- Repository URL
- Service Principal ID
- Password

An `Azure Service Principal` is recommended as the identity used to pull images.

Refer to this [article](https://docs.microsoft.com/en-us/azure/container-registry/container-registry-auth-service-principal) to create an Azure Service Principal that only has the pull permission.

- The format of the repository URI is: `REGISTRY_NAME.azurecr.io` and can be obtained from the `Azure Container Registry` section of the [Azure Portal](https://portal.azure.com/).
- The USERNAME is the ID GUID of the Service Principal (e.g., ed0a30b4-5cd0-44af-864a-cf825b0ceeb6).
- The PASSWORD is generated when creating the Service Principal. **By default, the password expires after 1 year.**

<Tip>

To increase the expiration length of the password, use the `--years` flag when running the `az ad sp create-for-rbac` command during the creation of a Service Principal.

</Tip>

Example:

```json JSON
{
  "auths": {
    "REGISTRY_NAME.azurecr.io": {
      "username": "APP_ID",
      "password": "PASSWORD"
    }
  }
}
```

#### GitHub Container Registry

To create a Docker secret targeting GitHub, a GitHub [personal access token](https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/creating-a-personal-access-token) (which has the `read:packages` scope) is required.

Example:

```json JSON
{
  "auths": {
    "ghcr.io": {
      "username": "controlplane",
      "password": "PERSONAL_ACCESS_TOKEN"
    }
  }
}
```

### Dictionary

- Used to securely store key/value pairs that can be used by a [workload's environment variables](/reference/workload#environment-variables).
- Multiple key/value pairs can be added to a single dictionary secret.

### ECR

The Elastic Container Registry (ECR) secret type is used when a [workload](/concepts/workload) pulls a container image from a private AWS ECR repository.

This secret type is used when configuring a [GVC's Pull Secret](/reference/gvc#pull-secrets). [Workloads](/concepts/workload) that are connected to that [GVC](/reference/gvc) will have access to the secret when pulling the image.

The ECR secret consists of:

- AWS Secret Key
- AWS Access Key
- AWS Role ARN (Optional; This role will be assumed after authentication with the IAM user’s programmatic access)
- ECR Repository URIs (e.g., AWS_ACCOUNT_ID.dkr.ecr.REGION.amazonaws.com/REPO_NAME)
- External ID (Optional)

<Tip>Multiple repositories can be added to the same ECR secret.</Tip>

To obtain the keys required to create an ECR secret, from the [AWS IAM Dashboard](https://console.aws.amazon.com/iam/home):

1. Add a new IAM User with programmatic access.
2. Create an Access Token for the new user and take note/download the secret and access key.
3. Create a new IAM Policy for the `Elastic Container Registry` service with the `Read` action on the specific repositories.
4. Attach the new IAM Policy to the new IAM User.
5. Optionally, impersonate the IAM user with its credentials and try to pull an image locally as described [here.](https://docs.aws.amazon.com/AmazonECR/latest/userguide/registry_auth.html)
6. Create the ECR secret using either the [UI Console](https://console.cpln.io) or [CLI](/reference/cli#secret-create-ecr).

#### Amazon ECR Helper Links

- [ECR Dashboard](https://us-west-2.console.aws.amazon.com/ecr/repositories)
- [Private registry concepts](https://docs.aws.amazon.com/AmazonECR/latest/userguide/Registries.html)

### Google Cloud Platform (GCP)

- Similar to a [Docker](#docker) and [ECR](#ecr) secret, a GCP secret is used when a [workload](/concepts/workload) pulls a container image from a private `Google Container Registry`.
- This secret type is used when configuring a [GVC Pull Secret](/reference/gvc#pull-secrets). [Workloads](/concepts/workload) that are connected to that [GVC](/reference/gvc) will have access to the secret when pulling the image.
- Using the UI, the secret JSON text can be in a file that is uploaded or pasted into the textbox.
- Below is a sample of a GCP secret. The values can be obtained from your GCP account.

```json JSON
{
  "type": "service_account",
  "project_id": "PROJECT_ID",
  "private_key_id": "PRIVATE_KEY_ID",
  "private_key": "PRIVATE_KEY_CERTIFICATE",
  "client_email": "CLIENT_EMAIL",
  "client_id": "CLIENT_ID",
  "auth_uri": "https://accounts.google.com/o/oauth2/auth",
  "token_uri": "https://oauth2.googleapis.com/token",
  "auth_provider_x509_cert_url": "https://www.googleapis.com/oauth2/v1/certs",
  "client_x509_cert_url": "X509_CERTIFICATE_URL"
}
```

### Keypair

- Used to securely store a keypair that can be used by a [workload's environment variables](/reference/workload#environment-variables).
- A keypair secret consists of:
  - Secret key
  - Public key
  - Passphrase (required if the secret key is encrypted)
- Using the UI, the secret and public key text can be in a file that is uploaded or pasted into the textbox.
- The keys will be validated and the secret will only be created or updated if they are valid PEM-encoded certificates.

<Accordion title="Sample Key Pair">

**Sample secret key:**

```
-----BEGIN RSA PRIVATE KEY-----
Proc-Type: 4,ENCRYPTED
DEK-Info: DES-EDE3-CBC,9A26BB15304B18E7

ZdBgMExsvIJEsIFDMQ02xh4nDnhXEGUNu7LiWIZjn9WS6QB2jApyOFOBWmp0lK6L
dIJ+Mb8wMeHtkiKS6ZbYeea8M29kwEejZRnKl1Wq0EFycdwbONtbcbjzF+tQGEBT
gQQgkY7wjDWl8HwjFEA+NUuitzi6uI2xWlQpFdUrmqJAZCbxNFa0aM8nW6jnitvP
616ps3HjLnWCjoyqS4hWxiWmt+VE3KruPnUVVV7bWlzc6jnoZcSaeqeaoQrNKguH
te2iBIMdY/uldb7Ik2Kxr2+kBRmV4YNkp1EelNi/m39VcoUHJLk1jLldzuINhbi2
IRqYZe4EEMSYdb3TkSosXa64Sz7jMBz5AxlA0n78FKlB9G5FAxaXcVYNQIlvzCbw
uXPbQd/UYKUuEI1Yn8OmGBN5xcOdgWz8hfyxA2Hq1tmo1XN6snavGe7TKbZd70N+
1yFbclB2T1z8fPcLwUZUxOl4g2DoMMHIzCSPaIe/otT8389k4H6hEulLis4lW0p3
qopL5kdpxmSGgXsX6q6CUFb/0cw9HskNT3zbzKLx2MzjFCo93IB07UxPwkCD2kb1
sLKMcpTC8a0vLaTVNYgDX7wW/YjBrCokaqk0z1whuN6iSReOtvmu5ybrq1Ksg8UQ
yvCSScM/+muKi+gbEOskQs4Ph3ZLHqAX3/XYoyBcFnPNxVHTIa5Dcju6h5gl1/uY
6tkRsHDr0Lzy8pd6jjf/ApPf9ypCuxKUO1q8PzPg2E4bmEFxc8zOB2NLvfPgFrUR
0Sbkapv/6x6nNRw75cu69c5we/atip6wst8J1MSU0fTqb6bZ3TF2pDyNEOkdkvoZ
YZ0r3hUytdT0pImoDLKoyy17mtHLLApzHyIgmR3cqtSt07ncmC5lyEBcZBrQXMa8
aZeOr8iUWQE/q+4BvoxeKsOD6ttKuFnrgl0rmMnYQsSyLJOPizrU4L1d1HMIKswm
iW+Rg7xlWmQg95m8XEWTjAb3tuNz/tGXC7Qa88HvC7YfyG69yM61oPsT83YnxcBT
C/X67lSFTYguFa3HgDZpjGq7Hc/Q7nhaoqNMEs01O6jbcmrue8IIa2FH1tTwPN0W
D7JefjCQjEghue2mjc0fovOGe9A9jvWf+gJHF3vRtFa67uQiQxge9zUzpHyVNpOj
Ve0y0HvibNTd6TSCArctJpIcwpjO3MTT5LBJ1p/8v4b4+knEKD2c69jumNbKGbWr
Wjq39M/MGNUO5SbZMO3gFCt6fgtXkOktH9pJ9iOQpYKgl7QTe2qQygfWkIm0EZRN
6EaQdNNKgENWicpKyKQ4BxoY1LYAHFHJ95VisLf3KmmOF5MwajADZQT/yth3gvht
xx21b9iudcgq/CRccSvfIPIWZKi6oaqNIXK+E3DQd40TUopLsBWzacTZn9maSZtW
RyAY1TkRn1qDR2soyhBcihrX5PZ83jnOlM3XTdfF1784g8zB9ooDnK7mUKueH1W3
hWFADMUF7uaBbo5EZ9sE+dFPzWPJLhu2j67a1iHmByqEvFY64lzq7VwwU/GE8JdA
85oEkhg1ZEPJp3OYTQfPI/CC/2fc93Exf6wmaXuss8AHehuGcKQniOZmFOKOBprv
-----END RSA PRIVATE KEY-----
```

**Sample public key:**

```
-----BEGIN PUBLIC KEY-----
MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAwrVyExI0uvRmwCAKFHiv
baAcPMcKJDa6f6TtaVo2p8jyfEhVwDTmR3FUrDDZAjh0Q8G/Up8Ob3+IJafNymCO
BhUKou+8ie7guqsbU9JrT0Zos1k/pd0aVfnAR0EpW3es/7fdkWUszU0uweeEj22m
XMlLplnqqoYOGAhuNMqGsZwBr36Bxq9EeB2O79QsAFDNkPVg7xIaYKn32j69o0Zr
ryYI8xqOYYy5Dw6CX+++YYLYiR/PkLYJTVAsxXeqyltCfb3Iv7vN5HrfoYBhndr3
NxBPkcIJZeh3Z+QzfJ5U+bB5fP/aOsEk5bPbtLzylj2KnOOM/ZxXJtOcu0xtJLd3
XwIDAQAB
-----END PUBLIC KEY-----
```

**Passphrase:**

```
cpln
```

</Accordion>

### Opaque

Opaque secrets are used to securely store any text.

When creating or updating an opaque secret, an option is available to perform a base64 decode at runtime.

To access the stored text, an [environment variables'](/reference/workload#environment-variables) value must be set to one of the following:

1. `cpln://secret/SECRET_NAME.payload`

   - If the option to perform a base64 decode at runtime is enabled, the decoded value will be returned.

2. `cpln://secret/SECRET_NAME` (without the .payload)

   - If the option to perform a base64 decode at runtime is enabled, the `encoding` property will be set to `base64`. It is the responsibility of the user to perform the base64 decode.

   Example values returned:

   `base64: "{\"payload\":\"VGhpcyBpcyBhbiBvcGFxdWUgaW4gYmFzZTY0\",\"encoding\":\"base64\"}"`

   `plain text: "{\"payload\":\"The is an opaque secret in plain text\",\"encoding\":\"plain\"}"`

### NATS Account

- Used to store NATS Account credentials.
- When creating a [Cloud Account using the Azure Connector](/reference/cloudaccount#azure-connector), the `deployment URL` and `code` will be saved.
- These values can be updated using the console or the [CLI](/reference/cli#secret-update).
- A NATS Account secret consists of:
  - Account ID
  - Private Key
- These properties will be validated and the secret will only be created or updated if they are valid.

### TLS

- Used to securely store a Transport Layer Security (TLS) secret that can be used by a [workload's environment variables](/reference/workload#environment-variables).
- A TLS secret consists of a:
  - Key
  - Certificate
  - Chain Certificate (optional if the certificate is self-signed or not part of the installed root certificates)
- Using the UI, the secret can be in a file that is uploaded or pasted into the textbox.
- The certificates will be validated and the secret will only be created or updated if they are valid PEM-encoded certificates

<Accordion title="Sample TLS">

**Sample key:**

```
-----BEGIN PRIVATE KEY-----
MIIEvgIBADANBgkqhkiG9w0BAQEFAASCBKgwggSkAgEAAoIBAQDBzN2jRf9ouoF4
XG0eUxcc4f1sP8vhW1fQXjun3cl0RsN4jRdOyTKWcls1yAxlOkwFod8d6HND9OvN
rsl7U4iJIEcJL6vTqHY7jTGXQkd9yPONMpMXYE8Dsiqtk0deoOab7fafYcvq1iWn
pvg157mJ/u9qdyU+1h8DncES30FkPsG8TsIsjx94JkTJeMmEJxtws4dfuoCk88IN
bBHLjxBQgwTu0vgMxN34b5z+esHraetDN2fqxSoTOeIlyFzeS+kwG3GK4I1hUQBi
L2TeDrnEY6qP/ZoGuyyVnsT/6pHY/BTAcH3Rgeqose7mqBT+7zlxDfHYHceuNB/l
jq0e1j69AgMBAAECggEAPGhrPZV4A2D/MlE9AhLMRYh7wd4w4tHiEWUOG0kank/g
Zhc0iK5WQmbq31y34GXHhInsThpCs5AIYFh3HSXwjS2udsKRQKxmDjH4nzldp2uX
3w9Aoiy29GP4wZoCyRBGUZxfH1cQhOazXgrBm6vbPZRldD4nMer0R+BIamWEsIYD
YjDj1pT0noLUSeqoLmGxSQ4DNIBQVZB/T8ziMcEzl6bhprT0QrapJSyD2CtA8tH1
Z8cyhmyE0CUvSkV4K2ecvVukWBJvrAYc6euPAnkS5LJrQotI5+3jJO2QawOlL6Uw
rFWBpgBrCgbzquMRpDCQ/J9/GDYaZjim4YdonboBgQKBgQD7jx3CVnG4LDz198am
spmPwKCW1ke6PhlG7zf3YR00xg9vPBYiy4obb1Jg6em1wr+iZ0dEt8fimeZXewBf
LzlrR8T1Or0eLzfbn+GlLIKGKhn2pKB/i1iolkfIonchqXRk9WNx+PzjgUqiYWRC
/1tH2BsODlVrzKL2lnbWKNIFdQKBgQDFOLedpMeYemLhrsU1TXGt1xTxAbWvOCyt
vig/huyz4SQENXyu3ImPzxIxpTHxKhUaXo/qFXn0jhqnf0LfWI4nbQUbkivb5BPr
KY9aj7XwwsY4MXW5C12Qi0lIwHOWCmfzvyS7TCMqnQb7sT4Mjmm4ydEbiI1TjlFJ
D/RFxzcDKQKBgQCehPcJyZNrrWTU0sh5rz4ZWhdYNbuJXyxqiMBJwQa4hL6hJ8oD
LyPeWe4daAmAIjLEUjSU1wK8hqKiKb54PLgAJH+20MbvyG14lm2Iul2d0dX+mIsT
FGpQAjNF+Sr9KV1RaVi7L12ct5KidKDLn0KUKVgTKXEmtxNSNEq6dYqzKQKBgDI8
zljzvnwSwNloIYgAYDK+FPGHU/Z8QrVHOQ1lmyn+8aO41DfeqZPeVW4b/GrII3QC
HnqsWdJ32EZOXoRyFFPqq2BojY+Hu6MthPy2msvncYKi5q/qOz00nchQbaEMqYon
aH3lWRfjxAGdFocwR7HwhrmSwR1FpWMNE1Yq9tJxAoGBANc0nZSy5ZlTiMWdRrTt
gFc9N/jz8OL6qLrJtX2Axyv7Vv8H/gbDg4olLR+Io38M0S1WwEHsaIJLIvJ6msjl
/LlseAW6oiO6jzhWEr0VQSLkuJn45hG/uy7t19SDuNR7W5NuEr0YbWd6fZEpR7RR
S1hFKnRRcrVqA+HjWnZ//BGi
-----END PRIVATE KEY-----

```

**Sample certificate:**

```
-----BEGIN CERTIFICATE-----
MIID+zCCAuOgAwIBAgIUEwBv3WQkP7dIiEIxyj+Wi1STz7QwDQYJKoZIhvcNAQEL
BQAwgYwxCzAJBgNVBAYTAlVTMRMwEQYDVQQIDApDYWxpZm9ybmlhMRQwEgYDVQQH
DAtMb3MgQW5nZWxlczENMAsGA1UECgwEQ1BMTjERMA8GA1UECwwIQ1BMTi1PUkcx
EDAOBgNVBAMMB2NwbG4uaW8xHjAcBgkqhkiG9w0BCQEWD3N1cHBvcnRAY3Bsbi5p
bzAeFw0yMDEwMTQxNzI4MDhaFw0zMDEwMTIxNzI4MDhaMIGMMQswCQYDVQQGEwJV
UzETMBEGA1UECAwKQ2FsaWZvcm5pYTEUMBIGA1UEBwwLTG9zIEFuZ2VsZXMxDTAL
BgNVBAoMBENQTE4xETAPBgNVBAsMCENQTE4tT1JHMRAwDgYDVQQDDAdjcGxuLmlv
MR4wHAYJKoZIhvcNAQkBFg9zdXBwb3J0QGNwbG4uaW8wggEiMA0GCSqGSIb3DQEB
AQUAA4IBDwAwggEKAoIBAQDBzN2jRf9ouoF4XG0eUxcc4f1sP8vhW1fQXjun3cl0
RsN4jRdOyTKWcls1yAxlOkwFod8d6HND9OvNrsl7U4iJIEcJL6vTqHY7jTGXQkd9
yPONMpMXYE8Dsiqtk0deoOab7fafYcvq1iWnpvg157mJ/u9qdyU+1h8DncES30Fk
PsG8TsIsjx94JkTJeMmEJxtws4dfuoCk88INbBHLjxBQgwTu0vgMxN34b5z+esHr
aetDN2fqxSoTOeIlyFzeS+kwG3GK4I1hUQBiL2TeDrnEY6qP/ZoGuyyVnsT/6pHY
/BTAcH3Rgeqose7mqBT+7zlxDfHYHceuNB/ljq0e1j69AgMBAAGjUzBRMB0GA1Ud
DgQWBBRxncC/8RRio/S9Ly8tKFS7WnTcNTAfBgNVHSMEGDAWgBRxncC/8RRio/S9
Ly8tKFS7WnTcNTAPBgNVHRMBAf8EBTADAQH/MA0GCSqGSIb3DQEBCwUAA4IBAQAr
sDZQj4K47fW6JkJbxlzZ1hd7IX6cQhI/DRIdTGR1u0kM1RtZoS0UtV5qsYV/g/S4
ChuB/aIARyTWvHKDhcT3bRGHLnoZJ8pLlQh4nEfO07SRhyeNiO4qmWM9az0nP5qD
wAXpLpmYIairzAgY7QXbk5wXbTrXli3mz14VaNoqN4s7iyLtHn5TGAXc12aMwo7M
5yn/RGxoWQoJqSQKc9nf909cR81AVCdG1dFcp7u8Ud1pTtlmiU9ZJ/YOXDCT/1hZ
YxoeotDBBOIao3Ym/3351somMoQ7Lz6hRWvG0WhDIsCXvth4XSxRkZFXgjWNuhdD
u2ZCis/EwXsqRJPkIPnL
-----END CERTIFICATE-----
```

**Sample chain certificate:**

```
None. The above key and certificate were self-signed.
```

</Accordion>

### Username & Password

- Used to securely store a username and password secret that can be used by a [workload's environment variables](/reference/workload#environment-variables).
- The secret consists of:
  - Username
  - Password
  - Encoding (Base64 / Plain Text)
- The secret will only be created or updated if the username and password are valid strings.

## Permissions

The permissions below are used to define [policies](/reference/policy) together with one or more of the four [principal types](/concepts/principal_types):

| Permission | Description                                                         | Implies                                         |
| :--------- | :------------------------------------------------------------------ | :---------------------------------------------- |
| create     | Create new secrets                                                  |                                                 |
| delete     | Delete secrets                                                      |                                                 |
| edit       | Modify existing secrets                                             | view, reveal                                    |
| manage     | Full access                                                         | create, delete, edit, manage, reveal, use, view |
| reveal     | Reveal the plaintext of the secret                                  | view                                            |
| use        | Refer to this secret from other entities (gvcs, cloudaccounts, etc) | view                                            |
| view       | Read-only access excluding plaintext                                |                                                 |

## Reveal Permission

TODO mention audit trail log here for each reveal action

The plaintext of a secret can be viewed only if you or an [identity](/reference/identity) has the `reveal` permission.

For example, when using a secret as the value of an [environment variable](/reference/workload#environment-variables) for a container, the [identity](/reference/identity) assigned to the [workload](/concepts/workload) must have the `reveal` permission set on the assigned secret using a [policy](/reference/policy).

When configuring the [environment variable](/reference/workload#environment-variables), the value of the variable will be in the following format: `cpln://secret/SECRET_NAME`. The image running within the container will be able to access the plaintext of the secret by referring to the name of the configured [environment variable](/reference/workload#environment-variables).

## Use Permission

A secret is used with a:

- GVC's [pull secret](/reference/gvc#pull-secrets)
- Container's [environment variables](/reference/workload#environment-variables)
- Policy's [binding](/concepts/policy#bindings)

TODO refer to guides for each use case here, mention 

To allow a non-administrator user the ability to use a secret with one of the above objects, the user must be granted the `use` permission.

For example, if the image assigned to a container belongs to a private Docker registry, a pull secret for that registry must be added to the associated GVC. The user that is configuring this application must have the `use` permission set on the secret (using a [policy](/reference/policy)) to be able to add it as a pull secret.

## Updating Secrets

If a secret value is updated, any workload referencing that secret will need to be redeployed.

## Guides

- [Name](/guides)

## Permissions

The permissions below are used to define [policies](/reference/policy) together with one or more of the four
[principal types](/concepts/principal_types):

| Permission | Description                 | Implies                                 |
| :--------- | :-------------------------- | :-------------------------------------- |
| create     | Create new agents           |                                         |
| delete     | Delete service agents       |                                         |
| edit       | Modify existing agents      | view                                    |
| manage     | Full access                 | create, delete, edit, manage, use, view |
| use        | Use a secret in an identity | view                                    |
| view       | Read-only access            |                                         |

TODO above permission list was saying "agent" search all the docs for similar issues

## API Reference

Click to see [API Agent Reference](/api-reference/agent)

## CLI Reference

Click to see [CLI Agent Reference](/references/cli/agent)

## Terraform Reference

Click to see [Terraform Agent Resource](/references/terraform/resources/cpln_gvc)

Click to see [Terraform Agent Data Source](/references/terraform/data-sources/cpln_gvc)


### 'Service Account'
**Path**: `objects/service-account.mdx`

---
title: 'Service Account'
---

## Overview

A service account is one of the [principal types](/concepts/principal_types) of an [org](/reference/org) that can be granted specific access permissions to perform headless operations against the [API](/api-reference/api).

A service account can be [mapped](#map-a-service-account-with-a-profile) to a [cpln profile](/reference/cli#profile) and execute CLI commands on behalf of that account.

## Built-in Service Accounts

The following service accounts are built-in and cannot be modified or deleted:

| Service Account Name | Description                                                                          |
| :------------------- | :----------------------------------------------------------------------------------- |
| controlplane         | Built-in service account used by Control Plane to interact with this org's resources |

## Limitations

TODO mention key count limit and length limit?
TODO mention how to revoke

## Map a Service Account with a profile

TODO make this a guide

Using the following [CLI](/reference/cli) command, a [profile](/reference/cli#profile) will be created and mapped to a service account:

```bash
cpln profile create PROFILE_NAME --token GENERATED_KEY
```

This profile can be set as the default profile by using the command `cpln profile set-default PROFILE_NAME` or by using the CLI option `--profile PROFILE_NAME` to override the default when executing a command.

## Service Account Keys

A service account can be associated with one or more **keys** that are generated by the platform. They are used to authenticate and authorize the service account to the API.

<Warning>

When a new key is created, it will only be displayed and available for download **one time**.

It cannot be retrieved again. If a key is lost, misplaced, or forgotten, it must be removed and regenerated.

</Warning>

After a new key has been generated and saved, the UI will display the name of the key (which matches the first sixteen characters of the key) and the description entered.

Individual keys can be removed if they are no longer used or have been compromised.

## Guides

- [Create a Service Account](/guides/create-a-service-account)

## Permissions

The permissions below are used to define [policies](/reference/policy) together with one or more of the four
[principal types](/concepts/principal_types):

| Permission | Description                            | Implies                                    |
| :--------- | :------------------------------------- | :----------------------------------------- |
| addKey     | Add key to an existing service account |                                            |
| create     | Create new service accounts            |                                            |
| delete     | Delete service accounts                |                                            |
| edit       | Modify existing resources              | view                                       |
| manage     | Full access                            | addKey, create, delete, edit, manage, view |
| view       | Read-only access                       |                                            |

## API Reference

Click to see [API Agent Reference](/api-reference/agent)

## CLI Reference

Click to see [CLI Agent Reference](/references/cli/agent)

## Terraform Reference

Click to see [Terraform Agent Resource](/references/terraform/resources/cpln_gvc)

Click to see [Terraform Agent Data Source](/references/terraform/data-sources/cpln_gvc)


### 'User'
**Path**: `objects/user.mdx`

---
title: 'User'
---

## Overview

A user is a member of one or more [orgs](/reference/org).

Users are granted specific access permissions to the various resources within the platform. These grants can be applied to a user by being a member of a [group](/reference/group) or [policy](/reference/policy).

## Invite Users

Refer to the [Invite Users](/guides/invite-users) guide for additional details on how to invite new users to your [org](/reference/org).

## Multiple Orgs

A user can be a member of one or more [orgs](/reference/org).

- To switch between [orgs](/reference/org) from the console:
  - Click on the profile dropdown in the upper right corner.
  - Click on the Org dropdown menu.
  - Click on the desired organization.

## Built-in Tags

Each user has the following built-in [tags](/reference/misc#tags):

- `firebase/sign_in_provider`

## Anything related to saml here TODO

## Guides

- [Invite Users](/guides/invite-users)

## Permissions

The permissions below are used to define [policies](/reference/policy) together with one or more of the four
[principal types](/concepts/principal_types):

| Permission  | Description                  | Implies                                         |
| :---------- | :--------------------------- | :---------------------------------------------- |
| delete      | Delete existing users        |                                                 |
| edit        | Modify existing users        | view                                            |
| impersonate | Lets you impersonate a user  |                                                 |
| invite      | Can invite users to this org |                                                 |
| manage      | Full access                  | delete, edit, impersonate, invite, manage, view |
| view        | Read-only access             |                                                 |

## API Reference

Click to see [API Agent Reference](/api-reference/agent)

## CLI Reference

Click to see [CLI Agent Reference](/references/cli/agent)

## Terraform Reference

Click to see [Terraform Agent Resource](/references/terraform/resources/cpln_gvc)

Click to see [Terraform Agent Data Source](/references/terraform/data-sources/cpln_gvc)


### 'Volume Set'
**Path**: `objects/volume-set.mdx`

---
title: 'Volume Set'
---

## Overview

A volume set is a collection of storage volumes, which are used by a stateful workload. A volume set provides a unique volume for each replica in the linked workload. Each volume set can be used by at most one [stateful workload](/reference/workload#stateful).

### Sharing Data Between Replicas

TODO exception is the shared volume set

Control Plane does not allow individual volumes in a set to be shared by multiple workload replicas, nor does Control Plane replicate data between volumes in a volume set. If you require data sharing or replication, this must be accomplished at the application level (e.g. by using WAL streaming between two Postgresql instances)

### Capacity and Billing

- When a volume is created, it will have an initial capacity defined by the spec of your volume set.
- Volume capacity can be increased by sending an `expandVolume` command.
- Volume capacity cannot be decreased.
- The bill for a volume set is calculated by summing the reserved GB of all volumes.

## Autoscaling

- Like workloads, volume sets scale horizontally. Every replica in the linked workload is automatically assigned a volume.
- When the linked workload scales down, the volumes are preserved. Volumes are only deleted when you send a `deleteVolume` command, or when the volume set itself is deleted.

### Automatic Expansion

The `spec.autoscaling` object allows you to specify rules for automatically expanding volumes in the set. The available options are:

- `maxCapacity`: The largest allowable size for any volume in the set.
- `minFreePercentage`: This must be a number between 1 and 100. When the free percentage on any volume drops below this threshold, Control Plane will issue an `expandVolume` command automatically.
- `scalingFactor`: This must be a number {`>`} 1. When a volume must be expanded, the new capacity will be (the minimum size to ensure `minFreePercentage`) {`*`} `scalingFactor`. E.g. if a volume is using 8/10 GB, and the `minFreePercentage` is 50, the new capacity will be 16 {`*`} `scalingFactor`, assuming that product is {`<=`} `maxCapacity`.

For example:

```json Volume Set Autoscaling
{
  ...
  "spec": {
    ...
    "autoscaling": {
       "maxCapacity": 100,
       "minFreePercentage": 70,
       "scalingFactor": 2
    }
  }
}
```

## Snapshots

Snapshots can be taken at any time and (optionally) on a regular schedule. To set up automatic snapshotting, you may use the `spec.snapshots` object. Options include:

- `retentionDuration`: The length of time to retain a newly created snapshot. This should be a floating point number followed by either d, h, or m (for day, hour or minute)
- `schedule`: A cron expression describing the snapshot frequency. Snapshots cannot be taken more frequently than once per hour.

## File Systems

Each volume set has a single, immutable file system.

Currently supported file systems are:

- ext4
- xfs

## Performance Classes

Each volume set has a single, immutable, performance class.

The performance class determines:

- How many Megabytes per second can be transferred to and from the volume (MB/second)
- How many I/O operations can be processed per second. (IOPS)
- Read/write latency

<Note>Because these drives are served over the network, IOPS/throughput is limited per VM. The performance of individual drives will vary.</Note>

Volume performance varies widely by cloud service provider.

### General-Purpose SSD

**Name**: `general-purpose-ssd`

**Minimum Capacity**: 10Gb

**Maximum Capacity**: 16384Gb

| Service Provider | Max Throughput | Max IOPS                   |
| :--------------- | :------------- | :------------------------- |
| AWS              | 125 MB/s       | 3000                       |
| GCP              | 1200 MB/s      | 80000                      |
| Azure            | 125 MB/s       | 3000                       |

### High-Throughput SSD

<Note>In general, IOPS/throughput capacity varies linearly with storage capacity. The values shown below are the maximum possible values, and may only be achievable with large volume sizes.</Note>
**Name**: `high-throughput-ssd`

**Minimum Capacity**: 200Gb

**Maximum Capacity**: 16384Gb

| Service Provider | Max Throughput | Max IOPS                    |
| :--------------- | :------------- | :-------------------------- |
| AWS              | 400 MB/s       | 4600                        |
| GCP              | 1200 MB/s      | 100000                      |
| Azure            | 1200 MB/s      | 15500                       |


## Commands

Volume sets support imperative operations on individual volumes and snapshots. To issue a command, send a `POST` to the volume set's `-command` endpoint. e.g. `POST https://api.cpln.io/org/my-org/gvc/my-gvc/volumeset/my-volume-set/-command`. These commands can also be created using the Control Plane console at https://console.cpln.io

## Volume Expansion

Volumes can be expanded on-demand by issuing a `expandVolume` command. If the volume set is in-use by a workload, the corresponding workload replica will be restarted.

<Warning>You can only expand a volume once every six hours. Please plan accordingly.</Warning>

<Info>Volumes cannot be "expanded" to a smaller size.</Info>

### expandVolume

Spec:

- location
- volumeIndex
- newStorageCapacity

For example:

```json expandVolume Command
{
  "type": "expandVolume",
  "spec": {
    "location": "aws-sa-east-1",
    "volumeIndex": 0,
    "newStorageCapacity": 11
  }
}
```

## Volume Deletion

To delete a volume, issue a `deleteVolume` command.

### deleteVolume

This command deletes the specified volume's storage device. Note: the metadata for the volume at the specified index will not be removed from the volume set. Only your data will be deleted.

### Deleting an in-use volume

If the volume set is in-use by a workload, a new storage device may be immediately created. e.g. if the volume set is in-use by a workload with one replica, and you delete the volume at index 0, Control Plane will:

1. Create an empty volume to service the workload
2. Delete the old volume as requested
3. Restart the workload replica, binding it to the volume created in step 1.

For example:

```json deleteVolume Command
{
  "type": "deleteVolume",
  "spec": {
    "location": "aws-sa-east-1",
    "volumeIndex": 0
  }
}
```

## Snapshots

Each volume in a set has its own list of snapshots. You manipulate snapshots by issuing commands to the volume set.

### createVolumeSnapshot

Take a snapshot for a given volume (specified by location and volume index). `snapshotName` must be unique for the target volume.

Spec:

- location
- volumeIndex
- snapshotName
- snapshotExpirationDate
- tags
  - Specify any key/value pair here.

For example:

```json createVolumeSnapshot Command
{
  "type": "createVolumeSnapshot",
  "spec": {
    "location": "aws-sa-east-1",
    "volumeIndex": 0,
    "snapshotName": "snap-0",
    "snapshotExpirationDate": "2025-01-01T00:00:00Z",
    "tags": {
      "my-tag-key": "my-tag-value"
    }
  }
}
```

### deleteVolumeSnapshot

Delete the specified snapshot.

Spec:

- location
- volumeIndex
- snapshotName

For example:

```json deleteVolumeSnapshot Command
{
  "type": "deleteVolumeSnapshot",
  "spec": {
    "location": "aws-sa-east-1",
    "volumeIndex": 0,
    "snapshotName": "snap-0"
  }
}
```

### restoreVolume

Restore the specified volume to one of its snapshots. If this volume set is in-use by a workload, the corresponding workload replica will restart.

<Warning>

This operation creates an entirely new volume using the given snapshot. All unsaved data on the original volume will be lost.

</Warning>

Spec:

- location
- volumeIndex
- snapshotName

For example:

```json restoreVolume Command
{
  "type": "restoreVolume",
  "spec": {
    "location": "aws-sa-east-1",
    "volumeIndex": 0,
    "snapshotName": "snap-0"
  }
}
```

## BYOK Support

Volume sets are supported in BYOK locations as long as the following prerequisites are met:

1. The cluster must have a CSI-compatible storage driver installed.

2. You must create storage classes which use the CSI-compatible provisioner, with the following names:
   - `general-purpose-ssd-ext4`
   - `general-purpose-ssd-xfs`
   - `premium-low-latency-ssd-ext4`
   - `premium-low-latency-ssd-xfs`
   - `general-purpose-ssd-ext4-command`
   - `general-purpose-ssd-xfs-command`
   - `premium-low-latency-ssd-ext4-command`
   - `premium-low-latency-ssd-xfs-command`

## Planned Features

- Automatic volume expansion.

## Guides

- [Name](/guides)

## Permissions

The permissions below are used to define [policies](/reference/policy) together with one or more of the four
[principal types](/concepts/principal_types):

| Permission                | Description                               | Implies                                                                                                                                                  |
| :------------------------ | :---------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------- |
| create                    | Create new volumesets                     |                                                                                                                                                          |
| delete                    | Delete existing identities                |                                                                                                                                                          |
| edit                      | Modify existing identities                | view                                                                                                                                                     |
| exec                      | Execute commands                          | exec.restoreVolume, exec.createVolumeSnapshot, exec.expandVolume, exec.deleteVolume, exec.deleteVolumeSnapshot                                           |
| exec.createVolumeSnapshot | Create a snapshot of a volume             |                                                                                                                                                          |
| exec.deleteVolume         | Delete a volume                           |                                                                                                                                                          |
| exec.deleteVolumeSnapshot | Delete a volume snapshot                  |                                                                                                                                                          |
| exec.expandVolume         | Increase the storage capacity of a volume |                                                                                                                                                          |
| exec.restoreVolume        | Restore a volume to a snapshot            |                                                                                                                                                          |
| manage                    | Full access                               | create, delete, edit, exec, exec.createVolumeSnapshot, exec.deleteVolume, exec.deleteVolumeSnapshot, exec.expandVolume, exec.restoreVolume, manage, view |
| view                      | Read-only access                          |                                                                                                                                                          |

## API Reference

Click to see [API Agent Reference](/api-reference/agent)

## CLI Reference

Click to see [CLI Agent Reference](/references/cli/agent)

## Terraform Reference

Click to see [Terraform Agent Resource](/references/terraform/resources/cpln_gvc)

Click to see [Terraform Agent Data Source](/references/terraform/data-sources/cpln_gvc)


## objects/org/external-logging


### CloudWatch
**Path**: `objects/org/external-logging/cloudwatch.mdx`

---
title: CloudWatch
---

## Overview

[AWS CloudWatch](https://aws.amazon.com/cloudwatch/) is a comprehensive monitoring and management service designed to provide real-time insights into your AWS resources and applications. It enables you to collect and track metrics, collect and monitor log files, set alarms, and automatically react to changes in your AWS environment.

By utilizing [AWS CloudWatch](https://aws.amazon.com/cloudwatch/), you can gain valuable insights into your system's performance, troubleshoot issues promptly, and maintain a high level of operational health. Its integration with other AWS services makes it an essential tool for maintaining and optimizing your cloud infrastructure.

Follow the steps below to configure log shipping to CloudWatch.

## Step 1 - Credential Procurement

AWS credentials are required to ship logs to CloudWatch.

To obtain AWS credentials and store it, follow the guide here: [AWS key](/reference/secret#amazon-web-services-aws)

## Step 2 - Configure External Logging

External logging can be configured by using either the [UI Console](#enable-logging-using-the-ui-console) or [CLI](#enable-logging-using-the-cli).

<Tip>

For `groupName` and `streamName` follow [Fluent Bit templating](https://docs.fluentbit.io/manual/administration/configuring-fluent-bit/classic-mode/record-accessor#limitations-of-record_accessor-templating). Use $stream, $location, $provider, $replica, $workload, $gvc, $org, $container, $version to template.

</Tip>

### Enable Logging using the UI Console

1. From the Control Plane Console UI, click on `Org` in the left menu.
2. Click `External Logs` in the middle context menu.
3. Select `CloudWatch` and fill out the required fields.
4. Select the AWS secret created to authenticate to AWS. Refer to the [credential procurement](#step-1-credential-procurement) section to obtain and configure the necessary credentials.
5. Click `Save`.
6. After the configuration is complete, log entries will be available at CloudWatch within a few minutes.

### Enable Logging using the CLI

The external logging configuration can be created / updated using the CLI's `cpln org patch ORG_NAME -f FILE.yaml` command.

Below is an example Org manifests (in YAML). Edit and save the YAML as a file and use it as an input to the CLI's `cpln org patch ORG_NAME -f FILE.yaml` command.

Refer to the [credential procurement](#step-1-credential-procurement) section to obtain and configure the necessary credentials.

- Substitute: ORG_NAME, AWS_SECRET and possibly the region, retentionDays, groupName and streamName.

```yaml YAML
kind: org
name: ORG_NAME
spec:
  logging:
    cloudWatch:
      region: us-east-1
      credentials: //secret/AWS_SECRET
      retentionDays: 7
      groupName: $gvc
      streamName: $workload
```


### Coralogix
**Path**: `objects/org/external-logging/coralogix.mdx`

---
title: Coralogix
---

## Overview

[Coralogix](https://coralogix.com/) is a log management and analytics platform designed to simplify log data storage, analysis, and visualization. It offers various features that make it an excellent choice for storing server logs.

Using [Coralogix](https://coralogix.com/) to store server logs can streamline your log management process, providing you with valuable insights into your server's performance, identifying potential issues early on, and improving overall application and system reliability.

Follow the steps below to configure log shipping to Coralogix.

## Step 1 - Credential Procurement

An API key is required to ship logs to Coralogix.

Follow these steps to obtain the API key, store it as an [Opaque Secret](/reference/secret#opaque), and
configure external logging.

1. From the Coralogix Dashboard, click the `Data Flow` link (in the header), then click the `API Keys` link.
2. Generate and/or copy the `Send Your Data` API Key.
3. From the Control Plane Console UI, click `Secrets` from the left menu.
4. Click the `New` button.
5. Enter a `Name` for the secret, and select `Opaque` from the Secret Type list.
6. Paste the string from step #2 into the content text box and click `Save`.
7. This secret will be used when configuring logging using the [UI Console](#enable-logging-using-the-ui-console) or [CLI](#enable-logging-using-the-cli).

## Step 2 - Configure External Logging

External logging can be configured by using either the [UI Console](#enable-logging-using-the-ui-console) or [CLI](#enable-logging-using-the-cli).

### Enable Logging using the UI Console

1. From the Control Plane Console UI, click on `Org` in the left menu.
2. Click `External Logs` in the middle context menu.
3. Select `Coralogix` and fill out the required fields.
4. Select the Opaque secret created to authenticate to Coralogix. Refer to the [credential procurement](#step-1-credential-procurement) section to obtain and configure the necessary credentials.
5. Click `Save`.
6. After the configuration is complete, log entries will be available at Coralogix within a few minutes.

<Tip>The cluster name will be the domain name that resolves when using the Coralogix dashboard.</Tip>

### Enable Logging using the CLI

The external logging configuration can be created / updated using the CLI's `cpln org patch ORG_NAME -f FILE.yaml` command.

Below is an example Org manifests (in YAML). Edit and save the YAML as a file and use it as an input to the CLI's `cpln org patch ORG_NAME -f FILE.yaml` command.

Refer to the [credential procurement](#step-1-credential-procurement) section to obtain and configure the necessary credentials.

- Substitute: `ORG_NAME`, `OPAQUE_SECRET`, and possibly the cluster.

<Note>

Use the cluster URL that matches your Coralogix account. The cluster will be the domain name that resolves when using the Coralogix dashboard.

</Note>

```yaml YAML
kind: org
name: ORG_NAME
spec:
  logging:
    coralogix:
      cluster: coralogix.com
      credentials: //secret/OPAQUE_SECRET
```


### Datadog
**Path**: `objects/org/external-logging/datadog.mdx`

---
title: Datadog
---

## Overview

[Datadog](https://www.datadoghq.com) is a robust and comprehensive monitoring service for cloud-scale applications, providing full visibility into IT infrastructure. The service combines metrics and events from servers, databases, applications, tools, and services to present a unified view of an entire stack.

[Datadog](https://www.datadoghq.com) is capable of ingesting, analyzing, and visualizing logs from a variety of sources, including servers. This feature is a part of [Datadog](https://www.datadoghq.com/)'s Log Management solution, which provides essential capabilities such as real-time log tailing and filtering, log analytics, and detailed visualizations. It can handle a wide range of log formats, including but not limited to, JSON, syslog, and common application logs.

[Datadog](https://www.datadoghq.com) offers capabilities for log retention and archiving, enabling compliance with various regulatory standards. It also supports role-based access controls to secure your logs and control who can access what information.

Follow the steps below to configure log shipping to [Datadog](https://www.datadoghq.com).

## Step 1 - Credential Procurement

An API key is required to ship logs to [Datadog](https://www.datadoghq.com).

Follow these steps to obtain the API key, store it as an [Opaque Secret](/reference/secret#opaque), and configure external logging.

1. From the [Datadog](https://www.datadoghq.com) dashboard, hover over your username at the bottom of the left menu and click `Organization Settings`.
2. In the middle menu, click `API Keys`.
3. Click the `New Key` button in the upper right corner, enter a key name, and click `Create Key`.
4. Click the `Copy Key` button. This will copy the key to your clipboard. Click the `X` to close the modal.
5. From the Control Plane Console UI, click `Secrets` from the left menu.
6. Click the `New` button.
7. Enter a `Name` for the secret, and select `Opaque` from the `Secret Type` list.
8. Paste the string from step #4 into the content text box and click `Create`.
9. This secret will be used when configuring logging using the [UI Console](#enable-logging-using-the-ui-console) or [CLI](#enable-logging-using-the-cli).

## Step 2 - Configure External Logging

External logging can be configured by using either the [UI Console](#enable-logging-using-the-ui-console) or [CLI](#enable-logging-using-the-cli).

### Enable Logging using the UI Console

1. From the Control Plane Console UI, click on `Org` in the left menu.
2. Click `External Logs` in the middle context menu.
3. Select `Datadog` and fill out the required fields.
4. Select the Opaque secret created to authenticate to [Datadog](https://www.datadoghq.com). Refer to the [credential procurement](#step-1-credential-procurement) section to obtain and configure the necessary credentials.
5. Click `Save`.
6. After the configuration is complete, log entries will be available at [Datadog](https://www.datadoghq.com) within a few minutes.

<Tip>

The hostname will be similar to the domain name that resolves when using the [Datadog](https://www.datadoghq.com) dashboard. (i.e., The host `http-intake.logs.us3.datadoghq.com` maps to the dashboard domain `us3.datadoghq.com`)

</Tip>

### Enable Logging using the CLI

The external logging configuration can be created / updated using the CLI's `cpln org patch ORG_NAME -f FILE.yaml` command.

Below is an example Org manifests (in YAML). Edit and save the YAML as a file and use it as an input to the CLI's `cpln org patch ORG_NAME -f FILE.yaml` command.

Refer to the [credential procurement](#step-1-credential-procurement) section to obtain and configure the necessary credentials.

- Substitute: `ORG_NAME`, `OPAQUE_SECRET`, and possibly the host.

<Note>

Use the host URL that matches your [Datadog](https://www.datadoghq.com) account. The host will be a similar domain name that resolves when using the [Datadog](https://www.datadoghq.com) dashboard.

</Note>

```yaml YAML
kind: org
name: ORG_NAME
spec:
  logging:
    datadog:
      host: http-intake.logs.us3.datadoghq.com
      credentials: //secret/OPAQUE_SECRET
```


### Logz.io
**Path**: `objects/org/external-logging/logz-io.mdx`

---
title: Logz.io
---

## Overview

[Logz.io](https://www.logz.io) is a comprehensive observability platform that provides better visibility into
applications and systems.

The fully managed SaaS solution allows you to collect, parse, and analyze logs, metrics, traces, and security data in one place, using AI and machine learning to help identify and resolve issues, respond faster to incidents, and manage costs effectively.

With [Logz.io](https://www.logz.io), you can aggregate and visualize your server log data in real-time, making understanding the events happening across your infrastructure easier.

[Logz.io](https://www.logz.io) supports long-term log retention and is built with security in mind, providing features like role-based access control, ensuring that your sensitive log data is properly protected.

Follow the steps below to configure shipping data from Control Plane to [Logz.io](https://www.logz.io):

## Step 1 - Generate Token Credentials

[Logz.io](https://www.logz.io) requires an authorization token in order to process data and logs. You’ll need to store the token as an [Opaque Secret](/reference/secret#opaque) and configure external logging.

1. Log into your [Logz.io](https://www.logz.io) account and open the [Data shipping tokens](https://app.logz.io/#/dashboard/settings/manage-tokens/data-shipping?product=logs) page.
2. Copy the **listener URL** and the relevant **account token** you want to use.

Next, log into your [Control Plane Console UI](https://console.cpln.io/), and follow these steps:

1. Navigate to `Secrets` and create a new secret.
2. Name your secret and select `Opaque` from the Secret Type list.
3. Paste the [Logz.io](https://www.logz.io) token string into the content text box and click Create.

This secret will be used when configuring logging using the [UI Console](#enable-logging-using-the-ui-console) or [CLI](#enable-logging-using-the-cli).

## Step 2 - Configuring Shipping Data to Logz.io

You need to enable logging from your [UI Console](#enable-logging-using-the-ui-console) or [CLI](#enable-logging-using-the-cli).

### Enable Logging using the UI Console

1. Open the [Control Plane Console UI](https://console.cpln.io/), click on `Org` in the left menu.
2. Click `External Logs` in the middle context menu.
3. Select `Logz.io` and fill out the required fields.
4. Select the Opaque secret created to authenticate to [Logz.io](https://www.logz.io). Refer to the [generate token credentials](#step-1-generate-token-credentials) section to obtain and configure the necessary credentials.
5. Click Save.

You will be able to see log entries at [Logz.io](https://www.logz.io) shortly after the configuration has been completed.

<Tip>

The `Listener Host` value is shown on the [Manage tokens](https://app.logz.io/#/dashboard/settings/manage-tokens/data-shipping?product=logs) page.

</Tip>

### Enable Logging using the CLI

The external logging configuration can be created / updated using the CLI's `cpln org patch ORG_NAME -f FILE.yaml` command.

Below is an example Org manifests (in YAML). Edit and save the YAML as a file and use it as an input to the CLI's `cpln org patch ORG_NAME -f FILE.yaml` command.

Refer to the [generate token credentials](#step-1-generate-token-credentials) section to obtain and configure the necessary credentials.

- Substitute: `ORG_NAME`, `OPAQUE_SECRET`, and possibly the listener host.

<Note>

Use the listener host URL that matches your [Logz.io](https://www.logz.io) account. The host will be a similar domain name that resolves when using the [Logz.io](https://www.logz.io) dashboard.

</Note>

```yaml YAML
kind: org
name: ORG_NAME
spec:
  logging:
    logzio:
      credentials: //secret/OPAQUE_SECRET
      listenerHost: listener.logz.io
```


### Overview
**Path**: `objects/org/external-logging/overview.mdx`

---
title: Overview
---

Log shipping to an external provider is a data replication and disaster recovery strategy used to keep a copy of server logs in an off-site location, often hosted by a third-party service provider. This approach ensures that critical server logs are safely stored in a separate location, providing an additional layer of protection in case of data loss, server failure, or other emergencies.

When logs are shipped to an external provider, all logs will remain accessible through Control Plane, adhering to the [current log retention policy](/reference/logs#log-retention).

Log shipping can be configured to multiple external providers.

Control Plane offers the ability to ship all Org logs to the following providers:

1. [Amazon S3](/external-logging/s3)
2. [CloudWatch](/external-logging/cloudwatch)
3. [Coralogix](/external-logging/coralogix)
4. [Datadog](/external-logging/datadog)
5. [Logz.io](/external-logging/logz-io)
6. [Stackdriver](/external-logging/stackdriver)


### Amazon S3
**Path**: `objects/org/external-logging/s3.mdx`

---
title: Amazon S3
---

## Overview

[Amazon S3](https://aws.amazon.com/s3/) (Simple Storage Service) is a highly scalable, durable, and secure cloud storage service offered by Amazon Web Services (AWS). It is commonly used for various data storage purposes, including storing server logs.

Using [S3](https://aws.amazon.com/s3/) to store server logs provides a reliable, scalable, and secure solution for retaining valuable log data. The centralized storage also simplifies log management, enhances data analysis capabilities, and supports compliance and auditing requirements. AWS's extensive global infrastructure ensures that your log data is available and accessible from anywhere with low latency, making [S3](https://aws.amazon.com/s3/) a popular choice for log storage in the cloud.

Follow the steps below to configure log shipping to [Amazon S3](https://aws.amazon.com/s3/).

## Step 1 - Credential Procurement

Authentication credentials are required to ship logs to [S3](https://aws.amazon.com/s3/).

Follow these steps to obtain the credentials, store them as an [AWS Secret](/reference/secret#amazon-web-services-aws), and
configure external logging.

1. Refer to [these instruction](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_users_create.html) to create a new AWS IAM user in your AWS account.

   - Select `Programmatic access` when creating the user and take note of the Access and Secret Key.

2. This user, at a minimum, must have an associated policy with the `s3:PutObject` action.

**Sample AWS Policy (substitute S3_BUCKET_NAME):**

```json JSON
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "VisualEditor0",
      "Effect": "Allow",
      "Action": "s3:PutObject",
      "Resource": "arn:aws:s3:::S3_BUCKET_NAME/*"
    }
  ]
}
```

3. From the Control Plane Console UI, click `Secrets` from the left menu.
4. Click the `New` button.
5. Enter a `Name` for the secret, and select `AWS` from the Secret Type list.
6. Enter the `Access Key` and `Secret Key` and click `Save`.
7. This secret can now be used when configuring logging using the [UI Console](#enable-logging-using-the-ui-console) or [CLI](#enable-logging-using-the-cli).

## Step 2 - Configure External Logging

External logging can be configured by using either the [UI Console](#enable-logging-using-the-ui-console) or the [CLI](#enable-logging-using-the-cli).

### Enable Logging using the UI Console

1. From the Control Plane Console UI, click on `Org` in the left menu.
2. Click `External Logs` in the middle context menu.
3. Select `S3` and fill out the required fields.
4. Select the AWS secret to authenticate to S3. Refer to the [credential procurement](#step-1-credential-procurement) section to obtain and configure the necessary credentials.
5. Click `Save`.
6. After the configuration is complete, log entries will be available at S3 within a few minutes.

<Tip>

The `prefix` will be the folder where the logs will be written.

The folder structure will follow the format:

`PREFIX/ORG_NAME/YEAR/MONTH/DAY/HOUR/MINUTE/LOG_FILE.jsonl`

The .jsonl file will contain ~1-3k of single line log entries in JSON.

Each entry will contain the following keys:

- time
- log
- location,
- version
- provider
- container
- replica
- workload
- gvc
- org
- stream

</Tip>

### Enable Logging using the CLI

The external logging configuration can be created / updated using the CLI's `cpln org patch ORG_NAME -f FILE.yaml` command.

Below is an example [Org](/reference/org) manifest (in YAML). Edit and save the YAML as a file and use it as an input to the CLI's `cpln org patch ORG_NAME -f FILE.yaml` command.

Refer to the [credential procurement](#step-1-credential-procurement) section to obtain and configure the necessary credentials.

- Substitute: `ORG_NAME`, `S3_BUCKET_NAME`, `AWS_SECRET`, and `AWS_REGION`.

```yaml YAML
kind: org
name: ORG_NAME
spec:
  logging:
    s3:
      bucket: S3_BUCKET_NAME
      credentials: //secret/AWS_SECRET
      prefix: /
      region: AWS_REGION
```


### stackdriver
**Path**: `objects/org/external-logging/stackdriver.mdx`

## Overview

[Stackdriver](https://cloud.google.com/products/operations), now known as Google Cloud Operations Suite, is a powerful monitoring, logging, and diagnostics tool for Google Cloud Platform (GCP) and other cloud environments. It offers a range of features to help you gain deep insights into your system's performance and health.

With [Stackdriver](https://cloud.google.com/products/operations), you can collect and analyze logs, monitor infrastructure and application metrics, set up custom alerts, and automate responses to critical events. By leveraging [Stackdriver](https://cloud.google.com/products/operations), you can enhance your operational efficiency, quickly identify and resolve issues, and ensure the reliability and stability of your applications and services.

Follow the steps below to configure log shipping to Stackdriver.

## Step 1 - Credential Procurement

GCP credentials are required to ship logs to Stackdriver.

To obtain GCP credentials and store it, follow the guide here: [GCP key](/reference/secret#google-cloud-platform-gcp)

## Step 2 - Configure External Logging

External logging can be configured by using either the [UI Console](#enable-logging-using-the-ui-console) or [CLI](#enable-logging-using-the-cli).

<TIP>Use a valid GCP location for the `location` field. E.g. us-east1</TIP>

### Enable Logging using the UI Console

1. From the Control Plane Console UI, click on `Org` in the left menu.
2. Click `External Logs` in the middle context menu.
3. Select `Stackdriver` and fill out the required fields.
4. Select the GCP secret created to authenticate to GCP. Refer to the [credential procurement](#step-1-credential-procurement) section to obtain and configure the necessary credentials.
5. Click `Save`.
6. After the configuration is complete, log entries will be available at Stackdriver within a few minutes.

### Enable Logging using the CLI

The external logging configuration can be created / updated using the CLI's `cpln org patch ORG_NAME -f FILE.yaml` command.

Below is an example Org manifests (in YAML). Edit and save the YAML as a file and use it as an input to the CLI's `cpln org patch ORG_NAME -f FILE.yaml` command.

Refer to the [credential procurement](#step-1-credential-procurement) section to obtain and configure the necessary credentials.

- Substitute: ORG_NAME, GCP_SECRET and possibly the location.

```yaml YAML
kind: org
name: ORG_NAME
spec:
  logging:
    stackdriver:
      location: us-east1
      credentials: //secret/GCP_SECRET
```


## objects/org


### 'Overview'
**Path**: `objects/org/overview.mdx`

---
title: 'Overview'
---

TODO combine below two

## First definition

An Org serves as a tightly isolated bounded context that encompasses all the resources managed by Control Plane. These resources comprise [domains](/reference/domain), [images](/reference/image), [workloads](/concepts/workload), [GVCs](/reference/gvc), [users](/reference/user), [groups](/reference/group), [service accounts](/reference/serviceaccount), and more.

It's possible for a physical organization, to create multiple 'orgs,' although this is not mandatory. Creating multiple orgs can be beneficial in order to establish complete isolation between environments, for instance.

## Second definition

An Org is a strictly isolated bounded context that encapsulates all the resources managed by Control Plane. These kinds of resources include [domains](/reference/domain), [images](/reference/image), [workloads](/concepts/workload), [GVCs](/reference/gvc), [users](/reference/user), [groups](/reference/group), [service accounts](/reference/serviceaccount), etc.

A physical organization (e.g., Acme) can create more than one ‘org’, although it is optional. Reasons for
doing so might be to provide absolute isolation between subsidiaries for example.

As a user of Control Plane, you will be a member of at least one organization and have access to manage the org resources listed below:

## Multiple Orgs

A user can be a member of one or more Orgs.

- To switch between Orgs from the console:
  - From the left menu, click on the `>` to the right of the current org.
  - Search or scroll to the desired org.
  - Click on the desired org.
  - A confirmation modal will be displayed. Click `Yes`.

## External Logs / Logging

TODO explain here briefly each provider, refer to guides
TODO mentione the log rate limitation here and for each provider if different

Control Plane offers the ability to ship all Org logs to an external provider.

Please [click here](/external-logging/overview) for additional details and configuration instructions.

## Tracing

OpenTelemetry traces are supported and can be configured with the native `Control Plane` tracing provider or sent to an OpenTelemetry collector endpoint by using the `OpenTelemetry` tracing provider.

### Control Plane Tracing Provider

The Control Plane tracing provider is the default method for collecting OpenTelemetry traces. They will be accessible for exploration using Grafana by accessing `Metrics` in the sidebar menu of the Console.

To enable traces using the Console, navigate to your GVC, click on `Tracing`, and choose `Control Plane` as the metric provider. Then, configure the sampling percentage and, optionally, the Custom Tags.

Here is an example of a GVC with enabled tracing:

```yaml YAML
kind: gvc
name: online-boutique
spec:
  staticPlacement:
    locationLinks:
      - //location/aws-eu-central-1
      - //location/azure-eastus2
      - //location/gcp-us-west1
  tracing:
    provider:
      controlPlane: {}
    customTags: {}
    sampling: 100
```

### OpenTelemetry Tracing Provider

Similarly, traces can be sent to an OTEL collector endpoint using the `OpenTelemetry` tracing provider.

For details, see the [Online Boutique](https://github.com/controlplane-com/examples/blob/main/examples/online-boutique/README.md) example.

TODO add lightstep

## Observability

The retention period for logs, metrics and traces defaults to 30 days and can be adjusted for each independently.

Charges apply for combined storage of logs, metrics and traces over 100GB calculated by GB-Month.

TODO mention free tier

## Threat Detection

Control Plane provides real-time threat detection and alerting by inspecting syscalls of all running workloads.
When enabled, you will receive real-time alerts of possible threats by severity level.

The following list of threats or attempted activities will trigger an alert at the specified severity levels.

#### Notice severity

- Packet socket created
- PTRACE anti-debug
- SSH Activity
- Connect to kubernetes api

#### Info severity

- Spawned processes with an interactive tty

#### Warning severity

- Directory traversal
- Sensitive file read activity
- Netcat remote code execution
- Search for private keys or passwords
- Log file clearing
- Remove data from disk
- Create symlinks\hardlinks to sensitive files
- Kernel module injection
- Debugfs activity
- PTRACE attached
- Credential search activity
- Execution from /dev/shm
- Malicious binaries or script execution

#### Critical severity

- Container escape attempts
- Drop and execute new binary
- Fileless execution using memfd_create
- Crypto currency mining activity

## Session Timeout - Console UI

The console UI will automatically sign out if inactive for 15 minutes. This timeout duration is the
default setting (for [PCI compliance](/compliance#pci)) and can be modified.

This timeout setting (in seconds) can be adjusted from the `Info` page when clicking on the `Org` link from the left menu.

## Guides

- [Create an Org](/guides/create-an-org)

## Permissions

The permissions below are used to define [policies](/reference/policy) together with one or more of the four
[principal types](/concepts/principal_types):

| Permission       | Description                                                                    | Implies                                                                                               |
| :--------------- | :----------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------- |
| edit             | Modify org                                                                     | view                                                                                                  |
| exec             | Grantees can execute all commands on the org                                   | exec.echo                                                                                             |
| exec.echo        | Grantees can execute the echo command                                          |                                                                                                       |
| grafanaAdmin     | Grantees are made Admin in Grafana, otherwise the role 'Viewer' is assigned    |                                                                                                       |
| manage           | Full access                                                                    | edit, exec, exec.echo, grafanaAdmin, manage, readLogs, readMetrics, readUsage, view, viewAccessReport |
| readLogs         | Grantees can read logs from all workloads                                      | view                                                                                                  |
| readMetrics      | Grantees can access usage and performance metrics                              |                                                                                                       |
| readUsage        | Grantees can access usage and billing metrics                                  |                                                                                                       |
| view             | Read-only view: every org member can view their org                            |                                                                                                       |
| viewAccessReport | Grantees can inspect the granted access report on all resources within the org |                                                                                                       |

## API Reference

Click to see [API Agent Reference](/api-reference/agent)

## CLI Reference

Click to see [CLI Agent Reference](/references/cli/agent)

## Terraform Reference

Click to see [Terraform Agent Resource](/references/terraform/resources/cpln_gvc)

Click to see [Terraform Agent Data Source](/references/terraform/data-sources/cpln_gvc)


## objects/workload


### Autoscaling
**Path**: `objects/workload/autoscaling.mdx`

---
title: Autoscaling
---

## Overview

Workload auto-scaling is configured by setting a **strategy**, a **target value**, and in some cases as **metric percentile**. Together these values determine when the workload will scale up & down.

As the system scales up, traffic will not be sent to the new replicas until they pass the readiness probe, if configured. If there is no probe configured or if it is a basic TCP port check, the requests will hit the new replicas before they are ready to respond. This could cause a delay or errors for end-user traffic.

<Tip>

You can configure autoscaling in the default options for a workload (`defaultOptions`) and in any of the location-specific options.

</Tip>

## Scaling Strategies

The scaling strategy is set using `autoscaling.metric`.

- Disabled (`disabled`)
  - Scaling will be disabled.
- Concurrent Requests Quantity (`concurrency`)
  - The average number of requests executing at a given point in time across all the replicas.
    `(requests * requestDuration)/(timePeriod * replicas)`.
  - Example: A workload with 5 replicas received 1000 requests with an average response time of 50ms (05 seconds)
    over a 1 second period. The concurrent requests metric for that period is `(1000 * .05)/(1 * 5) = 10`.
- Requests Per Second (`rps`)
  - The raw number of requests received by a workload each second divided by the number of replicas. Requests
    are counted even if they have not yet been completed.
- Percentage of CPU Utilization (`cpu`)
  - The percentage of CPU consumed by system and user processes in the container(s) as specified in the container cpu field.
- Request Latency (`latency`)
  - The request response time (at a configurable percentile) in milliseconds, averaged across all replicas.

<Warning>

Caveats when choosing a workload type and a scaling strategy:

- Serverless workloads cannot use the `latency` scaling strategy
- Standard workloads cannot use the `concurrency` scaling strategy

</Warning>

TODO create a matrix table for caveats

<Warning>

The scale to zero functionality is only available for Serverless workloads, and only when using the `rps` or `concurrency` scaling strategies.

</Warning>

## Autoscaling Standard Workloads

For standard workloads, Control Plane runs two asynchronous control loops:

1. The Scaling Decision Loop
2. The Metric Calculation Loop

TODO explain how this is different than other workload types

<Info>

Because of this asynchronous structure, autoscaling decisions may be made based on a metric value that is as old as the metric's collection rate (usually 20 seconds).

</Info>

### The Scaling Decision Loop

A workload's scale is evaluated every 15 seconds, using the value most recently calculated by the [metric calculation loop][#standard-metric-calculations]. Each time an evaluation is made the chosen metric is averaged across all available replicas and compared against the scale target. When scaling up, Control Plane does not enforce a stabilization window; the number of pods will increase as soon as the [scaling algorithm](https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/#algorithm-details) dictates. When scaling down, a stabilization window of 5 minutes is used; the highest number of pods recommended by the scaling algorithm within the past 5 minutes will be applied to the running workload.


### The Metric Calculation Loop

#### Requests per Second

Every 20 seconds, Control Plane calculates the average number of requests per second over the past 60 seconds.

#### Latency

Every 20 seconds, Control Plane calculates latency, using the response time of the workload once requests are received, using an average over the past 60 seconds at the specified percentile (p50, p75, p99).

#### CPU

Every 15 seconds, Control Plane calculates the average CPU usage over the past 15 seconds.

## Autoscaling Serverless Workloads

The current capacity is evaluated every 2 seconds and compared against the scale target. It averages requests completed over the previous 60 seconds to avoid rapid changes. If ever a scaling decision is made which results in a scale increase above 200% then it suspends scale down decisions and averages over 6 seconds for 60 seconds. This is to allow for rapid scaling when a burst of traffic is detected.

<Tip>

**Special considerations for the `latency` scaling strategy**

Because request latency is represented as a distribution, when using the `latency` scaling strategy, you must choose a metric percentile by setting the `autoscaling.metricPercentile` property to one of the following values:

- `p50`
- `p75`
- `p99`

</Tip>

TODO multi

## Options

- Minimum Scale (`autoscaling.minScale`)
  - The minimum allowed number of replicas. A workload can scale down to 0 when there is no traffic and scale-up immediately to fulfill new requests. (Must be between 0 and `Maximum Scale` inclusive).
- Maximum Scale (`autoscaling.maxScale`)
  - The maximum allowed number of replicas.
- Scale to Zero Delay (`autoscaling.scaleToZeroDelay`)
  - The amount of time (in seconds) when there are no requests received before a workload is scaled down to 0. (Must be between 30 and 3600 inclusive).
- Maximum Concurrency (`autoscaling.maxConcurrency`)
  - The maximum allowed number of requests to be actively running against a single replica. If there are no replicas available that are processing less than the configured maximum number of concurrent requests, the system will queue the request and wait for a replica to be available. It will not trigger a scale decision. The purpose of this setting is to prevent a single replica from taking more traffic than it is designed to process.
  - If, for example, Max Concurrency = 100, Scaling Strategy = ‘Concurrent Requests’, and Target = 100, the results would not be desirable for most end-user traffic. When the system decides to scale up, it will queue the requests until an existing request completes or the new replica becomes available.
  - Must be between 0 and 1000 inclusive.
- Metric Percentile (`autoscaling.metricPercentile`)
  - The nth percentile is a value below which n percent of the values in a distribution lie.
  - This may only be set while using the `latency` scaling strategy. The default value is `p50`.
  - e.g. If the 50th percentile of a latency distribution is 200ms, 50% of requests took less than 200ms.
  - Control plane supports p50, p75, and p99 metric percentiles.

<Info>

[Capacity AI](#capacity-ai) is not available if CPU Utilization is selected because dynamic allocation of CPU resources cannot be accomplished while scaling replicas based on the usage of its CPU.

</Info>


### Capacity AI
**Path**: `objects/workload/capacity.mdx`

---
title: Capacity AI
---

## Overview

Workloads can leverage intelligent allocation of its container's resources (CPU and Memory) by using Capacity AI.

Capacity AI uses an analysis of historical usage to adjust the resources up/down between the configured minimum and maximum values of each container.

This can significantly reduce cost but may, in rare cases, cause temporary performance issues with sudden spikes in usage depending on the autoscaling settings of the workload.

If capacity AI is disabled, the amount of resources configured is set using the provided cpu and memory settings for each container.

The minCpu and minMemory settings of a workload container are ignored when capacityAI is disabled.

Capacity AI must be disabled if the [autoscaling](#autoscaling) strategy is set to `CPU Utilization`.

<Info>

Capacity AI will prevent the ratio of memory and cpu from diverging by a large percentage.

</Info>

<Note>Changes made to a workload will reset its historical usage and will restart the analysis process.</Note>

## Minimum Capacity AI

When resources are not being used, Capacity AI will downscale CPU usage to a minimum of 25 millicores. The minimum will increase depending on the memory size being recommended by Capacity AI using a 1:3 ratio of CPU millicores to memory MiB.


### Containers
**Path**: `objects/workload/containers.mdx`

---
title: Containers
---

## Overview

Workloads must have at least one container configured with the following:

- [Image](#images)
- [Resources](#resources) (CPU and Memory)
- [Port(s)](#ports) that the container exposes
- optional [Environment Variables](#environment-variables)
- optional [Container Overrides](#container-overrides)
- optional [Custom Metrics](/reference/workload/custom-metrics)
- optional [Readiness / Liveness Probes](#probes)
- optional [Volumes](/reference/workload/volumes)
- optional [Lifecycle](#lifecycle)

<Tip>
  If a workload has more than one container, only one can serve traffic on the default global endpoint, however additional containers can
  receive traffic using a custom domain.
</Tip>

<Warning>

The following rules apply to the name of a container:

- Cannot be: 'istio-proxy', 'queue-proxy', 'istio-validation'.
- Cannot start with: `cpln_`.

</Warning>

## Images

Each workload must be configured with at least one container, associated with an image.

Images can be pulled from:

- A public registry

  - If the image does not require authentication, only the image name and optional tag are required.
  - If authentication is required, a [pull secret](/reference/gvc#pull-secrets) must be configured on the [GVC](/concepts/gvc) containing the [workload](/concepts/workload).

- Org's private registry

  - If the image resides in your org's private registry, no [pull secret](/reference/gvc#pull-secrets) is required and you may use one of the following for the image name:
    - Full Name: `/org/ORG_NAME/image/IMAGE_NAME:TAG`
    - Short Name: `//image/IMAGE_NAME:TAG`

TODO add this link structure to cpln terms page

- An external private registry
  - Create a [pull secret](/reference/gvc#pull-secrets) with the registry credentials and configure it for the GVC.

Images must be formatted for linux/amd64 to run on the Control Plane Cloud Platform managed locations. When using a BYOK location additional runtime platforms are available.

<Note>

Control Plane supports the use of dynamic tags. If an image is pushed and the tag is not updated (e.g., `latest`), the platform will redploy the new image within 5 minutes.

To enable this feature:

- Using the console
  - Toggle the `Support Dynamic Tag` switch on the `Info` page of the selected workload.
- Using [cpln apply](/guides/cpln-apply)
  - Add the element `supportDynamicTags: true` within the selected workload.

</Note>

<Warning>

The UserID 1337 is restricted.

If used then inbound and outbound communication to the workload will be disabled.

One known case where this UserID is configured by default is with [Laravel Sail](https://github.com/laravel/sail).

If you need to use Laravel Sail on Control Plane then you must change the default UserID.

Contact support for assistance.

</Warning>

## Ports

Workloads can expose ports to be accessed by other workloads internally, externally from the provided default endpoints and from Domains. Serverless workloads must expose one port. Cron workloads may not expose ports. Standard workloads can expose 0 or more ports. The default endpoints will route traffic to the first port exposed by the first container of a workload.

```yaml YAML
ports:
  - number: 8080
    protocol: http
```

#### Number

The port to expose externally or internally to other Control Plane workloads. Access is controlled using the workload [firewall](#firewall).

Ports which are not exposed or are only accessed from another container in the same workload do NOT need to be defined.

<Warning>

The ports listed below are blocked and are not allowed to be used.

Containers which attempt to use these ports will not be able to bind.

8012, 8022, 9090, 9091, 15000, 15001, 15006, 15020, 15021, 15090, 41000

</Warning>

#### Protocol

- grpc
- http
- http2
- tcp

If the protocol is not specified when using the `ports` then `http` is configured.

If the deprecated `port` parameter is used then `http2` is configured.

When the protocol is `tcp`...

1. External access to TCP ports of workloads is not available when using default external endpoints or standard custom domains.
1. The inbound allow CIDR list in firewall is always restricted to TCP ports when using default external endpoints or standard custom domains.

To enable external access through TCP and inbound firewall functionality you must:

1. Enable [Dedicated Load Balancer](/reference/gvc#dedicated-load-balancer) on the GVC
1. Configure access using a [Domain](/reference/domain) and a [custom port](/reference/domain#custom-ports) configured with TCP.

## Probes

Probes are used to check the health of an application running inside a container.

### Readiness Probe

TODO mention the default values for each workload type

The readiness probe is used to determine if the workload replica is ready to receive traffic. For example, if the application is performing some actions during start-up and needs it to complete before serving requests, the readiness probe should fail until the actions have been completed.

This check is used in two ways.

1. Determines if replicas from a new version of the workload are ready, when the check passes the rollout continues, when the check fails the rollout is paused.

2. Determines if the workload replica should receive new requests from end users. When the readiness probe is failing the replica is removed the pool of available replicas for this workload and all endpoints.

It is recommended to use an HTTP or Command probes that perform an adequate check that the workload is healthy and able to respond to requests.

### Liveness Probe

TODO mention that it defaults to readiness

The liveness probe defines when the container should be restarted.

For example, if the application code hits a deadlock condition, the liveness probe can catch that the container is not healthy, and Control Plane will restart the failing workload replica. This will ensure that the application is available as much as possible until the defect causing the deadlock is fixed.

### Options

Health Check Type:

- Run a Custom Command.
- HTTP
  - Scheme (either HTTP or HTTPS, default is HTTP).
  - Path.
  - Port (must be between 80 and 65535 inclusive).
  - Optional HTTP headers.
- TCP
  - Socket port (must be between 80 and 65535 inclusive. Ports 8012, 8022, 9090, 9091, 15000, 15001, 15006, 15020, 15021, 15090, 41000 are invalid).
- gRPC
  - gRPC port.

Configurable Limits:

- Initial Delay Seconds
  - The delay to wait after the container is started before performing the first probe (must be between 0 and 120 inclusive, default is 0).
- Period Seconds
  - How often to perform the probe (must be between 1 and 60 inclusive, default is 10).
- Timeout Seconds
  - Number of seconds after which the probe times out (must be between 1 and 60 inclusive, default is 1).
- Success Threshold
  - Minimum consecutive successes for the probe to be considered successful after having failed (must be between 1 and 20 inclusive, default is 1).
- Failure Threshold
  - When a probe fails, Kubernetes will try this amount of times before giving up. For a liveness probe, the container will be restarted. For a readiness probe, the workload will be marked `Unready`. (must be between 1 and 20 inclusive, default is 3).

Refer to the Kubernetes probe documentation [here](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/) for additional details.

## Resources

Control Plane allows you to specify CPU and memory resources for each container.

### CPU

CPU is specified in **millicores (m)** and **cores**.

- **Millicore**: Since a whole core might be too much for many applications, the platform allows you to specify CPU resources in millicores. One core is equivalent to 1,000 millicores. Specifying `500` (in the console) or `500m` (in the YAML manifiest) would allocate half a core.
- **Core**: A core is a CPU unit. Specifying `1` (in both the console and YAML manifest) as the CPU resource means allocating the equivalent of one full CPU core.

### Memory

Memory is specified in **Mebibytes (Mi)** and **Gibibytes (Gi)**.

- **Mebibyte**: A unit of digital data that is equal to 1,048,576 bytes. Specifying `1` and selecting Mi (in the console) or `1Mi` (in the YAML manifiest) would allocate 1 Mebibyte.
- **Gibibyte**: A unit of digital data that is equal to 1,073,741,824 bytes. Specifying `1` and selecting Gi (in the console) or `1Gi` (in the YAML manifiest) would allocate 1 Gibibyte.

### GPU

Workloads can be attached to the following GPUs at runtime:

| GPU         | # per replica |
| :---------- | :-----------: |
| Nvidia T4   |      1-4      |
| Nvidia A10g |       1       |

The drivers for the card will be installed and available for use automatically.
Driver versions are maintained by Control Plane and kept current.

When a GPU is selected, minimum values for CPU and Memory must be met and CapacityAI is not allowed to be enabled. There are no additional charges for GPUs. The standard CPU, Memory and Egress charges are used.

Example workload container with 4 Nvidia T4 GPUs:

```yaml YAML
gpu:
  nvidia:
    model: t4
    quantity: 4
```

## Environment Variables

Custom environment variables can be made available to the image running within a container.

The value of the variable can be in plain text or a [secret value](#secret-variables).

<Warning>The length of an environment variable value cannot be greater than 4096 characters.</Warning>

### Secret Variables

Sensitive values can be used as an environment variable by using a [secret](/reference/secret).

The [identity](#identity) of the workload must be member of a [policy](/reference/policy) that has the `reveal` permissions on the [secret](/reference/secret).

<Tip>

When adding an environment variable using the UI, a list of available secrets can be accessed by pressing Control-S within the value textbox. If you do not have any secrets defined, the prefix `cpln://secret/` will be inserted.

</Tip>

### Reference Variables

Environment variables can take on values from the pod manifest.

To reference a field, prefix the field with `cpln://reference/`

The supported fields are: `metadata.name`, `metadata.namespace`, `spec.nodeName`, `status.hostIP`, `status.podIP`, and `status.podIPs`

### PORT Variable

The `PORT` environment variable is provided at runtime and available to a container.

It can be assigned as a custom environment variable in all cases except when the container is exposed and the value doesn't match that of the exposed port.

For example:

- If the container is exposed with a port of `3000`:
  - the system will **accept** a PORT environment variable with the value `3000`.
  - the system will **deny** a PORT environment variable with any value other than `3000`.
- If the container is not exposed then any value is accepted for the PORT environment variable.

### Environment Variable Inheritance

Environment variables may be set at the [GVC](/reference/gvc#environment-variables) level. These variables are available to any container running in the GVC on an opt-in basis. To opt in, set the container's `inheritEnv` property to `true`. You can override the value of an inherited variable by adding a local variable with the same key.

### Use by Other Variables

Environment variables can contain the values of other environment variables by following the pattern `$(ENV_NAME)`.

For example, the runtime value of the built-in variable `CPLN_GLOBAL_ENDPOINT` can be used in another environment variable by having the value `$(CPLN_GLOBAL_ENDPOINT)` added to the new variable.

### Disallowed Variables

TODO check if up to date

The following variable names are not allowed to be used as a custom environment variable:

- `K_SERVICE`
- `K_CONFIGURATION`
- `K_REVISION`

### Import Variables

TODO make a guide and refer to it

A .env file can be uploaded using the console to import multiple environment variables. [Secret](#secret-variables) values are supported.

```text Sample .env file
URL=http://test.example.com
USERNAME=user001
PASSWORD=cpln://secret/username_secret.password
DATA=cpln://secret/opaque_secret.payload
```

## Container overrides

A custom `command` (entrypoint), `args` (arguments) or `workingDir` can be provided for the container which will override the startup configuration of the container.

### Command

The container entrypoint can be overridden by entering a custom command value.

### Arguments

The arguments will be appended to the image `ENTRYPOINT` if no command is specified.

The argument list is ordered and will be passed to the container in the same order it is defined in the api.

### Working Directory

The `workingDir` setting changes the directory that commands are executed in when no path or relative paths are specified.

## Lifecycle

Each Workload container can be configured to execute a subset of the [Kubernetes lifecycle hooks](https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/). The supported hooks are:

### PostStart

This hook is executed immediately after a container is created. However, there is no guarantee that the hook will execute before the container ENTRYPOINT. In the event of a failure, the relevant error message will be recorded in the corresponding deployment.

### PreStop

This hook is executed immediately before a container is stopped. In the event of a failure, the relevant error message will be recorded in the workload's event log

### Setting lifecycle hooks

These hooks can be configured using the console or [cpln apply](/guides/cpln-apply).

- Using the console

  - From the workload container, select the `Lifecycle` link from the top menu bar.
  - Enter the command and optional arguments.
  - Click `Save`.

- Using [cpln apply](/guides/cpln-apply)

  - Only the `exec` type is supported.
  - Example:

    **Add the `lifecycle` section to an existing workload container.**

    ```yaml Workload Spec
    spec:
      containers:
        - name: advanced-options-example
          args: []
          cpu: 50m
          env: []
          image: '//image/IMAGE:TAG'
          memory: 128Mi
          port: 8080
          lifecycle:
            postStart:
              exec:
                command:
                  - sh
                  - '-c'
                  - sleep 10
            preStop:
              exec:
                command:
                  - sh
                  - '-c'
                  - sleep 10
    ```


### Custom Metrics
**Path**: `objects/workload/custom-metrics.mdx`

---
title: Custom Metrics
---

## Overview

Control Plane can collect custom metrics from your workload by having your application emit a [Prometheus formatted list of metrics](https://prometheus.io/docs/practices/naming/) at a path and port of your choosing. The port can be different than the one serving traffic. Each container in a workload can be configured with metrics.

TODO remove ui references, show examples with timestamp too

<Tip>

The convention is to use the path `/metrics`, but any path can be used.

</Tip>

Sample output from the metrics endpoint:

```
MY_COUNTER 788
MY_COUNTER_2 123
NUM_USERS 2
NUM_ORDERS 91
```

The platform will scrape all the replicas in the workload every 30 seconds with a 5 second timeout. Metric names with the prefix `cpln_` will be ignored by the scrapping process.

The collected metrics can be viewed by clicking the `Metrics` link on the workload page within the console. Clear any existing query and enter the name of the metric. Click `Run Query` to execute.

The time-series displayed will include these labels:

- `org`
- `gvc`
- `location`
- `provider`
- `region`
- `cluster_id`
- `replica`

## Configuring Custom Metrics Scraping

1. In the UI, navigate to `Workloads` in the selected GVC and select the workload for which you want to scrape metrics.
2. Select the appropriate container name under `Containers`, then choose `Metrics`.
3. Configure the `Path` and `Port` where the container serves metrics, then save the settings.
4. The workload will automatically redeploy to apply the changes. Metrics will be collected once the rollout is complete.

<Frame>
  <img src="/public/images/reference/workload/workload-custom-metrics-config.png" />
</Frame>

<Tip>All objects in the UI can be exported to YAML, JSON, or Terraform formats by clicking `Actions` and selecting `Export`.</Tip>

For the configuration schema to use with the API, please refer to the `API Reference` in the documentation, under the `Workload` section.  
For Terraform documentation, [click here](https://registry.terraform.io/providers/controlplane-com/cpln/latest/docs/resources/workload#nestedblock--container--metrics).

To create dashboards for collected custom metrics, please refer to the [Grafana documentation](https://grafana.com/docs/grafana/latest/dashboards/build-dashboards/).


### Firewall
**Path**: `objects/workload/firewall.mdx`

---
title: Firewall
---

<Info>

Inbound network access is only available for workloads of types `serverless` and `standard`. For other workload types, only outbound firewall settings are relevant.

</Info>

## External

The external firewall is used to control Internet traffic to/from a workload.

### Inbound Requests

TODO mention blocking and how it works along with allowing

- By default, all inbound requests are disabled.
- Access is granted by explicitly adding one or more IPv4 / IPv6 / [CIDR](https://en.wikipedia.org/wiki/Classless_Inter-Domain_Routing) addresses or allowing all addresses.
- Using the UI:
  - Multiple address can entered within the textbox by delimiting each address with either a comma or space.
  - An import file can be uploaded containing each address on its own line or delimited with either a comma or space.

<Tip>

The CIDR address `0.0.0.0/0` allows full inbound access from the public Internet.

</Tip>

### Outbound Requests

- By default, all outbound requests are disabled.
- Access is granted by explicitly adding one or more IPv4 / IPv6 / [CIDR](https://en.wikipedia.org/wiki/Classless_Inter-Domain_Routing) addresses or public hostnames or allowing all addresses / hostnames.
  - **When using a hostname, only ports 80, 443, and 445 will be reachable. To allow all ports, enable all outbound requests.**
  - When using a IP or CIDR, all ports will be reachable.
- The IP/CIDR addresses takes precedence over hostnames.
- Using the UI:
  - Multiple address can entered within the textbox by delimiting each address with either a comma or space.
  - An import file can be uploaded containing each address on its own line or delimited with either a comma or space.

<Tip>

The CIDR address `0.0.0.0/0` allows full outbound access to the public Internet.

</Tip>

## Internal

The internal firewall is used to control access between other workloads within an [org](/reference/org). Only the ports listed in the workload containers array will be made accessible to other workloads.

**Available Options:**

- `None`: No access is allowed between workloads.
- `Same GVC`: Workloads running in the same [GVC](/reference/gvc) are accessible.
- `Same Org`: Workloads running in the same [org](/reference/org) are accessible.
- `Specific Workloads`: Specific workloads are allowed access this workload.
  - These workloads can be from the same or different GVCs.
  - The user configuring this setting must have the `view` permission, set within a [policy](/reference/policy#permissions), on the workload being specified.
- `Allow to Access Itself`: Enables replicas of this workload to access themselves.


### General
**Path**: `objects/workload/general.mdx`

---
title: General
---

## Overview

Refer to the [Workload concepts](/concepts/workload) page.

## Create a Workload

Refer to the [Create a Workload](/guides/create-workload) guide for additional details.

## Access Report

Displays the permissions granted to principals for the workload.

## Identity

Refer to the [identities](/reference/identity) page for additional details.

## Connect

TODO mention SSH here for search purposes

A specific replica of a workload can be connected to (similar to `exec`) from either the console or the CLI. This can be used for troubleshooting any issues with the replica.

To connect using the console, click the `Connect` link from a workload. Select the location, container, replica, and command. Click `Connect` to execute the command. By default, the `bash` shell will be executed.

To connect using the CLI, review the workload [connect](/reference/cli#workload-connect) subcommand.

## Debug

In order to see detailed routing for the global georouted endpoint of a workload, debug values can be included within the response headers of a workload's endpoint request.

The values will only be returned when:

1. `debug` is active and the header `x-cpln-debug: true` is in the request.
2. The global or canonical endpoint is being requested.

Using the console, debug can be activated by:

- Clicking `Options`.
- Clicking the `Debug` switch to `on`.
- Clicking `Save`.

After the workload redeploys, the response from the workload's endpoint will contain the following headers if the header `x-cpln-debug: true` is in the request:

- `x-cpln-location`: Location of the responding replica.
- `x-cpln-replica`: Name of the responding replica.

<CodeGroup>

```text Sample Request Headers
GET https://doc-test-v39red0.cpln.app/ HTTP/1.1
Host: doc-test-v39red0.cpln.app
Connection: keep-alive
x-cpln-debug: true
```

```text Sample Response Headers
HTTP/1.1 200 OK
content-length: 2993
content-type: text/plain
date: Fri, 10 Sep 2021 21:34:27 GMT
x-envoy-upstream-service-time: 2
x-cpln-location: aws-us-west-2
x-cpln-replica: doc-test-00083-deployment-75584b7d66-f8wtb
```

</CodeGroup>

## Endpoints

### Canonical Endpoint (global)

This URL is globally load-balanced and TLS terminated. This can be used for testing if there is an issue with the custom domain that is associated with the [GVC](/reference/gvc).

### Location Specific Endpoint

Within each deployment, a location specific URL is available that can be used for testing how your app is responding from a specific location of a [GVC](/reference/gvc).

### Custom Domain Endpoints

Additional globally load-balanced endpoints will show in the workload status for each domain route that is configured to use this workload.

### Internal Mutual-TLS Endpoint

Format: `$workloadName.$gvcName.cpln.local:$port`

Each workload can be allowed to receive requests from other workloads in the same Org internally using the provided internal endpoint. Access to this endpoint is controlled by the internal firewall settings.

TODO show examples for each workload and replica specific endpoints
TODO mention that it cannot reach across locations if the workloads are in the same gvc, hopefully with a matrix table


## Inter-Container Communication

Containers deployed within the same workload can communicate with each other using their names and assigned ports. This setup facilitates direct networking between containers.

- **Container Identification** - Each container is uniquely identified by its name.
- **Port Allocation** - Containers are assigned specific ports for network communication.

### Example Scenario

- Imagine two containers within the same workload: `foo` and `bar`.
- Container `foo` is running on port **4020**.
- Container `bar` is running on port **4030**.

`foo` can access `bar` using the URL **http://bar:4030**. This URL combines the name of the destination container `bar` and its assigned port **4030**, enabling direct communication between the two containers.

This method ensures efficient and organized networking within a multi-container workload environment.


## Built-in Variables

Each workload has the following built-in environment variables:

| Variable Name         | Description                                                                                                                                                 | Format                                           |
| :-------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------- | :----------------------------------------------- |
| CPLN_GLOBAL_ENDPOINT  | The canonical Host header that the container will receive requests on                                                                                       | `${\workloadName}-${gvcAlias}.cpln.app`          |
| CPLN_GVC              | The Global Virtual Cloud (/reference/gvc) the container is running under                                                                                    | string                                           |
| CPLN_GVC_ALIAS        | The Global Virtual Cloud Alias                                                                                                                              | 13 digit alphanumeric value                      |
| CPLN_LOCATION         | The [location](/reference/location) the container is serving the request from                                                                                          | aws-us-west-2, azure-eastus2, gcp-us-east1, etc. |
| CPLN_NAMESPACE        | The namespace of the container                                                                                                                              | Generated random string (e.g., aenhg2ec6pywt)    |
| CPLN_PROVIDER         | The cloud provider the container is serving the request from                                                                                                | aws, azure, gcp, etc.                            |
| CPLN_ORG              | The org the container is running under                                                                                                                      | string                                           |
| CPLN_WORKLOAD         | The workload the container is running under                                                                                                                 | string                                           |
| CPLN_WORKLOAD_VERSION | The Control Plane version of the Workload, only updated when needed to apply changes. For example, changing scaling settings will not cause this to change. | numeric                                          |
| CPLN_TOKEN            | A token used to authenticate to the Control Plane CLI / API                                                                                                | Random authorization token                       |
| CPLN_IMAGE            | The image as defined for this container in the Control Plane api                                                                                            | string                                           |

<Note>

Since a Workload Identity can be the target of a Policy, a running Workload can be authorized to exercise the
Control Plane [CLI](/reference/cli) or [API](/api-reference/api) without any additional authentication.

Examples:

- Direct call to the Control Plane API:

  - `curl ${CPLN_ENDPOINT}/org/${CPLN_ORG} -H "Authorization: ${CPLN_TOKEN}"`

- If the Control Plane CLI installed:
  - `cpln org get ${CPLN_ORG}`

** The value of CPLN_TOKEN is valid only if the request originates from the Workload it is injected in. If it is used from another Workload or externally, a `403 Forbidden` response will be returned. **

</Note>

<Tip>

If a Workload is not assigned an Identity, it can still `GET` its parent Org.

</Tip>

## Logs

Workload logs are consolidated from all the deployed locations and can be viewed using the UI or CLI.

Using the UI, the logs page will be prefilled with the [LogQL](https://grafana.com/docs/loki/latest/logql/)
query for the workload and [GVC](/reference/gvc) name.

```log Example LogQL Query
  {gvc="test-gvc", workload="test-workload"}
```

Logs can be further filtered by:

- `Date`
- `Location`
- `Container`

Grafana can be used to view the logs by clicking the `Explore on Grafana` link within the console.

Refer to the [logs](/reference/logs) page for additional details.


## Rollout Options

Settings to control the rollout process between versions.

```yaml YAML
spec:
  rolloutOptions:
    minReadySeconds: 0
    maxUnavailableReplicas: 1
    maxSurgeReplicas: 100%
    scalingPolicy: OrderedReady
```

#### minReadySeconds

The minimum number of seconds that a workload replica must be running before the rollout progresses.

#### maxUnavailableReplicas

The maximum number or percentage of replicas that can be unavailable during a rollout or during regular rescheduling of workloads.

#### maxSurgeReplicas

The maximum number or percentage of new replicas that can added during a rollout for each batch.

Example: If there are 4 running replicas and maxSurgeReplicas is set to 50%, then during each rollout 2 replicas will be added at the new version. Once they are healthy as determined by the [ReadinessProbe](#readiness-probe), the rollout will continue, -2 old replicas, +2 new replicas, -2 old replicas.

In cases where a short rollout cutover is needed, a maxSurgeReplicas setting of `100%` is recommended.

#### scalingPolicy

The strategies used to update applications and services deployed. Valid values: `OrderedReady` (Updates workloads in a rolling fashion, taking down old ones and bringing up new ones incrementally, ensuring that the service remains available during the update.), `Parallel` (Causes all pods affected by a scaling operation to be created or destroyed simultaneously. This does not affect update operations.). Default: `OrderedReady`.

## Default Ephemeral Storage

Each workload replica receives at least 1GB of local ephemeral solid state drive (SSD) storage. Workloads that request more than 1 core of CPU receive 1GB of storage for each core. For example, a workload that requests 1500 millicore of CPU can consume up to 1.5GB of ephemeral storage.

If the replica uses more than its allotted ephemeral storage, it will be replaced with a new replica.

TODO can add a basic calculator here

## TODO add a gpu section

## Suspend

Each workload can be suspended which immediately stops the workload from serving traffic. This is the same as setting the min/max scale to 0. When the workload is unsuspended, it will resume serving traffic.

To temporarily deactivate a workload choose `Stop` from the Actions menu.

```yaml YAML
spec:
  defaultOptions:
    suspend: true
```

The workload will stop running and will not serve any traffic.

To reactivate the workload, choose `Start` from the actions menu.

```yaml YAML
spec:
  defaultOptions:
    suspend: false
```

## Timeout

The maximum request duration in seconds before Control Plane will timeout. This timeout amount can be reached when Control Plane is waiting for the workload to respond or when waiting for a new workload to become available when using Autoscaling.

The minimum value is **1 second** and the maximum value is **600 seconds**.


### Metering and Billing

The CPU, memory and egress used for mounted object stores are billed to the workload. To review the costs of mounting an object store, query the container named `cpln-mounter` for the workload within the metrics page.

## Workload Health

TODO explain how these are calculated because this is incorrect and missing details

- Possible values:
  - `Loading`
  - `Healthy`
  - `Unhealthy`
  - `Deleting`
  - `Unknown`

## CLI

To view the CLI documentation for Workloads, [click here](/reference/cli#workload).


### JWT Authentication
**Path**: `objects/workload/jwt-auth.mdx`

---
title: JWT Authentication
---

JWT (JSON Web Token) Authentication is a security feature that allows you to validate and authenticate JSON tokens in HTTP requests.
 Multiple JWT providers can be configured for use.

 [Claims](/reference/workload/jwt-auth#claim-to-headers) inside the JWT can be assigned to headers that will be included in the request received by the Workloads.

 [Rules](/reference/workload/jwt-auth#rules) are used to define which requests must provide valid tokens and from which Provider.

 

## Configuration

JWT Authentication is configured as part of the Workload or GVC `sidecar.envoy` settings, specifically within the `http` filters array.

 The configuration includes a name, a typed config, and providers for JWT authentication.

 When configured on the GVC layer, the settings are applied to all Workloads in the GVC.


| Parameter | Type | Description |
| :-------- | :--- | :---------- |
| `name` | string | Must be set to `envoy.filters.http.jwt_authn`. |
| `priority` | number | Used for ordering multiple filters defined in the GVC and Workload. |
| `typed_config."@type"` | string | Must be set to `type.googleapis.com/envoy.extensions.filters.http.jwt_authn.v3.JwtAuthentication`. |
| `typed_config.providers` | object | A map of JWT provider configurations. Keys starting with `cpln_` are restricted and will be displayed in the UI. |
| `typed_config.rules` | object | A set of rules to control which paths and headers require a valid JWT and from which provider. |

## JWT Provider Configuration

Each JWT Provider is configured using a dictionary key of the provider name and the following parameters:

| Parameter | Type | Description |
| :-------- | :--- | :---------- |
| `issuer` | string | The URL of the domain that issued the JWT. |
| `audiences` | string[] | The audiences that are accepted for the JWT. |
| `claim_to_headers` | object[] | Specifies which claims should be added to headers. |
| `remote_jwks` | object | Configuration for [remote JWKS](/reference/workload/jwt-auth#remote-jwks) (JSON Web Key Set). |

### Claim to Headers

Each object represents a mapping between a claims in the JWT and the header it will be mapped to when teh request is forwarded to the workload.

| Parameter | Type | Description |
| :-------- | :--- | :---------- |
| `header_name` | string | The name of the header to add. |
| `claim_name` | string | The name of the claim to extract from the JWT. |

### Remote JWKS

Configuration for JWT public key resolution and cache behavior.

| Parameter | Type | Description |
| :-------- | :--- | :---------- |
| `http_uri` | object | The [HTTP URI](/reference/workload/jwt-auth#http-uri) configuration for the JWKS public key lookup. |
| `cache_duration` | string | Duration to cache the JWKS. Must be in the format "Ns" where N is the number of seconds. Example `300s`. |

#### HTTP URI

The JWKS public key lookup for this Provider.

| Parameter | Type | Description |
| :-------- | :--- | :---------- |
| `uri` | string | The endpoint use to lookup the JWKS public key. |
| `cluster` | string | The cluster name used for the JWKS public key. must match the [Cluster](/reference/workload/jwt-auth#clusters) for this Provider. |
| `timeout` | string | Timeout for the JWKS request. Must be in the format "Ns" where N is the number of seconds. Example `10s`. |

## Rules

Rules are evaluated in order using details from the request. The first matching rule will be used.

| Parameter | Type | Description |
| :-------- | :--- | :---------- |
| `match` | string | The issuer of the JWT. |
| `match.headers` | string[] | An optional list of headers that must exist in the request for this match |
| `match.prefix` | string | A required URI prefix for this match. |
| `requires.provider_name` | string | The optional JWT Provider to use for JWT Verification of this match. All requests are allowed when not specified. |

## Clusters

A Cluster for each provider is required to detail out how the request will be made to the JWT Provider.
 Since most providers must use `https` the cluster configuration the cluster configuration will be similar to the following.

Replace `${providerName}` with the name of the provider.
Replace `${providerEndpoint}` with the endpoint of the provider, ex `mydomain.auth.us-east-1.amazoncognito.com`.

```
      clusters:
        - name: cpln_${providerName}
          type: STRICT_DNS
          load_assignment:
            cluster_name: cpln_${providerName}
            endpoints:
              - lb_endpoints:
                  - endpoint:
                      address:
                        socket_address:
                          address: ${providerEndpoint}
                          port_value: 443
          transport_socket:
            name: envoy.transport_sockets.tls
```

## Notes

- Provider names starting with "cpln_" are configured by the UI and will have more restricted configurations.
- The `cache_duration` and `http_uri.timeout` must be equal when configured using the UI.
- All settings are available from envoyproxy [JWT Authentication](https://www.envoyproxy.io/docs/envoy/latest/api-v3/extensions/filters/http/jwt_authn/v3/config.proto) when configured manually, contact support for details.

## Example Configuration

```
  sidecar:
    envoy:
      clusters:
        - name: cpln_foo
          type: STRICT_DNS
          load_assignment:
            cluster_name: cpln_foo
            endpoints:
              - lb_endpoints:
                  - endpoint:
                      address:
                        socket_address:
                          address: foo.com
                          port_value: 443
          transport_socket:
            name: envoy.transport_sockets.tls
      http:
        - name: envoy.filters.http.jwt_authn
          priority: 50
          typed_config:
            '@type': >-
              type.googleapis.com/envoy.extensions.filters.http.jwt_authn.v3.JwtAuthentication
            providers:
              cpln_foo:
                audiences:
                  - myaudience
                claim_to_headers:
                  - claim_name: user.special
                    header_name: X_SPECIAL_USER
                issuer: https://foo.com/auth
                remote_jwks:
                  cache_duration: 5s
                  http_uri:
                    cluster: cpln_foo
                    timeout: 5s
                    uri: https://foo.com/auth
            rules:
              - match:
                  headers: []
                  prefix: /metric
              - match:
                  headers: []
                  prefix: /
                requires:
                  provider_name: cpln_foo
```


### Load Balancing
**Path**: `objects/workload/load-balancing.mdx`

---
title: Load Balancing
---

## Direct Load Balancer

The Direct Load Balancer allows you to expose your [Workload's Ports](/reference/workload/containers#ports) directly through a cloud load balancer in each location where the workload is running.

## Overview

TODO add status5xx and status401

Direct load balancers are created in each location where a workload is running and are configured for the standard endpoints of the workload. Customers are responsible for configuring the workload with certificates if TLS is required. Each location will obtain a public address that is configured as a possible target of the Geo DNS endpoint. The stadard latency based routing will be used for traffic distribution across the locations. Since the traffic is being routed directly to the workload through the load balancer, Domains do not need to be registered in order to receive traffic on the direct load balancer endpoints. The dns record for the workload can be configured in dns as a cname target for any source domains you wish accpet traffic for.

## Configuration

The Direct Load Balancer configuration is defined in the workload using `directLoadBalancer` in the workload spec, with the following properties:

### direct

The `direct` object contains the configuration for the Direct Load Balancer.

| Property  | Type    | Description                                                                        |
| :-------- | :------ | :--------------------------------------------------------------------------------- |
| `enabled` | boolean | When set to `false`, this load balancer will be stopped and no charges will accrue |
| `ports`   | array   | A list of ports that will be exposed by this load balancer                         |

### `ports`

Each port in the `ports` array is added to the cloud load balancer to control the routing behavior:

| Property        | Type              | Description                                                                                                                                     |
| :-------------- | :---------------- | :---------------------------------------------------------------------------------------------------------------------------------------------- |
| `externalPort`  | number            | The port that is available publicly. Must be between 22 and 32768                                                                               |
| `protocol`      | string            | The protocol that is exposed publicly. Can be either 'TCP' or 'UDP'                                                                             |
| `scheme`        | string (optional) | Overrides the default `https` URL scheme that will be used for links in the UI and status. Valid values are 'http', 'tcp', 'https', 'ws', 'wss' |
| `containerPort` | object            | The port on the container that will receive this traffic                                                                                        |

## Example Configuration

Here's an example configuration for a Direct Load Balancer:

```yaml
loadBalancer:
  direct:
    enabled: true
    ports:
      - externalPort: 80
        protocol: TCP
        scheme: http
        containerPort:
          port: 8080
      - externalPort: 443
        protocol: TCP
        scheme: https
        containerPort:
          port: 8443
      - externalPort: 9000
        protocol: UDP
        containerPort:
          port: 9000
```

# Geo Location Headers

The Geo Location Headers feature allows you to include geographic information in inbound HTTP requests.

When enabled, this feature adds headers containing geographic information to incoming HTTP requests. These headers can provide valuable data about the origin of the request, including the Autonomous System Number (ASN), city, country, and region.

This product includes GeoLite2 data created by MaxMind, available from

<a href="https://www.maxmind.com">https://www.maxmind.com</a>.

## Configuration

| Parameter         | Type    | Description                                                                                                                                |
| :---------------- | :------ | :----------------------------------------------------------------------------------------------------------------------------------------- |
| `enabled`         | boolean | When set to `true`, geo location headers will be included on inbound HTTP requests. Existing headers will be replaced. Default is `false`. |
| `headers.asn`     | string  | The header name for the Autonomous System Number information.                                                                              |
| `headers.city`    | string  | The header name for the city information.                                                                                                  |
| `headers.country` | string  | The header name for the country information.                                                                                               |
| `headers.region`  | string  | The header name for the region information.                                                                                                |

## Usage Guidelines

1. **Enabling the Feature**: Set `geoLocation.enabled` to `true` to activate the Geo Location Headers feature.

2. **Header Configuration**: When enabled, you must specify at least one header (ASN, city, country, or region).

3. **Unique Headers**: The values for ASN, city, country, and region headers must be unique. You cannot use the same header name for different types of information.

4. **Existing Headers**: If enabled, this feature will replace any existing headers with the same names in incoming requests.

## Notes

- Enabling this feature may have performance implications, as it requires additional processing for each incoming request.
- Enabling this feature has no effect if the workload does not expose an http port.
- Ensure that you comply with all relevant data protection and privacy regulations when using geographic information.
- The accuracy of geographic information may vary and should not be relied upon for critical decision-making without verification.
- Workloads receive the latest ip to geo database on startup.

## Example Configuration

Here's an example configuration that enables Geo Location Headers:

This configuration will add the following headers to incoming HTTP requests:

- `X-GeoIP-ASN`: Containing the Autonomous System Number
- `X-GeoIP-City`: Containing the city name
- `X-GeoIP-Country`: Containing the country name
- `X-GeoIP-Region`: Containing the region name

```yaml
loadBalancer:
  geoLocation:
    enabled: true
    headers:
      asn: X-GeoIP-ASN
      city: X-GeoIP-City
      country: X-GeoIP-Country
      region: X-GeoIP-Region
```


### 'Overview'
**Path**: `objects/workload/overview.mdx`

---
title: 'Overview'
---

A workload represents a backend application such as a microservice. It is comprised of one or multiple containers. Containers making up the workload communicate freely on localhost.

Workloads run in Control Plane’s AWS, Azure, GCP accounts or in your own [Custom Location](/reference/location#byok-locations) (BYOK), where clouds/regions are determined by the [GVC](/reference/gvc) definition. Your workload may run only in a single region of one cloud, or across many regions of all the three clouds – completely up to the GVC definition. Requests are routed to the nearest healthy location.

Workloads are managed using a common interface, regardless of cloud providers. Workload log data is consolidated for easy retrieval and analysis. It means that a particular workload can be operating on AWS, Azure and GCP, yet its log – across instances/providers is accessed using a single API/CLI/UI/Grafana operation.

## Features

- [Auto Scaling](#auto-scaling)
- DNS geo-routing TODO explain in its own page
- [Capacity AI](#capacity-ai) - Intelligent resource management
- Load balancing TODO explain in its own page
- [Location specific override](#location-override) of scaling and resource management
- Logging TODO explain how it works in its own page, with its limitations and external logging guide references
- [Probes](#probes)
- [Alerts](#alerts)

## Types

- **Serverless**:
  - Workloads that scale to zero when they aren't receiving requests.
- **Standard**:
  - Workloads that serve network traffic on multiple ports, but do not scale to zero.
- **Cron**:
  - Workloads that run on a schedule, and do not serve network traffic.
- **Stateful**:
  - Simlilar to a `standard` workload, `stateful` workloads have stable replica identities and hostnames, and can mount a [volume set](/reference/volumeset) for persistent storage.

TODO for stateful, show an example of a replica hostname

## Auto Scaling

The number of workload replicas is automatically scaled up and down based on the workload's scaling strategy.

Selectable Scaling Strategies:

TODO multi
TODO a table of which features are available with each autoscaling metric option

- Disabled
- Concurrent Requests Quantity
- Requests Per Second
- Percentage of CPU Utilization
- Request Latency

The minimum and maximum number of replicas that can be deployed are configurable. Workloads can be scaled down to 0 when there is no traffic and can scale up immediately to fulfill new request.

<Info>
  [Capacity AI](#capacity-ai) is not available if CPU Utilization is selected because dynamic allocation of CPU resources cannot be
  accomplished while scaling replicas based on the usage of its CPU.
</Info>

## Capacity AI

A workload can leverage intelligent allocation of its container's resources (CPU and Memory) by using Capacity AI.

Capacity AI uses an analysis of historical usage to adjust these resources up to a configured maximum.

This approach can substantially reduce costs; however, it may result in temporary performance issues during sudden spikes in usage.

If capacity AI is disabled, the amount of resources configured will be fully allocated.

TODO explain more like how it actually kills and regenerates replicas and not an in-place action
TODO mention how currently held connections are handled

## Location Override

By default, both [Capacity AI](#capacity-ai) and [Auto Scaling](#auto-scaling) settings are applied to all deployments at each location enabled in the [GVC](/concepts/gvc). However, these settings can be customized at each location to enhance performance for specific audiences.

This allows for granular control over how your workload scales in specific locations. For instance, if the majority of your users are in Europe, you can set the European locations to a higher level than the rest of the world.

Setting local options ensures that your target users are served quickly and helps reduce costs for unused resources.

## Probes

Probes are a feature of Kubernetes that are used to control the health of an application running inside a container.

Each container can have a:

- Readiness Probe

  - An endpoint is configured to allow queries, enabling you to check if the workload is available and ready to receive requests.

- Liveness Probe
  - An endpoint is configured to allow queries, enabling you to check if the workload is healthy or if it needs to be restarted.

TODO add a basic tcp warning

## Alerts

Using Grafana, you can create alerts on any of the standard metrics exposed by Control Plane, or on your [custom metrics](/reference/workload#metrics). To access Grafana, navigate to one of your orgs in the Control Plane console and click the "Metrics" link.

You have the full capability of Grafana alerting at your disposal. For more information, please consult [the Grafana documentation](https://grafana.com/docs/grafana/latest/alerting/)

TODO add guides for alerting
TODO explain each metric we put out there

## Guides

- [Name](/guides)

## Permissions

The permissions below are used to define [policies](/reference/policy) together with one or more of the four
[principal types](/concepts/principal_types):

| Permission | Description                 | Implies                                 |
| :--------- | :-------------------------- | :-------------------------------------- |
| create     | Create new agents           |                                         |
| delete     | Delete service agents       |                                         |
| edit       | Modify existing agents      | view                                    |
| manage     | Full access                 | create, delete, edit, manage, use, view |
| use        | Use an agent in an identity | view                                    |
| view       | Read-only access            |                                         |

## API Reference

Click to see [API Agent Reference](/api-reference/agent)

## CLI Reference

Click to see [CLI Agent Reference](/references/cli/agent)

## Terraform Reference

Click to see [Terraform Agent Resource](/references/terraform/resources/cpln_gvc)

Click to see [Terraform Agent Data Source](/references/terraform/data-sources/cpln_gvc)


### Security
**Path**: `objects/workload/security.mdx`

---
title: Security
---

## Permissions

The permissions below are used to define [policies](/reference/policy) together with one or more of the four [principal types](/concepts/principal_types):

| Permission           | Description                                    | Implies                                                                 |
| :------------------- | :--------------------------------------------- | :---------------------------------------------------------------------- |
| connect              | Connect to replica (open an interactive shell) |                                                                         |
| create               | Create new workloads                           |                                                                         |
| delete               | Delete existing workloads                      |                                                                         |
| edit                 | Modify existing workloads                      | view                                                                    |
| exec                 | Execute commands                               | exec.runCronWorkload                                                    |
| exec.runCronWorkload | Force a cron-workload to run                   |                                                                         |
| manage               | Full access                                    | connect, create, delete, edit, exec, exec.runCronWorkload, manage, view |
| view                 | Read-only access                               |                                                                         |


## Security Options

// TODO add a guide for this and refer to it and this page from the volumeset page

Settings to control the security of the container at runtime.


### filesystemGroupId

Any mounted [Volumes](#volumes) for this container will be owned by the group id provided. When not specified `0` (root) is used.

```yaml YAML
spec:
  securityOptions:
    filesystemGroupId: 777
```


### Termination Sequence
**Path**: `objects/workload/termination.mdx`

---
title: Termination Sequence
---

TODO how about the same one for initiation

The termination sequence ensures a controlled and graceful process for removing workload replicas from the load balancer pool and handling container termination. The use of a preStop hook, either default or custom, can be leveraged to manage termination and connections as per the workload's requirements.

Termination occurs most often when a workload is being scaled down or when an old version of the workload is taken offline after a successfull update to a new version. In rare cases, maintenance activities can cause workload replicas to be rescheduled and terminated.

The steps below are performed for each replica of the workload.

1. Load Balancer Update: At the initiation of workload termination, load balancers are sent a command to remove the workload replica from the pool.

2. Workload Sidecar and Containers Termination: The workload sidecar (managed by Control Plane) and all other workload containers are sent a command to begin their termination process. This happens at nearly the same time as step 1.

3. Load Balancer Routing: Once the load balancer is updated, any new incoming requests will be routed to the remaining healthy workload replicas for the workload.

4. Sidecar Monitoring: The sidecar managed by Control Plane continues to monitor network activity. It will remain running until no more active requests exist and connections terminate, for a maximum duration of up to 90 seconds.

5. Default PreStop Hook: If no customer-defined preStop hook is provided, a default preStop hook is applied to all workload containers. This default hook consists of the "sleep" command with a duration of 45 seconds. Once the sleep command completes the container is sent a SIGTERM signal and allowed to gracefully shutdown for an additional 45 seconds before receiving a SIGKILL signal.

<Warning>

If the "sleep" executable is not available in the customer's workload container, the container will be sent a graceful termination signal immediately. Requests might still reach it before the load balancer is fully updated.

</Warning>

6. Custom PreStop Hook (Optional): It is recommended to add a custom preStop hook only if specific custom logic is required, such as gracefully terminating connections that would not otherwise terminate. If a custom preStop hook is implemented, ensure it includes a delay or a check for existing requests before exiting. Once the preStop hook completes the container will receive a signal to terminate gracefully (SIGTERM) and will have up to 90 seconds from the start from the start of the shutdown process to complete.

Please note that implementing a custom preStop hook is only advisable when additional logic is necessary for your specific workload termination needs.


### Types
**Path**: `objects/workload/types.mdx`

---
title: Types
---

|                                                                  | Serverless | Standard / Stateful | Cron |
| :--------------------------------------------------------------- | :--------: | :-----------------: | :--: |
| Allow multiple containers                                        |     ✔      |          ✔          |  ✔   |
| Scale to Zero                                                    |     ✔      |                     |      |
| Must expose one HTTP port                                        |     ✔      |
| Allow no exposed ports                                           |            |          ✔          |  ✔   |
| Allow multiple exposed ports                                     |            |          ✔          |      |
| Unable to expose any ports                                       |            |                     |  ✔   |
| Custom Domain requests have the HOST header of the custom domain |            |          ✔          |      |
| Fast switching update between versions                           |     ✔      |                     |      |
| Rolling update between versions                                  |            |          ✔          |      |
| Autoscale by CPU                                                 |     ✔      |          ✔          |      |
| Autoscale by requests per second                                 |     ✔      |          ✔          |      |
| Autoscale by concurrent requests                                 |     ✔      |                     |      |
| Autoscale by request latency                                     |            |          ✔          |      |
| Runs on a schedule and is expected to complete                   |            |                     |  ✔   |
| Readiness/liveness probes default to TCP check of container port |     ✔      |                     |      |
| Readiness/liveness probes default to disabled                    |            |          ✔          |  ✔   |

TODO separate standard and stateful

## Serverless

Serverless workloads should be used for web applications that serve traffic on a single port, but may not need to run 100% of the time.

Serverless workloads **may**:

- Scale to zero.

Serverless workloads **may not**:

- Serve traffic on multiple ports.

Serverless workloads **must**:

- Expose a network endpoint.

## Standard

Standard workloads have greater flexibility in network exposure, but may not scale to zero.

Standard workloads **may**:

- Expose no network endpoint.
- Serve traffic on multiple ports.

Standard workloads **may not**:

- Scale to zero.

## Cron

Cron workloads should be used when you need to perform a background task on a regular schedule.

Cron workloads **may not**:

- Serve traffic.
- Scale to zero.
- Include a container that runs indefinitely.

Cron workloads **must**:

- Exit upon completion of the task at hand. Control Plane will start a new replica of your workload at the next scheduled execution time.



### Cron Configuration

<Info>

Cron workloads are always deployed to all locations within their GVC. Unlike workloads of other types, there is no way to provide location-specific configuration overrides.

</Info>

- `job.schedule`
  - A string, which determines how often the cron workload should execute. This field uses the [Kubernetes cron schedule syntax](https://kubernetes.io/docs/concepts/workloads/controllers/cron-jobs/#cron-schedule-syntax)
- `job.concurrencyPolicy`
  - Either `Forbid` or `Replace`. This determines what Control Plane will do when a prior execution of your workload is still running when the next scheduled execution time arrives.
    - `Forbid`: subsequent executions will be forgone until the running execution completes.
    - `Replace`: the running execution will be stopped so that a new execution can begin.
- `job.historyLimit`
  - An integer between 1 and 10 representing the number of prior executions to be retained for reference.
- `job.restartPolicy`
  - Either `Never` or `OnFailure`. This determines whether your workload will be restarted when it fails on execution.
- `job.activeDeadlineSeconds`
  - **Optional**: By default there is no deadline. Job executions are allowed to run indefinitely.
  - If this property is set, this is the maximum number of a seconds a job execution can run. If the job does not exit in the allotted time, Control Plane will remove it.


### Run Now

<Tip>Cron workloads can be run on-demand even when they are suspended.</Tip>

<Info>When running a cron workload on-demand the job.concurrencyPolicy field is ignored.</Info>

Cron workloads can be run on-demand by submitting a `runCronWorkload` command via `POST https://api.cpln.io/org/my-org/gvc/my-gvc/workload/my-cron-workload/-command`

```yaml runCronWorkload Command
type: runCronWorkload
spec:
  location: aws-us-west-2
  containerOverrides:
    - name: my-container
      command: '/bin/sh'
      cpu: '25m'
      memory: '32Mi'
      image: 'ubuntu:latest'
      args:
        - '-c'
        - sleep 10
      env:
        - name: MY_ENV_VAR
          value: some-new-value
```

#### runCronWorkload Spec

- `location`
  - The name of the location as specified in your [GVC](/reference/gvc) configuration.
- `containerOverrides`
  - **Optional**: A list of objects that override specific parts of a container's configuration.
- `containerOverrides[].name`
  - The name of the container to override in the workload specification.
- `containerOverrides[].command`
  - A new command for the container during this execution only. This field corresponds to `workload.containers[].command` in the workload specification.
- `containerOverrides[].cpu`
  - A new CPU configuration for the container during this execution. This field corresponds to `workload.containers[].cpu` in the workload specification.
- `containerOverrides[].memory`
  - A new memory allocation for the container during this execution. This field corresponds to `workload.containers[].memory` in the workload specification.
- `containerOverrides[].image`
  - A new image for the container during this execution. This field corresponds to `workload.containers[].image` in the workload specification.
- `containerOverrides[].args`
  - A new list of arguments for the container during this execution only. This field corresponds to `workload.containers[].args` in the workload specification.
- `containerOverrides[].env`
  - A new list of environment variables for the container during this execution only. This field corresponds to `workload.containers[].env` in the workload specification.

#### Run via the CLI

Run a cron workload using the `cpln` CLI via `cpln workload cron start`. e.g.

<Tip>If you do not specify a location using --location, the CLI will run the workload everywhere it has been deployed.</Tip>

<Info>The --file parameter should contain a list of containerOverrides.</Info>

```shell CLI Example
echo '[{"name":"my-container","command":"/bin/bash","args":["-c","sleep 10"],"env":[{"name":"MY_ENV_VAR","value":"some-new-value"}]}]' | cpln workload cron start cron --gvc my-gvc --org my-org --file -
```

### Job History

A cron workload retains up to `job.historyLimit` job executions in its history. Each job execution will be in one of the following statuses:

- Invalid
- Active
- Success
- Failure
- Removed


#### The Removed Status

The Removed status indicates that a job execution was deleted before it could finish execution. There are several reasons this can happen, but the most common are:

- The `job.concurrencyPolicy` is `Replace` and while the job was still executing, `job.Schedule` dictated that the job should begin again.
- The `job.activeDeadlineSeconds` limit was exceeded.

## Stateful

### Overview

Stateful workloads are similar to [standard](#standard) and [serverless](#serverless) workloads in many ways. Much of the base functionality including Universal Cloud Identity, autoscaling, metrics, logs, audit trail, etc. remains the same.

### Key Features

#### Stable Replica Identities

Each replica has a permanent identity. If a replica is rescheduled, restarted, or recreated for any reason, its identity will remain constant. Identities are of the form {`workloadName`}-{`replicaIndex`} e.g. for a workload called my-workload, the replica identities would be:

- my-workload-0
- my-workload-1
- etc.

#### Stable Hostnames

Each replica has a hostname corresponding to its identity. Hostnames are of the form `{replicaIdentity}.{\workloadName}` e.g. for a workload called my-workload, the replica hostnames would be:

- my-workload-0.my-workload
- my-workload-1.my-workload
- etc.

So to make an HTTP request to a specific replica, one might execute:

`curl http://my-workload.my-workload-1:8080` from another workload running on Control Plane

#### Persistent Storage

Stateful workloads can mount a [volume set](/reference/volumeset) as a volume in one or more of its containers.
To do this, simply add a volume to a container's list of volumes of the form:

```yaml YAML
uri: cpln://volumeset/my-volume-set
path: /some/mount/directory
```

#### Considerations When Using Persistent Storage

- Volume sets are GVC scoped.
- A workload can only use volume sets in the same GVC.
- A volume set can be used by at most one workload.
- A workload may use any number of volume sets.
- The volume set uri must begin with `cpln://volumeset/`.

### Examples

#### PostgreSQL

[This example](https://github.com/controlplane-com/examples/tree/main/examples/postgres) demonstrates how to run a simple postgresql instance on Control Plane.

#### NATS

[This example](https://github.com/controlplane-com/examples/tree/main/examples/nats) demonstrates how to run [NATS](https://nats.io/) on Control Plane

### Planned Features

- Access to a specific replica via the external endpoint. Currently, the external endpoint load-balances connections across all available replicas.


### Volumes
**Path**: `objects/workload/volumes.mdx`

---
title: Volumes
---

## Overview

Cloud Object and File storage, ephemeral scratch storage and [Secrets](/reference/secret) can be mounted to directories of [containers](#containers) at runtime by adding one or more volumes.

A volume consists of a `uri` and a mount `path`. The `uri` is prefixed with the provider scheme followed by the bucket/storage name (e.g., s3://my-s3-bucket). The mount `path` must be a unique absolute path (e.g., /s3-files). This path will be added to the container's file system and accessible by the running application.

During the set up of a volume using the console, the `uri` name can be entered manually or an existing [Cloud Account](/reference/cloudaccount) can assist looking up the name.

The [identity](#identity) of the workload is used to authenticate to the provider's cloud storage API, or used for authorization to access the Control Plane secret. A [Cloud Account](/reference/cloudaccount) for each cloud storage provider, with the necessary access/roles, must exist and be associated with
the workload [identity](#identity).

Volumes can be shared between containers of the same workload. For example if two containers in a workload are each configured with the volume `uri: 'scratch://volume1', path: '/my/shared/data'` then changes to files in `/my/shared/data` will be visible to both containers.

<Note>

A maximum of 15 volumes can be added.

</Note>

## Volume Providers

TODO mention targeting a property in a secret

| Volume Provider                         | URI Scheme       | Mode                  | Example                                |
| :-------------------------------------- | :--------------- | :-------------------- | :------------------------------------- |
| CPLN Secret                             | cpln://secret    | read-only             | cpln://secret/secretname               |
| [CPLN Volume Set](/reference/volumeset) | cpln://volumeset | read-write            | cpln://volumeset/my-volume-set         |
| AWS S3                                  | s3://            | read-only             | s3://my-s3-bucket                      |
| Google Cloud Storage                    | gs://            | read-only             | gs://my-google-bucket                  |
| Azure Blob Storage                      | azureblob://     | read-only             | azureblob://my-azure-account/container |
| Azure Files                             | azurefs://       | read-write            | azurefs://my-azure-account/my-files    |
| Scratch (emptyDir)                      | scratch://       | read-write, ephemeral | scratch://volume1                      |

## Secret Types

The secret type will dictate how the secret will be mounted to the file system.

- [Opaque Secret](/reference/secret#opaque)
  :

  - The `.payload` property is not required.
  - If the payload is base-64 encoded, the secret can be decoded at runtime by selecting the `Base64 decode at Runtime` checkbox when configuring the secret.
  - The configured path must contain at least one subpath (e.g., /path/subpath). The last path (or file name) will be mounted as a file and contain the payload. If a subpath is not given, the payload of the secret will be mounted as a file named `payload` (e.g., /path/payload).

- [Azure](/reference/secret#azure-sdk), [Docker](/reference/secret#docker), and [GCP](/reference/secret#google-cloud-platform-gcp) Secrets:{' '}

  - The secret will be mounted to the specified path as the file name `___cpln___.secret`.
  - The configured path must contain at least one subpath (e.g., /path/subpath). The last path will be mounted as a directory and contain the `___cpln___.secret` file.

- All other [Secret Types](/reference/secret#secret-types):

  - If the root secret is selected, the specified path will be mounted as a directory. The contents of the directory will contain files named as the key/property of the secret. The contents of each file will contain the value of the respective key.
  - If a key/property of a secret is selected, the secret will be mounted to the specified path as a file. The contents will include the value of the key/property.
  - The directory will include a file named `___cpln___.secret`. The contents of this file will be the JSON formatted output of the secret.

## Identity Configuration

A Workload that is configured with a [Volume](#volumes) that references a [Secret](/reference/secret) must be configured with an [Identity](/reference/secret#reveal-permission) bound to a [policy](/reference/policy) having the [reveal](/reference/secret#reveal-permission) permission.

## Identity Configuration

To allow a workload [identity](/reference/identity) the ability to authenticate to an object store, a [cloud access](/reference/identity#cloud-access-universal-cloud-identity) rule must be created for each provider. A [Cloud Account](/reference/cloudaccount) for each provider must exists in order to create the [cloud access](/reference/identity) rule.

The following list contains the minimum roles/scopes that must be added to a [cloud access](/reference/identity#cloud-access-universal-cloud-identity) rule:

- S3 (using an AWS Cloud Account)

  - Select `Create a new AWS role with existing policies` and choose `AmazonS3ReadOnlyAccess`.

- Google Cloud Storage (using a Google Cloud Account)

  - Select `Create a new GCP service account`.
  - Resource: Storage -> Global -> Bucket -> `Select bucket name`.
  - Role: `Storage Legacy Bucket Reader` and `Storage Legacy Object Reader`.
  - Verify that the [Cloud Account for GCP](/reference/cloudaccount#gcp-details) is configured correctly. In particular, the Control Plane GCP service account requires the `Storage Admin` role.

- Azure Blob Storage and Files (using an Azure Cloud Account)

  - Scope: Storage -> Region -> Storage Accounts -> `Select storage account`.
  - Role (for Azure Files) : [Reader and Data Access](https://docs.microsoft.com/en-us/azure/role-based-access-control/built-in-roles#reader-and-data-access).
  - Role (for Azure Blobs) : `Storage Blob Data Reader`.

## Firewall Configuration

To allow a Workload access to the object stores, the outbound requests of its [external firewall](#external) must either be set to `All Outbound Requests Allowed` or the hostnames listed below for the corresponding object store must be added to the `Outbound Hostname Allow List`.

<CodeGroup>

```bash AWS
  *.amazonaws.com
```

```bash Azure Blob
  *.blob.core.windows.net
  *.azure.com
```

```bash Azure File
  *.file.core.windows.net
  *.azure.com
```

```bash GCP
  *.googleapis.com
```

</CodeGroup>

## Limitations

- Volumes are read-only, except for Azure Files.
- The following Path names are reserved:
  - `/dev`
  - `/dev/log`
  - `/tmp`
  - `/var`
  - `/var/log`
- Authentication to a provider is only facilitated through the workload [identity](#identity). The use of an AWS or Azure key to mount a bucket/container within a container will not work.
- Properties of a mounted object store, such as cache policies and timeouts, cannot be configured by the user. Control Plane has optimized those values for each cloud provider.

## Secret Volume Provider

A [Secret](/reference/secret) can be mapped as a read-only file by using a [Volume](#volumes).

During the configuration of a [Volume](#volumes) using the console, the [Secret](/reference/secret) reference (e.g., `cpln://secret/SECRET_NAME`) can be entered manually or `Control-S` can be pressed to view and select the available [Secrets](/reference/secret).

The Path must be a unique absolute path and, optionally, a file name (e.g., /secret/my-secret.txt) depending on the secret type. This path will be added to the container's file system and will be accessible by the running application.

<Note>

A maximum of 15 volumes can be added.

</Note>


## platform


### Access Control
**Path**: `platform/access-control.mdx`

---
title: Access Control
---

## Overview

Access control starts with an admin inviting a user to a billing account or an org. 

Billing account has only three roles, `billing_admin`, `billing_viewer` and `org_creator`. 

For access control on orgs, there is a policy system in place that is more advanced, which relies on principals and bindings. See [policy](/objects/policy) for detail.

## Principals

A “principal” is somewhat of an overloaded term representing an “identity”. // TODO I think using the word identity is confusing here because it is a kind in the platform

The Control Plane Platform supports four principal types.

Each principal type is scoped to an org and can be granted permissions to certain items or a kind through policies.

- [Users](/reference/user)

A user represents a distinct human being. This principal type is associated with an email. A user is a member of one or more orgs. An authorized principal can invite users to an org (by providing their email address).

- [Service Accounts](/reference/serviceaccount)

A service account is a non-human, often an application that is utilized to consume the API.

- [Groups](/reference/group)

A group is a named collection of users and service accounts. When inviting users to an org, a group can optionally be assigned to the inviting users. A group can also target users dynamically using a query.

- [Identity](/reference/identity)

An identity is short for workload identity. It is a reusable (can be leveraged by multiple workloads) named principal that is only used by workloads. An identity encapsulates a set of [Cloud Access](/objects/identity#cloud-access-universal-cloud-identity) rules. Cloud Access rules define least privilege policies governing access to resources in the org's configured cloud accounts. In addition to Cloud Access rules, an identity also defines a set of [Network Resources](/reference/identity#network-resources-cloud-wormhole).

## Examples

* To allow a user or group access to perform actions within the console, an administrator would create a policy that bounds the user or group to the resource and the necessary permissions.

* To allow a workload the ability to access secured resources within Control Plane (e.g., a secret used as an environment variable), an administrator creates a policy that assigns the necessary permissions to the user or group for the specified resource.


### Accessing Cloud Resources
**Path**: `platform/accessing-cloud-resources.mdx`

---
title: Accessing Cloud Resources
---

// TODO needs aws, azure, gcp in the title
 
## Overview

The Control Plane platform enables your [workloads](/reference/workload), regardless of the cloud provider and location it is running at, to consume native services from different cloud providers in a least-privilege manner, without requiring developers to embed credentials to consume those services (e.g., S3, Dynamo, Big Query, etc.).

This capability is **optional**.

This feature alleviates various aspects of credential management. By leveraging this capability, running workloads becomes more straightforward. Cloud providers refer to this as "temporary session credentials." For more information, see how AWS uses temporary credentials in this [link](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_temp_use-resources.html).

Customers choosing to define fine-grained access that allows a [workload](/reference/workload) to access cloud resources must perform the following:

- Register with Control Plane a [cloud account](/reference/cloudaccount) for each cloud provider (AWS, Azure, or GCP) that hosts the resources your workload requires.
- Create an [identity](/reference/identity) and assign the desired [cloud access](/guides/create-identity#cloud-access) to resources within each registered [cloud account](/reference/cloudaccount).
- Assign the [identity](/reference/identity) to a [workload](/reference/workload). Only one identity can be assigned to a particular workload. [Identities](/reference/identity) can be re-used by multiple workloads and have the same set of permissions.

For Control Plane to provision and de-provision the [identity's](/reference/identity) access to consume native cloud services, Control Plane must be able to:

- Create `Roles` in AWS
- Create `App registrations` in Azure
- Create `Service Accounts` in GCP

For additional details on this process, refer to the [cloud account](/reference/cloudaccount) reference page for each cloud provider:

- [AWS](/reference/cloudaccount#aws-details)
- [Azure](/reference/cloudaccount#azure-details)
- [GCP](/reference/cloudaccount#gcp-details)


### "Relations"
**Path**: `platform/architecture.mdx`

---
title: "Relations"
description: "Description of your new file."
---

TODO show relation of user account org billing account and communication of workloads/clouds


### Audit Trail
**Path**: `platform/audit-trail.mdx`

---
title: Audit Trail
---

## Overview

Control Plane exposes a tamper-proof audit trail service for both Control Plane and custom workload actions. A [UI](#audit-trail-ui) is available to search, filter, and view the actions.

Each action that occurs on the Control Plane UI console or [CLI](/reference/cli) is reliably captured, securely stored, and indexed using the audit trail. When using the Control Plane UI console, most resources have an audit trail link that will redirect to the audit trail page with the resource ID prefilled. Additional filters can be added to drill-down to specific events.

Your custom workloads can leverage this robust audit trail service without having to build your own. Please refer to [custom workloads](#custom-workloads) for additional details.

## Audit Trail UI

The audit trail UI displays the details of each action that has been captured.

Each action contains:

- Timestamp
- Name of resource
- Kind of resource
- Version
- Results
- Message
- Subject (the user that acted)
- Link to display the raw JSON of the events

The actions displayed can be filtered by:

- Kind of resource
- Audit Context (the `cpln` audit context will only display Control Plane actions)
- Resource name or ID
- Subject Name
- Start and optional end date

## Sample Audit Trail UI

Below is a sample of the audit trail UI after executing a query showing all actions that occurred:

<Frame>
  <img src="/public/images/reference/audittrail/log-ui-audit-trail.png" />
</Frame>

## Custom Workloads

The architecture of the audit trail is generic and allows any [workload](/concepts/workload) to capture any action securely and reliably.

For your [workload](/concepts/workload) to use the audit trail, it must first create an [audit context](/reference/auditctx). Refer to the [audit context](/reference/auditctx) reference page for additional details.

**COMING SOON**: Detailed instructions on how your workload can use the audit trail service.

### View Custom Audit Trail

To view the actions that have been captured by your workload, you can use:

- The Control Plane Audit Trail UI:
  - Within the UI, you can select the [audit context](/reference/auditctx) and only view those actions.
- The Control Plane audit API:
  - Leveraging the API, you can create a custom UI to display the audit data.
  - View the OpenAPI documentation [here](https://audit.cpln.io/openapi.json) to review the audit schema and available methods.

## CLI

To view the CLI documentation for the Audit Trail, [click here](/reference/cli#audittrail).


### Authentication
**Path**: `platform/authentication.mdx`

---
title: Authentication
---

## Overview

Control Plane offers the following single sign-on (SSO) providers for authenticating users:

- Google
- GitHub
- Microsoft
- SAML

After successful authentication, users' access privileges are determined based on their assigned [group](/reference/group) membership or [policy](/reference/policy).

## Guides

- [Configure SAML Authentication](/guides/auth/configure-saml)
- [Authentication for CPLN API](/guides/auth/cpln-api)
- [Authentication for CPLN CLI](/guides/auth/cpln-cli)
- [Authentication for Terraform Provider](/guides/auth/terraform-provider)
- [Authentication for Pulumi](/guides/auth/pulumi)


### "Compliance"
**Path**: `platform/compliance.mdx`

---
title: "Compliance"
---

Control Plane is committed to providing secure products and services
to safely and easily manage billions of digital identities across the globe. Our
external certifications reinforce our duty to safeguard our customers. These certifications
are a testament to our unwavering dedication, regularly assessing and validating
the effectiveness of Control Plane's security practices.

## PCI

### Control Plane is Level 1 PCI DSS compliant

Stripe is the payment information and credit card processing provider used by Control Plane.
Security is a top priority for Control Plane, and as such, we have invested significant resources to obtain and
maintain PCI compliance. This commitment to security is evidenced by annual on-site assessments and continuous risk
management to ensure the platform remains secure for all of our users. For a copy of our PCI Attestation of Compliance (AoC),
please contact [support@controlplane.com](mailto:support@controlplane.com).

### What is PCI?

The Payment Card Industry Data Security Standard (PCI DSS) is a security standard for organizations
that handle credit and debit card information. The standard was created to increase controls around payment data and reduce fraud. If you want to sell
online and accept payments from Visa, Mastercard, American Express, or Discover, your software and hosting needs to be PCI compliant.

<Card title="Download PCI Responsibility Matrix" icon="download" href="https://controlplane.com/downloads/Control_Plane_PCI_Responsibilities_Matrix.pdf" />

## SOC2 Type II

### Security as a Company Value

Guided by Control Plane’s security and compliance principles, we deliver products and services that enable simple, secure access to the digital world.

### Secure Personnel

Control Plane prioritizes the security of its own data as well as that of its clients and customers, ensuring that only vetted personnel have access to these resources.

* All Control Plane contractors and employees undergo background checks prior to being engaged or employed by us in accordance with local laws and industry best practices.

* Confidentiality or other types of Non-Disclosure Agreements (NDAs) are signed by all employees, contractors, and others who have a need to access sensitive or internal information.

* We foster a culture of security across our company by continuously training and testing our employees on the latest and emerging security techniques and attack vectors.

### Secure Development

* All development projects at Control Plane, including on-premises software products, support services, and our own Digital Identity Cloud offerings, follow secure development lifecycle principles.

* All development of new products, tools, services, and major changes to existing ones, undergo a design review to ensure security requirements are incorporated into proposed development.

* All team members regularly involved in any system development undergo annual secure development training in coding or scripting languages that they work with, as well as any other relevant training.

* Software development is conducted in line with OWASP Top 10 recommendations for web application security.

### Secure Testing

Control Plane deploys third-party penetration testing and vulnerability scanning of all production and Internet facing systems on a regular basis.

* All new systems and services are scanned prior to being deployed to production.

* All new and existing systems, products, services, and updates are thoroughly evaluated from multiple perspectives. Leveraging external penetration testing and our top-tier internal security engineers, we provide users with a comprehensive and real-world view of all Control Plane products and environments.

* We perform static and dynamic software application security testing of all code, including open-source libraries, as part of our software development process.

### Cloud Security

Control Plane's cloud provides maximum security with complete customer isolation in a modern, multi-tenant cloud architecture.

Control Plane's cloud leverages the native physical and network security features of the cloud service and relies on the providers to maintain the infrastructure, services, and physical access policies and procedures.

* All customer cloud environments and data are isolated using Control Plane’s patented isolation approach. Each customer environment is stored within a dedicated trust zone to prevent any accidental or malicious co-mingling.

* All data is also encrypted at rest and in transmission to prevent any unauthorized access and data breaches. Our entire platform is continuously monitored by dedicated, highly trained Control Plane experts.

* We separate each customer's data and our own, utilizing unique encryption keys to ensure data is protected and isolated.

* Client’s data protection complies with SOC 2 standards to encrypt data in transit and at rest, ensuring customer and company data and sensitive information are protected at all times.

* We implement role-based access controls and the principles of least privileged access, and review revoke access as needed.

### SOC 2 Type 2

Control Plane successfully completed the AICPA Service Organization Control (SOC) 2 Type II audit. The audit confirms that Control Plane’s information security practices, policies, procedures, and operations meet the SOC 2 standards for security.

Control Plane was audited by Prescient Assurance, a leader in security and compliance certifications for B2B and SAAS companies worldwide. Prescient Assurance is a certified public accounting firm in the US and Canada, providing risk management and assurance services including but not limited to SOC 2, PCI, ISO, NIST, GDPR, CCPA, HIPAA, CSA STAR, etc. For more information about Prescient Assurance, you may reach out them at [info@prescientassurance.com](mailto:info@prescientassurance.com).

A successful SOC 2 Type II audit report assures Control Plane’s current and future customers that their data is managed with the highest standards of security and compliance.

For a copy of our audit report, please contact [support@controlplane.com](mailto:support@controlplane.com).


### Logs
**Path**: `platform/logs.mdx`

---
title: Logs
---

## Overview

The logs UI displays the logs for your running [workloads](/concepts/workload). No matter which combination of cloud providers or regions your workload is running at, the logs will be aggregated and displayed as if they were running at one provider/region.

[Filters](#log-filters) can be applied to pinpoint any issues that might be occurring at a specific [workload](/concepts/workload).

The [Grafana](https://grafana.com/grafana/) explorer is available to query and visualize your log data.

## Sample Log UI

Below is a sample of the Log UI after executing a query:

<Frame>
  <img src="/public/images/reference/logs/log-ui.png" />
</Frame>

## LogQL

The Control Plane logs use the LogQL query language to query your log data.

The documentation for LogQL is available [here](https://grafana.com/docs/loki/latest/logql/).

The available labels that can be used to create a query are:

- container
- gvc
- location
- replica
- stream
- workload

## Log Filters

The results of a query can be filtered by the following:

- [Location](/reference/location)
- [Container](/reference/workload/containers)
- Start date and optional end date

  - The date/time selector includes helper buttons ranging from the `Last 5 minutes` to the `Last 30 days`

    <Frame>
      <img src="/public/images/reference/logs/log-ui-date-selector.png" />
    </Frame>

Selecting a [location](/reference/location) or [container](/reference/workload/containers) will automatically add the value to the LogQL query.

## Live Logs

The results of the given query can be streamed in real-time using the `Live` button.

After entering the desired query, click the `Live` button`.

To end the live streaming, click the `Stop` button.

## Grafana

Clicking on the `Explore on Grafana` link will launch the Grafana UI in a new tab. When clicking the button from a specific [workload](/concepts/workload), the query will be prefilled with the [GVC](/reference/gvc) and [workload](/concepts/workload).

Grafana gives you the ability to "Explore your data through ad-hoc queries and dynamic drill-down. Split view and compare different time ranges, queries, and data sources side by side."

View the documentation for Grafana [here](https://grafana.com/docs/grafana/latest/explore/).

Below is a sample of the Grafana UI after executing a query:

<Frame>
  <img src="/public/images/reference/logs/log-ui-grafana.png" />
</Frame>

## Example LogQL Queries

- View the logs for a specific [GVC](/reference/gvc) and [workload](/concepts/workload)

```log Query
{gvc="GVC_NAME", workload="WORKLOAD_NAME"}
```

- View the logs for a GVC, workload, location, and container

```log Query
{gvc="GVC_NAME", workload="WORKLOAD_NAME", location="aws-eu-central-1", container="CONTAINER_NAME"}
```

- View all logs (will contain all workloads logs across gvcs)

```log Query
{gvc=~".+"}
```

## Log Retention Policy

The log retention period for logs stored at Control Plane is 30 days by default and can be adjusted for each Org.

Click [here](/external-logging/overview) to learn how to configure log shipping to an external provider.

## CLI

To view the CLI documentation for logs, [click here](/reference/cli#logs).


### Query
**Path**: `platform/query.mdx`

---
title: Query
---

Clients and items can select/filter other items with the help of queries. Queries utilize [tags](/common-configs/tags), `propertites` of an item or the `relations` of it to execute.

Query is also used for sorting items when fetching a list of items, by any property and by ascending or descending order.

Some examples are of the items that uses queries;
  - [Group](/objects/group) can dynamically assign users.
  - [Policy](/objects/policy) can target items or principals with queries.
  - [GVC](/objects/gvc) can dynamically update its assigned locations.

## Quick guide for using queries

<Tabs>
  <Tab title="UI Console">
    In the UI Console, each page that lists items of a kind has a query button on top of the table.

    <Frame>
      <img src="/public/images/reference/misc/query.png" />
    </Frame>

    The `Match Tags By` selector values are:

    | Selector | Definition                      |
    | :------- | :------------------------------ |
    | All      | All tag items should match      |
    | Any      | Any of the tags should match    |
    | None     | None of these tags should match |

    To filter resources based on their tags:

    1. Click on the `Query` button
    2. Select the wanted match tag selector
    3. Enter a tag name, equality operator, and value. Click `Add`.
    4. Enter any additional tags
    5. Click `Apply` and the filtered resources will be displayed

    To remove the filter, click on the `Query` button again and click `Clear`.
  </Tab>
  <Tab title="CLI">
    Every item kind supports a query command. Below are a few examples:

    ```
    cpln workload query --match any --rel gvc=my-first-gvc --rel gvc=my-second-gvc
    ```

    ```
    cpln workload query --match all --tag environment=production --tag region=europe
    ```

    ```
    cpln workload query --match all --rel gvc=emea --tag payment-service=true --tag thisTagExists --tag version
    ```

    See [cli reference](/references/cli) for the corresponding item kind for more details.
  </Tab>
  <Tab title="API">
    Every item kind supports an api request path that ends with `/-query` and accepts `POST` as the http method. Below are a few examples:

    ```
    https://api.cpln.io/org/myorg/workload/-query
    ```

    ```
    https://api.cpln.io/org/myorg/agent/-query
    ```

    Here is an example request body for querying with api:

    ```
    {
      "spec":{
        "match":"all",
        "terms":[
          {"op":"=","tag":"region","value":"emea"},
          {"rel":"gvc","op":"=","value":"mygvc"}
        ]
      }
    }
    ```

    See [api reference](/api-reference/api) for the corresponding item kind for more details.
  </Tab>
</Tabs>


### "Security"
**Path**: `platform/security.mdx`

---
title: "Security"
---

Authentication and Authorization
User Accounts
Access to the Control Plane console or CLI is granted by authenticating using single sign-on (SSO) to one of the following providers:

Google
Github
Microsoft
Security Assertion Markup Language (SAML)
For your chosen provider, Multi-Factor Authentication (MFA) is recommended.

Service Accounts
Access to the Control Plane CLI using a Service Account is granted by the use of a generated token. During the token generation, the token can be copied to the clipboard or downloaded. Once the token modal is dismissed, the token will no longer be available for display or retrieval. If the token is lost or compromised, it must be regenerated.

Authorization
Authorization to all Control Plane resources is controlled using fine-grained authorization policies assigned to the following principal types:

Users
Groups
Service Accounts
Workload Identities
Certificates
External
All communications from external sources use end-to-end TLS to the destination Workloads.

The server certificates are generated by Let’s Encrypt and are rotated every 60 days.

Internal
All internal communications use mutual TLS (mTLS) using client certificates.

These certificates are rotated every hour.

Firewall
Control Plane uses industry-standard firewall technology. All Workloads are configured to be fully restricted with no internal or external communication enabled by default, except for internal health check monitoring.

External
Inbound access to a Workload can be enabled/disabled from the entire Internet or limited to a specific list of CIDRs.

Outbound access from a Workload can be enabled/disabled to the entire Internet or limited to a specific list of CIDRs or hostnames.

Internal
By default, the Workload’s internal firewall is disabled.

Each Workload can be configured to allow inbound communications from:

Workloads in the same GVC
Workloads in the same Org
Specific Workloads
Allow to access itself (enable replicas of a Workload to access other replicas)
Network Resource Access
Network resource access via agents (configured within a Workload Identity) is implicitly allowed through the firewall.

Workload Access
The internal Kubernetes API access is restricted from all Workloads by multiple firewall levels.
No Kubernetes access tokens are available to the Workloads.
Access to kernel system calls is filtered using gVisor which provides an isolation boundary between the application and the host kernel.
Workloads can communicate with:
The Control Plane metadata service which provides short-lived cloud credentials based on the identity of the Workload.
The Control Plane audit service.
GVC Isolation
Every Workload receives discovery information for other Workloads across the Org but communication is disabled by default using firewalls and client certificate validation.

Workload Isolation
All Workloads are isolated at the Org level based on the use of:

Host-based Firewalls
Client Certificates
Proxies
Direct communications between containers residing in other Orgs are not possible. Isolation between Workloads within an Org is defined based on the Workloads' internal firewall configuration.

Container Isolation
Containers are isolated by the use of:

cgroups
Namespaces
Restricted Syscalls
Restricted Capabilities (groups of syscalls)
Headers
The following headers are sanitized and replaced with valid content before being forwarded to running Workloads:

x-envoy-external-address
Used to verify the source address of the external requestee.
x-forwarded-client-cert
Used to verify that communications between Workloads were made using mTLS and to verify the identity of the requesting Workload.
x-forwarded-for
x-forwarded-proto
x-request-id
referer
Identity Cloud Access
Amazon
Leverages AWS roles and policies to create least privileged, short-lived tokens that are assigned to Workloads during startup.
Network traffic between Control Plane and the AWS API is over a TLS connection.
During the creation of a Cloud Account targeting AWS, a policy within an AWS account is created that allows the Control Plane AWS account the ability to perform the following actions:
iam:CreatePolicy
iam:UpdateAssumeRolePolicy
iam:DetachRolePolicy
iam:TagRole
iam:UpdateRoleDescription
iam:DeletePolicy
iam:CreateRole
iam:DeleteRole
iam:AttachRolePolicy
iam:UpdateRole
iam:PutRolePolicy
iam:TagPolicy
Azure Connector
Leverages Azure Function Apps to create least privileged, short-lived tokens that are assigned to Workloads during startup.
Network traffic between Control Plane and the Azure Function App endpoint is over a TLS connection and the request body is signed and encrypted using JOSE.
The Function App is assigned the owner role within the Azure subscription. Users with permissions to create/update Workloads identities have the ability to assign any scope and roles within the subscription.
Google Cloud
Leverages GCP Service Accounts to create least privileged, short-lived tokens that are assigned to Workloads during startup.
Network traffic between Control Plane and the GCP API is over a TLS connection.
During the creation of a Cloud Account targeting GCP, the Control Plane GCP Service Account is added to a project and granted the following roles:
Viewer
Service Account Admin
Service Account Token Creator
Data Security
Log Access and Retention Policy
All logs generated by an Org are only accessible by a user having the readLogs permission.

Logs are retained for 30 days by default.

Rentention settings for logs, metrics and traces can be adjusted on the Org.

Secrets
Org secrets are encrypted at rest using envelope encryption and use TLS while in transit. Secrets are stored on multiple cloud providers using cloud-based Hardware Security Modules (HSM).

Platform Security
Vulnerability Policy
Security updates and patches are applied regularly and meet all compliance and regulation requirements.

For zero-day vulnerabilities, updates are applied as soon as they are available and verified.

All scheduled maintenance that could cause downtime will be communicated via email and Discord.

If you find any security issues, or have any security questions, please email [secops@controlplane.com](mailto:secops@controlplane.com).

Compliance
Data Centers
The Control Plane platform is hosted at the following providers:

Amazon via Amazon Web Services (AWS)
Google via Google Cloud Platform (GCP)
Microsoft via Azure
Each provider complies with the following:

Sarbanes-Oxley (SOX)
ISO 27001
SOC 1 and SOC 2/SSAE 16/ISAE 3402 (Previously SAS 70 Type II)
PCI Level 1 AWS, Azure, {
" "
} GCP
FISMA Moderate
Payment Processing
Stripe is used to encrypt and process credit card payments. Stripe is PCI Service Provider Level 1 compliant.

Privacy
Control Plane is committed to customer privacy. Review the privacy policy here.

Support staff has access to the following:

Infrastructure support staff have access to monitor Workload activity to maintain the stability of the platform.


### Terms
**Path**: `platform/terms.mdx`

---
title: Terms
---

## Kind

Each object in Control Plane Platform belongs to a kind. These are the fundamental pieces you will create, manage and design the relationship between, such as `Workload`, `VolumeSet`, `Agent`, `Service Account` and more.

Each instance of a kind is referred to as `item` in the platform. Our API drives all of the other clients (`Terraform Provider`, `UI Console`, `CPLN CLI`) and when a request is made to our API, it will usually act on a single or multiple items (`instances of a kind`).

## Context

All of the clients work better within a context, which is a pair of an `org` item, and  a `gvc` item. This makes it easier for the clients to refer to items within an org/gvc.

Some kinds are scoped to a gvc, while others are scoped to an org. `Workload`, `Identity`, and `VolumeSet` kinds are scoped under gvc, while all other kinds are scoped under org.

## Links

Each `item` is accessible by its link. This is a url/address for the `item` and is an essential part of the platform. There are two ways to structure the link of an item, which is called a `selfLink`. These types are `fullLink` and `relativeLink`. When a kind is scoped to a gvc, its relative link must include gvc name.

<Note>
Relative link relies on the `context` set in the client that is being used.
</Note>

See examples for different possibilities such as gvc or org scoped items.


| Kind     | Item Name  | Full Link                                | Relative Link                   |
| -------- | ---------- | ---------------------------------------- | ------------------------------- |
| Org      | myorg      | /org/myorg                               | NA                              |
| Secret   | mysecret   | /org/myorg/secret/mysecret               | //secret/mysecret               |
| GVC      | mygvc      | /org/myorg/gvc/mygvc                     | //gvc/mygvc                     |
| Workload | myworkload | /org/myorg/gvc/mygvc/workload/myworkload | //gvc/mygvc/workload/myworkload |


## Clients

There are multiple ways to use the platform, which are our `clients`. Such as the UI Console, CPLN API, CPLN CLI, Terraform Provider Plugin, Pulumi.

## Containers

Refer to the [Kubernetes containers](https://kubernetes.io/docs/concepts/containers/) concepts page.

## Grafana Alerts

Alerts can be created from the Org's Grafana instance. Refer to these [instructions](https://grafana.com/docs/grafana/latest/alerting/unified-alerting/alerting-rules/create-grafana-managed-rule/) on how to create a Grafana managed alert.

### Built-in Alert Rules

The Grafana instance accessed via the "Metrics" link of your Workload comes with several automatically provisioned objects, including built-in alert rules. These rules can send notifications to one or several of your preferred contact points (e.g., email). By default, notifications for these alerts are disabled. To receive notifications, you must add a contact point (refer to the Grafana [documentation](https://grafana.com/docs/grafana/latest/alerting/fundamentals/notifications/contact-points/)).

You can find the built-in alert rules in your Grafana instance under `Alerts` > `Alert rules`:

- `container-restarts`

  - This alert triggers if any of your workloads restart repeatedly. Specifically, it activates if the Control Plane custom metric `container_restarts` is greater than 1 in the last 5 minutes.

- `stuck-deployments`

  - This alert triggers if any of your deployments are stuck.
  - It checks for multiple container restarts within specific groups (gvc and workload). If any group exceeds one restart in the last 15 minutes, it triggers an alert.

To edit or create new alerts, go to the `Alerts` > `Alert rules` section in your Grafana instance.

If you edit built-in alerts, your changes will be saved. However, if you delete any built-in alerts, they will be recreated automatically the next time you log in to Grafana.

To disable built-in alerts, edit the corresponding alert rule and turn on the `Pause evaluation` toggle in the alert editing view.

## Public IPs

// TODO use tabs here for each client

The list of public IPs for each cloud provider and region can be obtained from the following:

- Console UI: The `Locations` page. Select the location to display the IP ranges.
- CLI: Using the command [cpln location get -o json](/reference/cli#location) will list the IPs in the `ipRanges` property. The output can also be formatted in YAML by using the flag `-o yaml-slim`.
- API: Using the `location` endpoint. View the available endpoints [here](/api-reference/location/get-all-locations). The `ipRanges` property will contain the list of SIPs.

<Tip>

The list of IPs may be required by external services that restrict the IPs allowed to call them.

The IPs may change when underlying infrastructure changes. Therefore, Control Plane recommends the automation of querying the location API for changes. In case of changes, the automation should re-configure external services’ allowed IP address list.

</Tip>

## Workload Deployment Errors

- `Error: exitCode: 1 message: standard_init_linux.go:228: exec user process caused: exec format error`
  - The incorrect platform was used to build the configured image. Control Plane requires the image target `amd64`. Refer to the [Push an Image Guide](/guides/push-image#step-2-build-a-new-image-using-docker-and-a-dockerfile-optional) for additional details.


## Root


### Release Notes
**Path**: `release-notes.mdx`

---
title: Release Notes
---

This page will be updated regularly. Check back often for the latest features, updates, and changes.

## Latest Versions

* CLI

  * Date: December 2, 2024

  * Version Info

    * npm: **3.2.1**

  * [Installation Instructions](/reference/cli)

## Known Issues

* CLI

  * Windows

    * [Autocomplete](/reference/cli#autocomplete) functionality is not available. A [workaround](/reference/cli#autocomplete) is available for `cygwin`.

## CLI v3.2.1 Release

* Date: December 2, 2024

* Version Info

  * npm: 3.2.1

* **Minor Changes**

  * Fix yaml output for cpln convert.

  * Handle tar errors and warnings.

  * Fix cpln cp for Windows.

  * Inject more cpln context to helm template.

  * Convert individual K8s Jobs.

## CLI v3.2.0 Release

* Date: November 1, 2024

* Version Info

  * npm: 3.2.0

* **Minor Changes**

  * Add 'names' as a new output option.

  * Enhance [cpln cp](/reference/cli#cp) reliability and performance.

  * Add progress indicator for [cpln cp](/reference/cli#cp).

  * Fix priority resource deletion order in [cpln helm uninstall](/reference/cli#helm-uninstall).

  * Add `--all` option to [cpln helm get values](/reference/cli#helm-get-values).

## CLI v3.1.1 Release

* Date: August 26, 2024

* Version Info

  * npm: 3.1.1

* **Patch Changes:**

  * Fix a bug causing invalid target links in policies when converting K8s files using the [cpln convert](/reference/cli#convert).

  * Add tags that are passed to [cpln helm install](/reference/cli#helm-install) to the state as well.

## CLI v3.1.0 Release

* Date: August 19, 2024

* Version Info

  * npm: 3.1.0

* **Major Changes:**

  * Refactor of [cpln workload exec](/reference/cli#workload-exec) command:The [cpln workload exec](/reference/cli#workload-exec) command has been updated to align with the functionality of [kubectl exec](https://kubernetes.io/docs/reference/kubectl/generated/kubectl_exec/).For more details, refer to the [cpln workload exec guide](/guides/cli/workload/exec).

    * **Stdin and TTY Handling:** Previously, stdin and TTY were enabled by default. Now, these must be explicitly set:

      * Use the `-i` option to send stdin to the workload.

      * Use the `-t` option to treat stdin as TTY.

* **Minor Changes:**

  * Improve [cpln convert](/reference/cli#convert) command to convert ConfigMaps, Persistent Volume Claims and pull secrets.

  * Add `--encoding` option to [cpln secret create-opaque](/reference/cli#secret-create-opaque) command.

  * Fix path syntax for [cpln mk8s kubeconfig](/reference/cli#mk8s-kubeconfig) command on Widnows.

  * Use the first location of a GVC if the `--location` option is not specified for [cpln workload exec](/reference/cli#workload-exec), [cpln workload connect](/reference/cli#workload-connect) and [cpln cp](/reference/cli#cp) commands. Specifying a location is no longer required.

## CLI v3.0.0 Release

* Date: July 22, 2024

* Version Info

  * npm: 3.0.0

* Notes:

  * Fix cpln cp.

  * Allow identity name for policy binding.

## CLI v2.4.0 Release

* Date: July 15, 2024

* Version Info

  * npm: 2.4.0

* Notes:

  * Use cpln://reference to reference fieldRef for K8s Converter.

  * Add BYOK location support.

  * Allow setting profile's default org and gvc to empty.

  * Optimize the performance of the `cpln helm list` command.

  * Add `cpln cp` command.

  * Directly stream stdin to the workload replica when using the `cpln workload exec` and `cpln workload run commands`.

## CLI v2.3.1 Release

* Date: June 9, 2024

* Version Info

  * npm: 2.3.1

* Notes:

  * Fix stdin null issue on macOS.

## CLI v2.3.0 Release

* Date: June 7, 2024

* Version Info

  * npm: 2.3.0

* Notes:

  * Query by GVC if --gvc option is specified.

  * Fix stack capture of command & args.

  * Retry requests upon hitting rate limits.

  * Remove maxContentLength limit.

  * Handle standard input (stdin) in workload exec.

  * Enhance error handling for Helm deployment API call failures.

  * Add --no-cache argument to image build command.

## CLI v2.2.2 Release

* Date: May 28, 2024

* Version Info

  * npm: 2.2.2

* Notes:

  * Notify users of a new CLI version once a day.

  * Prevent a helm release from managing a resource that belongs to a different release.

## CLI v2.2.1 Release

* Date: May 15, 2024

* Version Info

  * npm: 2.2.1

* Notes:

  * Add retry to internal API requests.

  * Helm: Skip resource deletion if specified.

## CLI v2.2.0 Release

* Date: May 15, 2024

* Version Info

  * npm: 2.2.0

* Notes:

  * Additional k8s converter functionionality.

## CLI v2.1.0 Release

* Date: April 24, 2024

* Version Info

  * npm: 2.1.0

* Notes:

  * Truncate description text if length > 40 characters.

  * Add alias and update location table view for mk8s.

## CLI v2.0.2 Release

* Date: April 1, 2024

* Version Info

  * npm: 2.0.2

* Notes:

  * Fix terminal interrupt handlers.

  * Provide user with a manual delete command to delete workload if workload run fails.

  * Fix generate name bug in helm.

  * Modify priority order in order for policy to be created before workload.

## CLI v2.0.1 Release

* Date: March 18, 2024

* Version Info

  * npm: 2.0.1

* Notes:

  * Add CRON `get` command.

  * Add fetch pages to CRON get and snapshot get.

  * Limit cron get and snapshot get output to --max.

  * Add release notes page to readme.

  * Add delete and get volume commands.

  * Enforce valid naming in stack command.

  * Require location for workload connect/exec command.

  * Add resize terminal feature to workload run interactive.

  * Fix protocol override in k8s converter.

  * Add stop replica command.

  * Add helm rollback and helm history.

  * Add helm upgrade command.

  * Remove clone command from volumeset.

  * Upgrade default buildpacks to `builder:22`.

## CLI v1.6.0 Release

* Date: February 7, 2024

* Version Info

  * npm: 1.6.0

* Notes:

  * Print `workload cron start` command output as a table.

  * Add container override arguments to the `workload cron start` command.

  * Fix file option to load from stdin when file option is optional.

  * Update description for: `clone`, `Expand volume set`, `snapshot`.

  * Fix command snapshot date formats.

  * For snapshot, Update column name from `Created` to `Snapshot Created`.

  * Logs: add `-f` as alias to `-t`.

  * Fix `delete` in `workload run` command.

  * Add external id to AWS and ECR secrets.

  * Update dependencies.

## CLI v1.5.4 Release

* Date: January 23, 2024

* Version Info

  * npm: 1.5.4

* Notes:

  * Add `ACTIVE` column for profiles.

  * Modify helm list to display release names only.

  * Print `NOTES.txt` on helm install.

  * Sort helm template output before applying.

  * Add helm wait option.

  * Helm --wait option to wait 5m if --timeout is not provided.

  * Fix for terminal resizing.

  * Inject GVC into the helm template command as a value.

  * Add `volume set` and `snapshot` commands.

  * Add `cron` and `replica` sub-commands to workload.

## CLI v1.5.2 Release

* Date: December 6, 2023

* Version Info

  * npm: 1.5.2

* Notes:

  * Fix workload connect prompt length and line wraps.

  * Improve workload connect prompt issue.

  * Resizing terminal on the initial connection.

  * Change login port to 48794.

  * Add check for latest release.

  * Add stack command.

  * Add helm command.

  * Add --replace flag.

## CLI v1.4.0 Release

* Date: November 21, 2023

* Version Info

  * npm: 1.4.0

* Notes:

  * Fix prompt length and line wrap when connecting to workload + Improve volumeset deletion.

  * Force delete command.

  * Fix SAML login.

  * Add tags enabled for the `workload run` command.

## CLI v1.3.2 Release

* Date: October 30, 2023

* Version Info

  * npm: 1.3.2

* Notes:

  * Remove deploy timestamp tag from slimmed objects.

  * Add account get and org create.

  * Add token server.

## CLI v1.2.6 Release

* Date: October 16, 2023

* Version Info

  * npm: 1.2.6

* Notes:

  * Remove deploy timestamp tag from slimmed output.

  * Connect to first replica if multiple are present.

  * Add ready flag to apply command.

  * Add remove tag flag.

  * Adding useful error messages to auto-completion installation.

## CLI v1.2.5 Release

* Date: September 28, 2023

* Version Info

  * npm: 1.2.5

* Notes:

  * Fix bug in setting sleep for ubuntu image on run cmd.

  * Deprecate container port property. Use ports going forward.

  * Inform user on verbose mode when CPLN\_ORG, CPLN\_GVC, CPLN\_ENDPOINT or CPLN\_PROFILE is being used.

  * Add mk8s command.

  * Fix GVC add/remove location commands when resource doesn't contain a location property.

  * Improved slim output format.

  * Add recursive folder support for apply command.

  * Add Terraform output option.

  * Add retry logic to the workload run command.

## CLI v1.1.0 Release

* Date: July 9, 2023

* Version Info

  * npm: 1.1.0 / Build: 925739349 / Version: 9784f19

* Notes:

  * Added json-slim and yaml-slim output options.

## CLI v1.0.0 Release

* Date: June 27, 2023

* Version Info

  * npm: 1.0.0 / Build: 912602973 / Version: bddd583

* Notes:

  * Logs: `maxBodySize` not set when reading.

  * Inform user when the environment variable `CPLN_TOKEN` is being used for authentication.

  * Updates to `cpln workload run` command.

## CLI v0.0.90 Release

* Date: May 5, 2023

* Version Info

  * npm: 0.0.90 / Build: 859056052 / Version: b58459f

* Notes:

  * Update HTML on `cpln login` browser page.

## CLI v0.0.82-89 Release

* Date: April 21, 2023

* Version Info

  * npm: 0.0.89 / Build: 844733757 / Version: ba7245d

* Notes:

  * Fix get all workloads from all GVCs.

  * Update image copy command to use a destination profile.

  * Workload `run` command.

  * Allow `--tag` to accept an optional value.

## CLI v0.0.82 Release

* Date: March 15, 2023

* Version Info

  * npm: 0.0.82 / Build: 807750891 / Version: 99792cd

* Notes:

  * Added image copy command.

## CLI v0.0.73-81 Release

* Notes:

  * K8s converter not creating identity and policy if not required.

  * Added prestop hook for k8s converter.

  * Added GVC environment variables and container inherit environment variables.

  * Added active deadline seconds to workload update command.

  * Fixed token for fetching logs, exec, and connect.

  * Fixed long websocket connections.

  * Added SAML login.

  * Fix workload create for standard workload type.

  * Added workload ready status to workload get command.

  * Command: Only enable raw mode if it's TTY.

## CLI v0.0.72 Release

* Date: November 7, 2022

* Version Info

  * npm: 0.0.72 / Build: 687290579 / Version: 718968f

* Notes:

  * Added docker store and erase commands. Fixes issue when using both `cpln image` and `docker login` commands.

## CLI v0.0.71 Release

* Date: November 2, 2022

* Version Info

  * npm: 0.0.71 / Build: 683695375 / Version: 3124c60

* Notes:

  * Added instructions to create an Azure Connector Cloud Account.

  * Added delete resource from files command `cpln delete`.

  * Added k8s manifest to Control Plane manifest converter command `cpln convert`.

  * Added stop/start/suspend commands to `cpln workload`.

  * Added `cpln workload exec` command.

* [Installation Instructions](/reference/cli#instruction)

## CLI v0.0.61 Release

* Date: August 30, 2022

* Version Info

  * npm: 0.0.61 / Build: 626945486 / Version: 2f98cdd

* Notes:

  * Updated agent image version.

  * Added standard workload.

## CLI v0.0.60 Release

* Date: August 24, 2022

* Version Info

  * npm: 0.0.60 / Build: 621247366 / Version: cd5c35e

* Notes:

  * Updated agent image version.

## CLI v0.0.59 Release

* Date: July 28, 2022

* Version Info

  * npm: 0.0.59 / Build: 599431645 / Version: 4ebdf36

* Notes:

  * Added `NGS` Cloud Account.

  * Added `NATS Account` Secret type.

  * Removed GVC domain.

  * Upgrade buildpacks to version 0.27.0.

## CLI v0.0.57 Release

* Date: May 23, 2022

* Version Info

  * npm: 0.0.57 / Build: 545699003 / Version: e16bbbf

* Notes:

  * Add default of 50 maximum records.

  * Fix issue when using a value \< 1 to return all records.

  * Fix issue when updating container memory.

  * Add additional set flags for the `workload update` command.

## CLI v0.0.55 Release

* Date: February 21, 2022

* Version Info

  * npm: 0.0.55 / Build: 475892711 / Version: 6b87320

* Notes:

  * Add --psp flag for agent manifest command to configure a pod security policy.

  * Enable the k8s agent to run as a privileged pod.

## Previous Versions

## CLI v0.0.54 Release

* Date: February 10, 2022

* Version Info

  * npm: 0.0.54 / Build: 467951861 / Version: 7c17ca8

* Notes:

  * Fix issues with the k8s Agent.

  * Fix issue when building images on ARM64 machines.

## CLI v0.0.52 Release

* Date: January 20, 2022

* Version Info

  * npm: 0.0.52 / Build: 452736596 / Version: bffc420

* Notes:

  * Updated login page.

  * Fix issue persisting profile default GVC when using the --token flag.

## CLI v0.0.50 Release

* Date: December 28, 2021

* Version Info

  * npm: 0.0.50 / Build: 438151551 / Version: f1586e9

* Notes:

  * Update pack to version 0.23.0.

  * Added ARM64 support for pack.

## CLI v0.0.49 Release

* Date: November 30, 2021

* Version Info

  * npm: 0.0.49 / Build: 419000724 / Version: cdc6af5

* Notes:

  * Fix issue building an image using an ARM processor.

## CLI v0.0.48 Release

* Date: November 18, 2021

* Version Info

  * npm: 0.0.48 / Build: 411017996 / Version: d1b67a5

* Notes:

  * Updated k8s agent version.

## CLI v0.0.47 Release

* Date: November 11, 2021

* Version Info

  * npm: 0.0.47 / Build: 407265118 / Version: 140e31f

* Notes:

  * Added `cpln agent manifest` command to allow running an agent on a k8s cluster.

## CLI v0.0.46 Release

* Date: October 11, 2021

* Version Info

  * npm: 0.0.46 / Build: 386067508 / Version: 7ca3dd7

* Notes:

  * Update error handling:

    * All errors are outputted to stderr.

    * If the -o flag is set to json or yaml, the output will be in the respective format. If -o is set to text, only the
      output of the .message property from response object will be outputted. Otherwise, output the
      error.message property from the exception.

    * If there are multiple actions, any errors will be included in the output.

    * The exit code will be 1 if at least one action failed.

  * Added `force-redeployment` subcommand to the `workload` command.

## CLI v0.0.44 Release

* Date: September 10, 2021

* Version Info

  * npm: 0.0.44 / Build: 368794552 / Version: 6435502

* Notes:

  * New workload subcommands:

    * connect: Connect to a replica of the workload.

    * get-replicas: Get the replicas of the referenced workload in a given location.

## CLI v0.0.43 Release

* Date: September 7, 2021

* Version Info

  * npm: 0.0.43 / Build: 365437960 / Version: f3f59d1

* Notes:

  * New secret type: azure-connector

## CLI v0.0.42 Release

* Date: July 16, 2021

* Version Info

  * npm: 0.0.42 / Build: 338229644 / Version: db33b86

* Notes:

  * CLI can work without CPLN\_ENDPOINT

  * Allow environment variables without a value

  * Add mount volumes to workload

## CLI v0.0.41 Release

* Date: July 14, 2021

* Version Info

  * npm: 0.0.41 / Build: 336244315 / Version: b864944

* Notes:

  * Create \~/.docker during `cpln image docker-login`

## CLI v0.0.40 Release

* Date: June 30, 2021

* Version Info

  * npm: 0.0.40 / Build: 329714271 / Version: 4c67950

* Notes:

  * Infers container name from image name unless defined using the --container-name argument.

  * Set internal firewall to `same-org` when the `--public` flag is used during the creation of a workload.

## CLI v0.0.39 Release

* Date: June 22, 2021

* Version Info

  * npm: 0.0.39 / Build: 325071193 / Version: acbc925

* Notes:

  * Added 'smart' reveal to secret output format

  * Added multi-document sources for the `apply` command

## CLI v0.0.38 Release

* Date: June 16, 2021

* Version Info

  * npm: 0.0.38 / Build: 321518748 / Version: aa315ea

* Notes:

  * Remove account subcommand and references

  * Update buildpacks to version 0.19.0

  * Add `create-ecr` secret command

  * Fix create command for Cloud Account to include additional error messages

  * Fix issue when shell would close when running `cpln login`

## CLI v0.0.36 Release

* Date: June 7, 2021

* Version Info

  * npm: 0.0.36 / Build: 315420524 / Version: cb4cb4f

* Notes:

  * For the binary package, include the executable `docker-credential-cpln` in the same archive as the CLI

## CLI v0.0.34 Release

* Date: May 31, 2021

* Version Info

  * npm: 0.0.34 / Build: 312124373 / Version: 0a44b37

* Notes:

  * Make profile optional if at least --endpoint & --token flags are set

  * When there is a profile present, honor the environment variables 'CPLN\_ORG', 'CPN\_GVC', 'CPLN\_ENDPOINT', and 'CPLN\_TOKEN'

  * Install auto-completion for non-interactive installation

## CLI v0.0.33 Release

* Date: May 6, 2021

* Version Info

  * npm: 0.0.33 / Build: 298694423 / Version: 30dc6d4

* Notes:

  * Added `task` as a policy target kind

  * Resume `cpln logs` stream on disconnect

  * Refresh authentication token before getting logs

  * Fix for missing Docker config.json file

## CLI v0.0.31 Release

* Date: May 1, 2021

* Version Info

  * npm: 0.0.31 / Build: 295632825 / Version: 01e4461

* Notes:

  * Added `cpln agent info` command

## CLI v0.0.30 Release

* Date: April 27, 2021

* Version Info

  * npm: 0.0.30 / Build: 293303600 / Version: 81bde51

* Notes:

  * Fix for the closing of a command or PowerShell shell in Windows 10 if the `cpln login` command is executed.

  * Updated axios to version 0.21.1


## self-hosted/byok


### Overview
**Path**: `self-hosted/byok/overview.mdx`

---
title: Overview
---

The Bring Your Own Kubernetes (BYOK) offering allows you to take a Kubernetes cluster and plug it into the Control Plane Cloud Platform. It works by installing a few additional components into the cluster and then it registers as a new Location in the API for your Org(s). Any Workloads that are configured for that Location will be managed by Control Plane and roll out onto your cluster. You get all the benefits of Control Plane with the added flexibility and security of running in your own cloud account or data center.

## Requirements

- Label at least one nodegroup in the cluster with `cpln.io/nodeType=core`. This label deploys critical system pods and workloads managed by the Control Plane Platform.
- Minimum 2 CPUs per node (4 CPUs or more recommended)
- Minimum 8 GB of RAM per node (16 GB or more recommended)
- Minimum 2 nodes per cluster (3 or more recommended)
- Node processor architecture: x86
- Supports the three most recent minor releases of Kubernetes for installation. For information on Kubernetes releases, [click here](https://kubernetes.io/releases/).
- Full network connectivity between all nodes in the cluster (either public or private network)
- Enable egress access for all nodes (contact customer support for alternatives if this is not feasible)
- Exclude service-mesh from your cluster. Control Plane provides an out-of-the-box Istio-based service-mesh

## Setup Procedure

### Step 1 - Create BYOK Location Using the UI Console

1. Create a new location by either:
   - Clicking `Locations` in the left menu and then clicking `New`, or
   - Clicking the `Create` dropdown in the upper right corner and selecting `Location`.

2. Enter a unique name. Click `Next (Tags)`.

3. Enter any optional [tags](/reference/misc#tags). Click `Create`.

You have now created a new location. To use it, install this location on at least one Kubernetes cluster as described in the next step.

### Step 2 - Install Location on a Kubernetes Cluster

1. Generate the install command:
   - Click `Actions` in the upper right corner of the created location page and choose `Install`.

<Frame>
  <img src="/public/images/byok/install-location.png" />
</Frame>

2. Copy the generated kubectl command. You will need to apply the command within about 5 and a half minutes, as the manifests contain sensitive tokens.

3. Connect to your Kubernetes cluster that you wish to integrate as a location in Control Plane and apply the kubectl command generated in the previous step.

4. Follow the `cpln-byok-agent` deployment in the `kube-system` namespace. Use the following command to fetch its status: 
   ```shell
   kubectl get pod -l app=cpln-byok-agent -n kube-system
   ```
   The `cpln-byok-agent` will create and maintain the necessary deployments for your location to function. Allow a few minutes for all necessary components to finish deploying.

<Note>
Ensure at least one of the node groups is labeled with `cpln.io/nodeType=core`, as it is required to deploy essential components.
</Note>

You can now add the BYOK location to a GVC in your Org. 

Repeat [Step 2 - Install Location on a Kubernetes Cluster](#step-2-install-location-on-a-kubernetes-cluster) if you need to add more clusters to the same location, or start from [Step 1 - Create BYOK Location Using the UI Console](#step-1-create-byok-location-using-the-ui-console) to add another location.

## Uninstall Procedure

1. Generate the uninstall command:
   - Click `Actions` in the upper right corner of the location you want to remove and choose `Uninstall`.

<Frame>
  <img src="/public/images/byok/install-location.png" />
</Frame>

2. Copy the generated `kubectl` command. You will need to apply the command within about 5 and a half minutes, as the manifests contain sensitive tokens.

3. Connect to your Kubernetes cluster that you wish to remove from the location in Control Plane and apply the `kubectl` command generated in the previous step.

4. The job `cpln-agent-uninstall` will be created in the `kube-system` namespace. It will clean up all BYOK components from the cluster.

## Cloud Provider Recommendations

### GKE

- Private Cluster: Enabled
- Default SNAT: Enabled
- Stack type: IPv4
- VPC-native traffic routing: Enabled
- Intranode visibility: Disabled
- HTTP Load Balancing: Enabled
- Calico Network Policy: Enabled
- DNS provider: Kube-DNS
- Shielded GKE Nodes: Enabled
- Application -layer secrets encryption: Enabled
- Compute Engine persistent disk CSI Driver: Enabled
- Service Mesh: Disabled

After the GKE cluster is created you must provide the IP Address of the kube-dns service in the kube-system namespace to support.

```bash
kubectl get svc -n kube-system kube-dns
```

Once the Control Plane configuration has been applied to the cluster, scale down the kube-dns deployments.

```bash
kubectl scale --replicas=0 deployment/kube-dns-autoscaler --namespace=kube-system
kubectl scale --replicas=0 deployment/kube-dns --namespace=kube-system
```

### EKS

- Enabled Add-ons:
  - Amazon VPC CNI
  - kube-proxy
  - CoreDNS
  - Amazon EBS CSI Driver

## Settings

When using a BYOK Location with Control Plane there are additional settings available to control the behavior of that location.

- [Agent Configuration:](/byok/settings/agent) Agent settings are used during the installation and upgrade of all BYOK components.
- [Actuator Settings:](/byok/settings/actuator) Actuator settings are used to control ingress and other changes to the way workloads are created in Kubernetes.
- [Workload Settings:](/byok/settings/workload) Additional workload settings when using a BYOK Location.
- [Volume Set Settings:](/byok/settings/volumeset) Additional volume set settings when using a BYOK Location.

## Guides

- [Configure a Content Delivery Network (CDN) Domain.](/guides/configure-cdn#amazon-cloudfront-configuration-steps)


## self-hosted/byok/settings


### Actuator Settings
**Path**: `self-hosted/byok/settings/actuator.mdx`

---
title: Actuator Settings
---

The Actuator component receives events from Control Plane and uses the metadata provided in the events to instantiate the desired configuration on the kubernetes cluster. This can be Kubernetes deployments, domain routing configuration, storage devices, etc.

## Settings

These environment variables can be provided to the actuator deployment on the cluster. If you are making adjustments to these settings provide the changes to Control Plane support so they will be included when new manifests are generated.

### INGRESS_REQ_CPU

- The initial cpu request size used for shared and dedicated load balancer ingress deployments.

### INGRESS_REQ_MEM

- The initial memory request size used for shared and dedicated load balancer ingress deployments.

### INGRESS_TARGET_CPU_PERCENT

- The target cpu percent used by the horizontal pod autoscalers for shared and dedicated load balancer ingress deployments. This should be calculated with awareness that the cpu value used is 4000 millicores but may be less if small nodes are used. For example, if the request size is set to 1000m and desire a target to be 3000m, then set this value to 300.

### INGRESS_FIREWALL_CIDR_LIST

- A comma delimited list of CIDRs used to restrict inbound access for shared and dedicated load balancers.

### INGRESS_LOAD_BALANCER_SCHEME

- One of `internet-facing` or `internal`. When internal is used then you must be on a private network to access the workloads running in this location. Automated detection of geo-routing is limited in this configuration since the external monitoring will not be able to reach the endpoints.

### INGRESS_ANNOTATIONS

- Annotations to be used instead of standard generated ones for the load balancer service for shared and dedicated load balancer ingress deployments. This can be useful if your cloud provider load balancer controller is not already supported by Control Plane and requires a specific annotation.

### INGRESS_EXTRA_ANNOTATIONS

- Extra annotations to be added to the load balancer service for shared and dedicated load balancers. This is useful if a specific annotation should be used in your environment for all load balancers. This is applied after the standard load balancer annotations and can be used to replace existing values. Passthrough annotations are applied after this can be used to make additional adjustments to specific dedicated load balancers.

### INGRESS_PORTS

- An array of ports used to limit the custom ports that are added to dedicated load balancers.

### BYOK_K8S_API_WORKLOADS

- An array of workload links which are allowed to access the kubernetes api.
- The ClusterRole the workloads are given should be specified with the tag cpln/k8sClusterRole on the workload.
<Note>
Ensure the ClusterRole already exists
</Note>


### Agent Settings
**Path**: `self-hosted/byok/settings/agent.mdx`

---
title: Agent Settings
---

The configmap `cpln-byok-default` in the `kube-system` namespace shows all available configuration options and their default values.

You can read the values in the configmap by running this kubectl command against the cluster:

`kubectl get configmap -n kube-system cpln-byok-default -o yaml`

## Usage

To modify the configuration, update the configmap `cpln-byok-current` in the `kube-system` namespace.

Its recommended to store settings in a git repo or CI system so that they can be applied automatically for each new cluster.


## Example cpln-byok-default configmap

```json
{
  "actuator": {
    "minCpu": "50m",
    "maxCpu": "1001m",
    "minMemory": "200Mi",
    "maxMemory": "500Mi",
    "logLevel": "info",
    "env": {
      "CACHE_PERIOD_DATA_SERVICE": "600",
      "LABEL_NODES": "false"
    }
  },
  "common": {
    "pdb": {
      "minAvailable": 0
    }
  },
  "internalDns": {
    "minCpu": "1m",
    "maxCpu": "1001m",
    "minMemory": "100Mi",
    "maxMemory": "512Mi"
  },
  "istio": {
    "istiod": {
      "replicas": 1,
      "maxCpu": "1001m",
      "minMemory": "100Mi",
      "maxMemory": "2500Mi",
      "pdb": 0
    }
  },
  "logSplitter": {
    "minCpu": "1m",
    "maxCpu": "200m",
    "minMemory": "10Mi",
    "maxMemory": "256Mi",
    "memBufferSize": "128M",
    "perPodRate": 10000
  },
  "monitoring": {
    "minMemory": "100Mi"
  },
  "redis": {
    "minCpu": "10m",
    "maxCpu": "2001m",
    "minMemory": "100Mi",
    "maxMemory": "1000Mi",
    "storage": "8Gi"
  }
}
```

## General Configurations

Common configuration settings that may be available for each component, check the `cpln-byok-default` configmap for availability.

| Property         | Type          | Description                                                    |
| :--------------- | :------------ | :------------------------------------------------------------- |
| minCpu           | string        | Minimum CPU allocation                                         |
| maxCpu           | string        | Maximum CPU allocation                                         |
| minMemory        | string        | Minimum memory allocation                                      |
| maxMemory        | string        | Maximum memory allocation                                      |
| logLevel         | string        | Logging level for the actuator                                 |
| env              | key: string[] | Optional environment variables for the component               |
| targetPercent    | number        | Target percentage for Horizontal CPU autoscaling               |
| pdb.minAvailable | number        | Minimum number of available pods for the pod disruption budget |
| replicas         | number        | Number of replicas                                             |

## Additional Options

### Actuator

Actuator is responsible for syncing the configuration between the Control Plane API and the cluster.
 It has several environment variables that will control its behavior.

[Actuator Settings](/byok/settings/actuator)

### Log Splitter

Configuration for component that forwards logs for workloads to Control Plane.

| Property      | Type                | Description                                           |
| :------------ | :------------------ | :---------------------------------------------------- |
| memBufferSize | string              | Memory buffer size                                    |
| perPodRate    | number              | Max log records per second before rate limit; per pod |

### Redis

Configuration for a Redis instance that is used by Control Plane.

| Property   | Type   | Description                                                                                  |
| :--------- | :----- | :------------------------------------------------------------------------------------------- |
| storage    | string | Storage allocation for Redis in kubernetes storage capacity format. examples: `1Gi`, `500Mi` |


### Volume Set settings
**Path**: `self-hosted/byok/settings/volumeset.mdx`

---
title: Volume Set settings
---

When using a volume set in a BYOK environment, there are some additional configuration settings available

## Storage Class Suffix

You can specify a `spec.storageClassSuffix` in a volume set. When this property is set, Control Plane will look for a storage class including this suffix. Storage classes are constructed by combining `spec.performanceClass`, `spec.fileSystemType`, and (optionally) the `spec.storageClassSuffix`. If a storage class including the suffix cannot be found, Control Plane falls back to the storage class excluding the suffix. This allows BYOK users to utilize any CSI-compatible storage solution they wish.


### Workload Settings
**Path**: `self-hosted/byok/settings/workload.mdx`

---
title: Workload Settings
---

When running workloads on a BYOK Location, there are some additional configuration settings that are available.

## Internal Firewall Settings

When a workload is running on the Control Plane cloud platform IP Addresses and CIDR blocks configured for the external firewall of a workload are ignored if they are in any private address ranges. When running in a BYOK location these internal address ranges are allowed and can be used to directly access internal resources in your data center.

## Custom Tags

An extra list of Control Plane tags can be used to change the behavior of workloads when they are run in BYOK Locations.

### Disable Service Mesh

`cpln/disableServiceMesh`=`true`

- When this tag is added to a workload the inbound and outbound sidecar is completely disabled. this can be useful in situations where proxying can confuse clients that are expecting direct IP communication without any NAT.

### Disable Service Mesh Inbound Port

`cpln/disableServiceMeshInboundPort`

- A comma delimited list of ports to exclude from being intercepted by the sidecar proxy inbound.

### Disable Service Mesh Outbound Port

`cpln/disableServiceMeshOutboundPort`

- A comma delimited list of ports to exclude from being intercepted by the sidecar proxy outbound.

### Disable Service Mesh Outbound CIDR

`cpln/disableServiceMeshOutboundPort`

- A comma delimited list of CIDR IP ranges to exclude from being intercepted by the sidecar proxy outbound.

### ClusterRole

`cpln/k8sClusterRole`

- The ClusterRole that should be binded to the workload
  <Note>The actuator must be configured to allow this. See [BYOK Actuator settings](/byok/settings/actuator#byok-k8s-api-workloads)</Note>


## self-hosted/mk8s/add-ons


### AWS ECR
**Path**: `self-hosted/mk8s/add-ons/aws_ecr.mdx`

---
title: AWS ECR
---

## Overview

The AWS ECR add-on facilitates access to [Amazon ECR](https://docs.aws.amazon.com/AmazonECR/latest/userguide/what-is-ecr.html) for managed Kubernetes clusters.

## Supported Providers

- [AWS](../aws)
- [Hetzner](../hetzner)
- [Generic](../generic)

## Prerequisites

- The [AWS Workload Identity](/mk8s/add-ons/aws_workload_identity) add-on must be enabled for your cluster.
- For **AWS providers** accessing private ECR within the **same account**, no additional Role ARN (Amazon Resource Name) is required.
- For **non-AWS providers** or when accessing an ECR in a **different account**, create an AWS IAM Role with the necessary permissions to pull images from a private AWS ECR. Attach the `AmazonEC2ContainerRegistryReadOnly` managed policy to grant these permissions. You will need the IAM Role's ARN for configuration.

## How to Enable

You can enable the AWS ECR add-on for your Kubernetes cluster either during the cluster creation process or at any time afterward. The following sections outline the methods for enabling the add-on:

### At Cluster Creation

#### AWS Providers Accessing Private ECR in the Same Account

- **Through Cluster Manifest**: Add the following snippet to your cluster manifest when creating the cluster:

  ```yaml YAML
  spec:
    ...
    addOns:
      awsECR: {}
    ...
  ```

- **Using the Console**: If you're creating the cluster through the console, navigate to `Add-ons`, find the `AWS ECR` add-on in the list of available add-ons, and toggle it on.

#### For NON-AWS Providers or Different AWS Account Access

- **Through Cluster Manifest**: Add the following snippet to your cluster manifest when creating the cluster:

  ```yaml YAML
  spec:
    ...
    addOns:
      awsECR:
        roleArn: 'arn:aws:iam::999999999999:role/mk8s-ecr-driver'
    ...
  ```

- **Using the Console**: If you're creating the cluster through the console, navigate to `Add-ons`, find the `AWS ECR` add-on in the list of available add-ons, toggle it on, and then enter the ROLE ARN required for accessing the AWS ECR repository.

### After Cluster Creation

If the AWS ECR add-on was not enabled during the cluster creation, you can still enable it using the following methods:

#### AWS Providers Accessing Private ECR in the Same Account

##### Using Manifest

To enable the AWS ECR add-on after cluster creation, add the following to your cluster's YAML manifest:

- **Direct Edit & Apply**: Navigate to your cluster in the Console, and use the `Edit & Apply` option.
- **CLI Application**: Apply the entire manifest using the `cpln apply >_` command or through the `cpln` [CLI](/reference/cli).

  ```yaml YAML
  spec:
    ...
    addOns:
      awsECR: {}
    ...
  ```

- **Using the Console**: If you're creating the cluster through the console, navigate to `Add-ons` of your cluster, find the `AWS ECR` add-on in the list of available add-ons, and toggle it on.

#### For NON-AWS Providers or Different AWS Account Access

- **Through Cluster Manifest**: Add the following snippet to your cluster manifest when creating the cluster:

  ```yaml YAML
  spec:
    ...
    addOns:
      awsECR:
        roleArn: 'arn:aws:iam::999999999999:role/mk8s-ecr-driver'
    ...
  ```

- **Using the Console**: If you're creating the cluster through the console, navigate to `Add-ons` of your cluster, find the `AWS ECR` add-on in the list of available add-ons, toggle it on, and then enter the ROLE ARN required for accessing the AWS ECR repository.

## Usage Instructions

### Accessing ECR in Same AWS Account

If you are using an AWS provider to access ECR within the same AWS account, follow these steps:

#### Step 1 - Create OIDC Identity Provider in AWS (If not already done)

Skip this step if you have already created the provider as part of the [AWS Workload Identity configuration](/mk8s/add-ons/aws_workload_identity#steps-to-configure-access).

1.  Retrieve the cluster's **oidcProviderUrl**:
    ```
    cpln mk8s get -o json $cluster_name | jq -r '.status.oidcProviderUrl'
    ```
2.  Access the AWS console and navigate to **IAM**. In the left panel, under `Access management`, select `Identity providers` and then click `Add provider`.
3.  Select `OpenID Connect`, paste the `Provider URL` obtained in the previous step, and click `Get thumbprint`.
4.  In the `Audience` field, enter `sts.amazonaws.com`.

#### Step 2 - Creating Kubernetes workload

Deploy a Kubernetes workload using an image from a private ECR Registry:

```yaml YAML
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: example-ecr
spec:
  replicas: 1
  selector:
    matchLabels:
      app: example
  template:
    metadata:
      labels:
        app: example
    spec:
      terminationGracePeriodSeconds: 0
      containers:
      - image: [account-id].dkr.ecr.[region].amazonaws.com/example
        name: example
        imagePullPolicy: Always
```

Replace `[account-id]` and `[region]` with appropriate values.

### Accessing ECR with NON-AWS Provider or Different AWS Account

If you are using a non-AWS provider or an AWS provider to access ECR in a different AWS account, follow these steps:

#### Step 1 - Create OIDC Identity Provider in AWS (If not already done)

Skip this step if you have already created the provider as part of the [AWS Workload Identity configuration](/mk8s/add-ons/aws_workload_identity#steps-to-configure-access).

1.  Retrieve the cluster's **oidcProviderUrl**:
    ```
    cpln mk8s get -o json $cluster_name | jq -r '.status.oidcProviderUrl'
    ```
2.  Access the AWS console and navigate to **IAM**. In the left panel, under `Access management`, select `Identity providers` and then click `Add provider`.
3.  Select `OpenID Connect`, paste the `Provider URL` obtained in the previous step, and click `Get thumbprint`.
4.  In the `Audience` field, enter `sts.amazonaws.com`.

#### Step 2 - Update Trust Policy

1.  Obtain the trust policy template:
    ```
    cpln mk8s get -o json $cluster_name | jq -r '.status.addOns.awsECR.trustPolicy'
    ```
2.  Update the `Trust Policy` of the IAM Role in the AWS Account to reflect these changes.

#### Step 3 - Creating Kubernetes workload

Deploy a Kubernetes workload using an image from private ECR Registry. Use proper values.

```yaml YAML
apiVersion: apps/v1
kind: Deployment
metadata:
  name: example-ecr
spec:
  replicas: 1
  selector:
    matchLabels:
      app: example
  template:
    metadata:
      labels:
        app: example
    spec:
      terminationGracePeriodSeconds: 0
      containers:
      - image: [account-id].dkr.ecr.[region].amazonaws.com/example
        name: example
        imagePullPolicy: Always
```

Replace `[account-id]` and `[region]` with appropriate values.


### AWS EFS
**Path**: `self-hosted/mk8s/add-ons/aws_efs.mdx`

---
title: AWS EFS
---

## Overview

The AWS EFS add-on facilitates access to [Amazon EFS](https://docs.aws.amazon.com/efs/latest/ug/whatisefs.html) for Kubernetes workloads running on a managed Kubernetes cluster.

## Supported Providers

- [AWS](../aws)
- [Hetzner](../hetzner)
- [Generic](../generic)

## Prerequisites

- [AWS Workload Identity](/mk8s/add-ons/aws_workload_identity)
- AWS Account

## How to Enable

To use the AWS EFS add-on for your Kubernetes cluster, ensure you have created an AWS IAM Role with the [necessary permissions](https://docs.aws.amazon.com/efs/latest/ug/security_iam_service-with-iam.html) to use the AWS EFS filesystem. The ARN (Amazon Resource Name) of this role is required for the configuration steps that follow. For the required permissions, you can attach the managed policy `AmazonEFSCSIDriverPolicy` to the IAM Role and verify that the EFS filesystem policy permits access.

The AWS EFS add-on can be enabled for your Kubernetes cluster either during the cluster creation process or at any time thereafter. The following sections outline the methods for enabling the add-on:

### At Cluster Creation

- **Through Cluster Manifest**: Add the following snippet to your cluster manifest when creating the cluster:

  ```yaml YAML
  spec:
    ...
    addOns:
      awsEFS:
        roleArn: 'arn:aws:iam::999999999999:role/mk8s-efs-driver'
    ...
  ```

- **Using the Console**: If you're creating the cluster through the console, navigate to `Add-ons`, find the `AWS EFS` add-on in the list of available add-ons, toggle it on, and then enter the ROLE ARN required for accessing the AWS EFS filesystem.

### After Cluster Creation

If the AWS EFS add-on was not enabled during the cluster creation, you can still enable it using either of the following methods:

#### Using Manifest

To enable the AWS EFS add-on after cluster creation, add the following to your cluster's YAML manifest:

- **Direct Edit & Apply**: Navigate to your cluster in the Console, and use the `Edit & Apply` option.
- **CLI Application**: Apply the entire manifest using the `cpln apply >_` command or through the `cpln` [CLI](/reference/cli).

  ```yaml YAML
  spec:
    ...
    addOns:
      awsEFS:
        roleArn: 'arn:aws:iam::999999999999:role/mk8s-efs-driver'
    ...
  ```

#### Using the UI

1. **Navigate to the Control Plane Console**: Open [Control Plane Console](https://console.cpln.io/console/).
2. **Select Your Kubernetes Cluster**: In the Control Plane Console, go to `Kubernetes` in the left sidebar, and click on the cluster you wish to configure.
3. **Activate the Dashboard**: Choose `Add-ons`, find the `AWS EFS` add-on in the list, and toggle it on.
4. **Enter Role ARN**: Provide the ROLE ARN necessary for AWS EFS filesystem access.

## Usage Instructions

After enabling the AWS EFS add-on, two additional steps are required before you can successfully create [Kubernetes volumes](https://kubernetes.io/docs/concepts/storage/volumes/) using AWS EFS.

First, it's essential to update the **trust policy** to grant the Managed Kubernetes cluster the necessary permissions to assume the AWS Role for accessing AWS EFS. This step ensures that your
Kubernetes cluster can securely interact with the AWS EFS service.

Second, you must properly configure the [Kubernetes Storage Class](https://kubernetes.io/docs/concepts/storage/storage-classes/). This configuration allows Kubernetes to understand how to provision storage based on AWS EFS for your applications.

Follow the steps below to configure:

### Step 1 - Create OIDC Identity Provider in aws (If not already done)

Skip this step if you have already created the provider as part of the [AWS Workload Identity configuration](/mk8s/add-ons/aws_workload_identity#steps-to-configure-access).

1. Retrieve the cluster's **oidcProviderUrl**:
   ```
   cpln mk8s get -o json $cluster_name | jq -r '.status.oidcProviderUrl'
   ```
2. Access the AWS console and navigate to **IAM**. In the left panel, under `Access management`, select `Identity providers` and then click `Add provider`.
3. Select `OpenID Connect`, paste the `Provider URL` obtained in the previous step, and click `Get thumbprint`.
4. In the `Audience` field, enter `sts.amazonaws.com`.

### Step 2 - Update Trust Policy

1.  Obtain the trust policy template:
    ```
    cpln mk8s get -o json $cluster_name | jq -r '.status.addOns.awsEFS.trustPolicy'
    ```
2.  Update the `Trust Policy` of the IAM Role in your AWS Account to reflect these changes.

### Step 3 - Create Storage Class

Create the following Storage Class in your Managed Kubernetes cluster. For guidance on accessing your cluster, refer to the documentation page of your Provider.

Ensure to replace the `fileSystemId` with the correct one from your account.

```yaml YAML
kind: StorageClass
apiVersion: storage.k8s.io/v1
metadata:
  name: efs-dynamic
provisioner: efs.csi.aws.com
parameters:
  provisioningMode: efs-ap
  fileSystemId: fs-999999999999 # Replace with your EFS FileSystemId
  directoryPerms: '700'
  gidRangeStart: '1000' # optional
  gidRangeEnd: '2000' # optional
  basePath: '/dynamic_provisioning' # optional
  subPathPattern: '${.PVC.namespace}/${.PVC.name}' # optional
  ensureUniqueDirectory: 'true' # optional
  reuseAccessPoint: 'false' # optional
```

### Step 4 - Example on creating volumes

Create the following `PersistentVolumeClaim` and `Pod` in your Managed Kubernetes cluster. This example demonstrates creating a Pod that writes the current date to a file every 5 seconds, utilizing a volume backed by the AWS EFS, as configured previously.

```yaml YAML
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: efs-claim
spec:
  accessModes:
    - ReadWriteMany
  storageClassName: efs-dynamic
  resources:
    requests:
      storage: 5Gi
---
apiVersion: v1
kind: Pod
metadata:
  name: efs-app
spec:
  terminationGracePeriodSeconds: 0
  containers:
    - name: app
      image: centos
      command: ['/bin/sh']
      args: ['-c', 'while true; do echo $(date -u) >> /data/out; sleep 5; done']
      volumeMounts:
        - name: persistent-storage
          mountPath: /data
  volumes:
    - name: persistent-storage
      persistentVolumeClaim:
        claimName: efs-claim
```


### AWS ELB
**Path**: `self-hosted/mk8s/add-ons/aws_elb.mdx`

---
title: AWS ELB
---

## Overview

The AWS ELB add-on configures the [AWS Load Balancer Controller](https://kubernetes-sigs.github.io/aws-load-balancer-controller/latest/) for use by the cluster.

This add-on is required for routing external traffic to the cluster with:

- AWS [Network Load Balancer (NLB)](https://docs.aws.amazon.com/elasticloadbalancing/latest/network/introduction.html)
- AWS [Application Load Balancer (ALB)](https://docs.aws.amazon.com/elasticloadbalancing/latest/application/introduction.html)
- UDP protocol access from public users
- AWS [Cloudfront](https://aws.amazon.com/blogs/containers/protecting-your-amazon-eks-web-apps-with-aws-waf/) K8S WAF Integration

## Supported Providers

- [AWS](../aws)

## Prerequisites

- [AWS Workload Identity](/mk8s/add-ons/aws_workload_identity)
- AWS Account

## Step 1: Enable the AWS ELB Add-On

The awsELB addon has one optional parameter of elbRole. If provided, the controller will this role to access the AWS API. 
If no role is provided then the [recommended role](https://kubernetes-sigs.github.io/aws-load-balancer-controller/latest/deploy/installation/#configure-iam) from AWS will be used.
The [AWS Workload Identity](/mk8s/add-ons/aws_workload_identity) Add-On is leveraged in the configuraiton of the load balancer controller to configure access for this role.

### Using Manifest

Enable AWS ELB w/ a custom role
  ```yaml YAML
  spec:
    ...
    addOns:
      awsELB:
        roleArn: 'arn:aws:iam::999999999999:role/custom-elb-addon-role'
    ...
  ```

Enable AWS ELB w/ the built-in role
  ```yaml YAML
  spec:
    ...
    addOns:
      awsELB: {}
    ...
  ```
This add-on can be enabled at cluster creation or afterwards.

### Using the UI

1. **Navigate to the Control Plane Console**: Open [Control Plane Console](https://console.cpln.io/console/).
2. **Select Your Kubernetes Cluster**: In the Control Plane Console, go to `Kubernetes` in the left sidebar, and click on the cluster you wish to configure.
3. **Enable the Add-on**: Choose `Add-ons`, find the `AWS ELB` add-on in the list, and toggle it on.
4. **Optional: Enter Role ARN**: Select the AWS ELB menu under Add-ons in the center pane. Provide the ROLE ARN necessary for AWS ELB Controller access to your AWS account.

## Step 2: Subnet Configuration

The [AWS Load Balancer Controller](https://kubernetes-sigs.github.io/aws-load-balancer-controller/latest/) needs to know
 which subnets it is allowed to use for internet facing and internal load balancer resources for this cluster.

The following tags must be added to AWS Subnets in order to designate how they can be used:

**Private subnet tag**:

Key: "kubernetes.io/role/internal-elb"
Value: "1"

**Public subnet tag**:

Key: "kubernetes.io/role/elb"
Value: "1"

## Step 3: Verify Controller Logs

After enabling the AWS ELB add-on, check to make sure that the controller is running and that it can access the AWS API using AWS Workload Identity.
 Connect to the MK8s Cluster using the Kubernetes Dashboard or the kubectl CLI.

### Dashboard UI

1. Select the `kube-system` namespace from the drop down menu on the top of the page.
1. Select `Pods` on the left menu.
1. In the center pane, find the aws-load-balancer-controller pod.
1. Click the three dot menu on the right side of the pod and choose `Logs`.

A live log view will open. Inspect the output for any error messages.

### kubectl

```bash
kubectl logs -n kube-system -l app.kubernetes.io/name=aws-load-balancer-controller -f
```

If the controller cannot access the AWS API, verify that you have performed [Step 1 for the AWS Identity Add-On](/mk8s/add-ons/aws_workload_identity#steps-to-configure-access).

Aditional troubleshooting steps are available in this AWS Knowledge Center [article](https://repost.aws/knowledge-center/load-balancer-troubleshoot-creating).

## Step 4 - Create Sample App

Create the following `Service` and `Deployment` in your Managed Kubernetes cluster.
 This example demonstrates creating a workload that is exposed externally.

```yaml YAML
apiVersion: v1
kind: Service
metadata:
  name: httpbin
  annotations:
    service.beta.kubernetes.io/aws-load-balancer-type: external
    service.beta.kubernetes.io/aws-load-balancer-nlb-target-type: ip
    service.beta.kubernetes.io/aws-load-balancer-scheme: internet-facing
spec:
  ports:
    - port: 80
      targetPort: 80
      protocol: TCP
  type: LoadBalancer
  selector:
    app: httpbin
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: httpbin
spec:
  replicas: 1
  selector:
    matchLabels:
      app: httpbin
  template:
    metadata:
      labels:
        app: httpbin
    spec:
      containers:
        - name: httpbin
          image: kennethreitz/httpbin
          ports:
            - name: tcp
              containerPort: 80
```

### Collect the endpoint

Once the objects are created, check the status of the Service.
 An Endpoint should be created for it automatically and listed under the External-IP column of the output.

```bash
kubectl get svc httpbin
```

### Test the endpoint

```bash
curl http://${endpoint}/headers
```

## Troubleshooting

Check the describe output of the service and the logs of the load balancer controller if the endpoint is not created or it is not working correctly.

```bash
kubectl describe svc httpbin
```

```bash
kubectl logs -n kube-system -l app.kubernetes.io/name=aws-load-balancer-controller -f
```

## Cleanup

```bash
kubectl delete svc,deployment httpbin
```


### AWS Workload Identity
**Path**: `self-hosted/mk8s/add-ons/aws_workload_identity.mdx`

---
title: AWS Workload Identity
---

## Overview

The AWS Workload Identity is a feature designed to enhance security and streamline access management for Control Plane managed Kubernetes clusters. This feature enables Pods running on Kubernetes clusters to assume an AWS IAM Role. By leveraging these IAM Roles, Pods can securely access AWS resources, adhering to the permissions defined in the corresponding IAM policies.

A key application of this feature is in scenarios where a Pod needs to interact with AWS services. For instance, a Pod requiring access to an S3 bucket can assume an IAM Role with the necessary permissions to perform actions on that bucket.

Enable AWS Workload Identity when secure access to AWS resources from Pods on the cluster is required.

## Supported Providers

- [AWS](../aws)
- [Hetzner](../hetzner)
- [Generic](../generic)

## Prerequisites

- AWS Account

## How to Enable

The `AWS Workload Identity` add-on can be enabled for your Kubernetes cluster either during the cluster creation process or at any time thereafter. The following sections outline the methods for enabling the add-on:

### At Cluster Creation

- **Through Cluster Manifest**: Add the following snippet to your cluster manifest when creating the cluster:

  ```yaml YAML
  spec:
    ...
    addOns:
      awsWorkloadIdentity: {}
  ...
  ```

- **Using the Console**: If you're creating the cluster through the console, navigate to `Add-ons`, find the `AWS Workload Identity` add-on in the list of available add-ons, and toggle it on.

### After Cluster Creation

If the `AWS Workload Identity` add-on was not enabled during the cluster creation, you can still enable it using either of the following methods:

#### Using Manifest

Under `spec.addOns` in the YAML manifest of the cluster, you can edit it either by navigating to the cluster in the Console and using the `Edit & Apply` option for the cluster, or by applying the entire manifest using the `cpln apply >_` option in the upper right corner or by using the `cpln` [CLI](/reference/cli).

Add the following:

```yaml YAML
spec:
---
addOns:
  awsWorkloadIdentity: {}
```

#### Using UI

1. **Navigate to Control Plane Console**: Visit the [Control Plane Console](https://console.cpln.io/console/).
1. **Navigate to the Kubernetes cluster**: In the Control Plane Console, navigate to `Kubernetes` in the left sidebar panel and click on the Kubernetes cluster for which you want to enable the dashboard.
1. **Enable the Dashboard**: Choose `Add-ons` and locate the `AWS Workload Identity` add-on from the list of available add-ons, then toggle it on.

## Setup

After enabling AWS Workload Identity, an [OIDC Identity Provider](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_providers_create_oidc.html) for each cluster must be created in your AWS account before it can be used.
The `oidcProviderUrl` for the OIDC Identity Provider is in the status of the cluster.

1. **Create OIDC Identity Provider in AWS**

   1. Retrieve the cluster's **oidcProviderUrl**:

      CLI

      ```
      cpln mk8s get -o json $cluster_name | jq -r '.status.oidcProviderUrl'
      ```

      UI

      1. From the Managed Kubernetes cluster in the UI, select `View` from the `Actions` drop down in the upper right corner.
         
         A new window will open sowing the content of the Managed Kubernetes object in the Control Plane API.
      
      1. Toggle the `Slim` button so it is turned off.
      1. The `providerUrl` is shown in the object at `.status.addOns.awsWorkloadIdentity.oidcProviderConfig`


   1. Access the AWS console and navigate to **IAM**. In the left panel, under `Access management`, select `Identity providers` and then click `Add provider`.
   1. Select `OpenID Connect`, paste the `Provider URL` obtained in the previous step, and click `Get thumbprint`.
   1. In the `Audience` field, enter `sts.amazonaws.com`.

## Usage Instructions

After enabling AWS Workload Identity, your Managed Kubernetes cluster becomes an identity provider for your Pods.

To grant a Pod access, ensure it uses a [Kubernetes Service Account](https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/) with the annotation: `eks.amazonaws.com/role-arn: "arn:aws:iam::<ACCOUNT_ID>:role/IAM-ROLE-HERE"`. This setup is compatible with all [Kubernetes Workloads](https://kubernetes.io/docs/concepts/workloads/), as they ultimately provision Pods.

Follow these steps below to configure.

### Steps to configure access

1. **Retrieve and Save the Trust Policy JSON**

   1. Obtain the trust policy template:
      ```
      cpln mk8s get -o json $cluster_name | jq -r '.status.addOns.awsWorkloadIdentity.trustPolicy'
      ```
   1. Save the obtained policy to a file named `example-trust-policy.json`. Then, modify the trust policy by replacing
      `<SERVICE_ACCOUNT>` and `<NAMESPACE>` with the appropriate values:
      - For `<NAMESPACE>`, use `default`.
      - For `<SERVICE_ACCOUNT>`, use `mk8s-identity-example`.

1. **Create an IAM Role**
   - You can create a new IAM Role using the AWS Console, or use an existing one. For creating a role via CLI, follow this example:
     - Replace `<ACCOUNT_ID>` with your AWS Account ID.
     - Used the obtained trust policy from the previous step as `default-trust-policy.json`
     - Run the following command:
       ```
       aws iam create-role --role-name "arn:aws:iam::<ACCOUNT_ID>:role/mk8s-identity-example" --assume-role-policy-document file://default-trust-policy.json
       ```
1. **Create Kubernetes Service Account and a Pod**  
   Create the Kubernetes Service Account and a Pod in your Managed Kubernetes cluster. For guidance on accessing your cluster, refer to the documentation page of your Provider.

   - Replace `<ACCOUNT_ID>` with your AWS Account ID in the following YAML configuration:

     ```yaml YAML
     apiVersion: v1
     kind: ServiceAccount
     metadata:
       name: mk8s-identity-example
       namespace: default
       annotations:
         eks.amazonaws.com/role-arn: 'arn:aws:iam::<ACCOUNT_ID>:role/mk8s-identity-example'
     ---
     apiVersion: v1
     kind: Pod
     metadata:
       name: identity-example
       namespace: default
     spec:
       terminationGracePeriodSeconds: 0
       serviceAccountName: mk8s-identity-example
       containers:
         - command:
             - sleep
             - '99d'
           image: amazon/aws-cli:2.13.35
           name: shell
     ```

   - The Pod `identity-example` can now access AWS resources using the IAM role `arn:aws:iam::<ACCOUNT_ID>:role/mk8s-identity-example`.


### Kubernetes Dashboard
**Path**: `self-hosted/mk8s/add-ons/dashboard.mdx`

---
title: Kubernetes Dashboard
---

## Overview

The Kubernetes Dashboard add-on provides a user-friendly interface, enabling users to manage and monitor their Kubernetes clusters directly from a web interface. This add-on simplifies cluster management tasks and offers a comprehensive view of the cluster's state.

For more details, please refer to the official Kubernetes documentation [here](https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard/).

## How to Enable

The Dashboard add-on can be enabled for your Kubernetes cluster either during the cluster creation process or at any time thereafter. The following sections outline the methods for enabling the add-on:

### At Cluster Creation

- **Through Cluster Manifest**: Add the following snippet to your cluster manifest when creating the cluster:

  ```yaml YAML
  spec:
    ...
    addOns:
      dashboard: {}
    ...
  ```

- **Using the Console**: If you're creating the cluster through the console, navigate to `Add-ons`, find the `Dashboard` add-on in the list of available add-ons, and toggle it on.

### After Cluster Creation

If the Dashboard add-on was not enabled during the cluster creation, you can still enable it using either of the following methods:

#### Using Manifest

Under `spec.addOns` in the YAML manifest of the cluster, you can edit it either by navigating to the cluster in the Console and using the `Edit & Apply` option for the cluster, or by applying the entire manifest using the `cpln apply >_` option in the upper right corner or by using the `cpln` [CLI](/(/reference/cli).

Add the following:

```yaml YAML
spec:
---
addOns:
  dashboard: {}
```

#### Using UI

1. **Navigate to Control Plane Console**: Visit the [Control Plane Console](https://console.cpln.io/console/).
2. **Navigate to the Kubernetes cluster**: In the Control Plane Console, navigate to `Kubernetes` in the left sidebar panel and click on the Kubernetes cluster for which you want to enable the dashboard.
3. **Enable the Dashboard**: Choose `Add-ons` and locate the `Dashboard` add-on from the list of available add-ons, then toggle it on.

## How to Access

Once enabled, the Dashboard add-on can be used as follows:

1. **Navigate to Control Plane Console**: Visit the [Control Plane Console](https://console.cpln.io/console/).
2. **Access the Dashboard**: In the Control Plane Console, navigate to `Kubernetes` in the left sidebar panel and click on `Open` under `Dashboard` for the cluster.


### Local Path Storage
**Path**: `self-hosted/mk8s/add-ons/local_path_storage.mdx`

---
title: Local Path Storage
---

## Overview

The Local Path Storage add-on enables the [Rancher Local Path Provisioner](https://github.com/rancher/local-path-provisioner). This feature allows users to automatically create persistent volumes based on either `hostPath` or `local` storage on the node.

Before using this feature, be aware that Local Volumes have their own limitations. It's important to familiarize yourself with `hostPath` and `local` volumes, including their purposes and limitations. For more information, refer to the [Kubernetes Documentation](https://kubernetes.io/docs/concepts/storage/volumes/).

## Supported Providers

- [AWS](../aws)
- [Hetzner](../hetzner)
- [Generic](../generic)

## How to Enable

The Local Path Storage add-on can be enabled for your Kubernetes cluster either during the cluster creation process or at any time thereafter. The following sections outline the methods for enabling the add-on:

### At Cluster Creation

- **Through Cluster Manifest**: Add the following snippet to your cluster manifest when creating the cluster:

  ```yaml YAML
  spec:
    ...
    addOns:
      localPathStorage: {}
    ...
  ```

- **Using the Console**: If you're creating the cluster through the console, navigate to `Add-ons`, find the `Local Path Storage` add-on in the list of available add-ons, and toggle it on.

### After Cluster Creation

If the Local Path Storage add-on was not enabled during the cluster creation, you can still enable it using either of the following methods:

#### Using Manifest

To enable the Local Path Storage add-on after cluster creation, add the following to your cluster's YAML manifest:

- **Direct Edit & Apply**: Navigate to your cluster in the Console, and use the `Edit & Apply` option.
- **CLI Application**: Apply the entire manifest using the `cpln apply >_` command or through the `cpln` [CLI](/reference/cli).

  ```yaml YAML
  spec:
    ...
    addOns:
      localPathStorage: {}
    ...
  ```

#### Using the UI

1. **Navigate to the Control Plane Console**: Open [Control Plane Console](https://console.cpln.io/console/).
2. **Select Your Kubernetes Cluster**: In the Control Plane Console, go to `Kubernetes` in the left sidebar, and click on the cluster you wish to configure.
3. **Activate the Dashboard**: Choose `Add-ons`, find the `Local Path Storage` add-on in the list, and toggle it on.

## Usage Instructions

It is now possible to create Pods backed by `hostPath` and `local` volumes.

### Create a StatefulSet that uses a local volume for the storage of its pods

Create the following StatefulSet in your Managed Kubernetes cluster. For guidance on accessing your cluster, refer to the documentation page of your provider.

```yaml YAML
---
apiVersion: v1
kind: Service
metadata:
  name: nginx-localpath
  labels:
    app: nginx-localpath
spec:
  ports:
    - port: 80
      name: web
  type: LoadBalancer
  selector:
    app: nginx-localpath
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: nginx-localpath
  labels:
    app: nginx-localpath
spec:
  serviceName: 'nginx-localpath'
  selector:
    matchLabels:
      app: nginx-localpath
  replicas: 1
  template:
    metadata:
      labels:
        app: nginx-localpath
    spec:
      containers:
        - name: nginx-localpath
          image: registry.k8s.io/nginx-slim:0.8
          ports:
            - containerPort: 80
              name: web
          volumeMounts:
            - name: www-localpath
              mountPath: /usr/share/nginx/html
  volumeClaimTemplates:
    - metadata:
        name: www-localpath
      spec:
        accessModes: ['ReadWriteOnce']
        storageClassName: local-path
        resources:
          requests:
            storage: 1Gi
```


### logs
**Path**: `self-hosted/mk8s/add-ons/logs.mdx`

## Overview

The Logs add-on, once enabled, will send logs from pods running on the cluster, and optionally, [Kubernetes audit records](https://kubernetes.io/docs/tasks/debug/debug-cluster/audit/), to Control Plane. This will allow you to query the logs and audit records from your clusters managed by the Control Plane centrally in the web UI or in Grafana.

## Supported Providers

- [AWS](../aws)
- [Hetzner](../hetzner)
- [Generic](../generic)

## How to Enable

The Logs add-on can be enabled for your Kubernetes cluster either during the cluster creation process or at any time thereafter. The following sections outline the methods for enabling the add-on:

### At Cluster Creation

- **Through Cluster Manifest**: Add the following snippet to your cluster manifest when creating the cluster:

  ```yaml YAML
  spec:
    ...
    addOns:
      logs: {}
    ...
  ```

- **Using the Console**: If you're creating the cluster through the console, navigate to `Add-ons`, find the `Logs` add-on in the list of available add-ons, and toggle it on.

### After Cluster Creation

If the Logs add-on was not enabled during the cluster creation, you can still enable it using either of the following methods:

#### Using Manifest

Under `spec.addOns` in the YAML manifest of the cluster, you can edit it either by navigating to the cluster in the Console and using the `Edit & Apply` option for the cluster, or by applying the entire manifest using the `cpln apply >_` option in the upper right corner or by using the `cpln` [CLI](/reference/cli).

Add the following:

```yaml YAML
spec:
---
addOns:
  logs: {}
```

#### Using UI

1. **Navigate to Control Plane Console**: Visit the [Control Plane Console](https://console.cpln.io/console/).
2. **Navigate to the Kubernetes cluster**: In the Control Plane Console, navigate to `Kubernetes` in the left sidebar panel and click on the Kubernetes cluster for which you want to enable logging.
3. **Enable Logs**: Choose `Add-ons` and locate the `Logs` add-on from the list of available add-ons, then toggle it on.

## Configuring Logs add-on

The configuration is optional. You can configure the following:

- List of namespaces to include for logging collection
- List of namespaces to exclude for logging collection
- Enable/Disable audit

You can make the configuration in the UI for your cluster, as displayed in the picture below, or by modifying the clusters object spec.

<Frame>
  <img src="/public/images/mk8s/add-ons/logs-configurations.png" />
</Frame>

Alternatively, directly edit the clusters object spec:

```yaml YAML
spec:
---
addOns:
  logs:
    auditEnabled: true
    excludeNamespaces: kube-system, istio-system
    includeNamespaces: default, fronted, app1
```

## Analyzing Logs

Once enabled, you can analyze the logs and audit events.

1. **Navigate to Control Plane Console**: Visit the [Control Plane Console](https://console.cpln.io/console/).
2. **Analyze logs**: In the Control Plane Console, navigate to `Logs` in the left sidebar panel.  
   Use [LogQL](https://grafana.com/docs/loki/latest/query/) for query. Example query: `{cluster_name="aws-us-east-2", namespace="default"}`

<Frame>
  <img src="/public/images/mk8s/add-ons/ui-logs.png" />
</Frame>

Click on `Explore On Grafana` and analyze logs in Grafana:

<Frame>
  <img src="/public/images/mk8s/add-ons/grafana-logs.png" />
</Frame>


## self-hosted/mk8s


### AWS Provider
**Path**: `self-hosted/mk8s/aws.mdx`

---
title: AWS Provider
---

The AWS Provider for Managed Kubernetes is designed to facilitate the setup of Kubernetes clusters on AWS Cloud. It automates key cloud component management, enabling easy and rapid creation and maintenance of scalable, production-grade Kubernetes clusters. This provider simplifies various cloud infrastructure tasks, including node autoscaling, load balancer provisioning, version upgrades, and storage management. It enables centralized management of a fleet of Kubernetes clusters across single or multiple AWS accounts.

## Requirements

- [AWS Account](https://aws.amazon.com/console/)

## Supported add-ons

- [Dashboard:](/mk8s/add-ons/dashboard) Provides a Kubernetes dashboard UI for the cluster.
- [AWS Workload Identity:](/mk8s/add-ons/aws_workload_identity) Allows your pods to assume AWS IAM Roles.
- [AWS ECR:](/mk8s/add-ons/aws_ecr) Allows pulling images from private ECR registries.
- [AWS EFS:](/mk8s/add-ons/aws_efs) Provides support for persistent volumes using AWS Elastic File System.
- [Local Path Storage:](/mk8s/add-ons/local_path_storage) Create PVCs backed by local volumes.
- [Logs:](/mk8s/add-ons/logs) Enable logging for pods and cluster auditing.

## Step 1 - Preparing the AWS environment

**Ensure your AWS environment includes:**

- **A VPC with**:
  - At least one public subnet, or
  - At least one private subnet with a NAT gateway for egress traffic
  - [Guide on creating a VPC with AWS Console (External)](https://www.youtube.com/watch?v=ApGz8tpNLgo)

<Note>

Tailored instructions for IAM Role creation are available in the [Control Plane Console](https://console.cpln.io/console/) when creating an AWS Kubernetes cluster using the UI. Alternatively, you can follow the instructions below:

</Note>

- **IAM Role:**
  1. Create an _IAM Role_ with the naming pattern `cpln-mk8s-${ORG}`. For example, `cpln-mk8s-testing` if the organization name is `testing`.
  2. Create an _IAM Policy_ with the naming pattern `cpln-mk8s-${ORG}`. For example, `cpln-mk8s-testing` if the organization name is `testing`.

```json Control Plane Connector Policy
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "CreateIamResourcesForCplnPrefix",
      "Effect": "Allow",
      "Action": [
        "iam:Get*",
        "iam:CreateRole",
        "iam:DeleteRole",
        "iam:PassRole",
        "iam:CreateInstanceProfile",
        "iam:DeleteInstanceProfile",
        "iam:AddRoleToInstanceProfile",
        "iam:RemoveRoleFromInstanceProfile",
        "iam:CreatePolicy",
        "iam:DeletePolicy",
        "iam:CreatePolicyVersion",
        "iam:DeletePolicyVersion",
        "iam:AttachRolePolicy",
        "iam:DetachRolePolicy",
        "iam:UpdateRoleDescription",
        "iam:UpdateAssumeRolePolicy",
        "sts:AssumeRole"
      ],
      "Resource": [
        "arn:aws:iam::*:instance-profile/cpln-*",
        "arn:aws:iam::*:policy/cpln-*",
        "arn:aws:iam::*:role/cpln-*"
      ]
    },
    {
      "Sid": "ValidateConfiguration",
      "Effect": "Allow",
      "Action": [
        "kms:ListKeys",
        "kms:DescribeKey",
        "iam:ListPolicies",
        "iam:ListPolicyVersions",
        "iam:ListRolePolicies",
        "ec2:DescribeKeyPairs",
        "ec2:DescribeSubnets",
        "ec2:DescribeVpcs",
        "ec2:DescribeSecurityGroups",
        "iam:ListAttachedRolePolicies",
        "iam:ListInstanceProfilesForRole",
        "iam:SimulatePrincipalPolicy"
      ],
      "Resource": "*"
    },
    {
      "Sid": "PrepareCluster",
      "Effect": "Allow",
      "Action": [
        "autoscaling:CreateAutoScalingGroup",
        "ec2:CreateLaunchTemplate",
        "ec2:ModifyLaunchTemplate",
        "ec2:CreateSecurityGroup",
        "ec2:CreateLaunchTemplate",
        "ec2:CreateTags",
        "autoscaling:CreateOrUpdateTags",
        "ec2:RunInstances",
        "ec2:DescribeLaunchTemplates",
        "ec2:DescribeLaunchTemplateVersions",
        "ec2:DescribeImages",
        "autoscaling:UpdateAutoScalingGroup",
        "autoscaling:StartInstanceRefresh",
        "ec2:CreateLaunchTemplateVersion",
        "ec2:AuthorizeSecurityGroupIngress",
        "ec2:AuthorizeSecurityGroupEgress",
        "ec2:DescribeSecurityGroups"
      ],
      "Resource": "*"
    },
    {
      "Sid": "Cleanup",
      "Effect": "Allow",
      "Action": [
        "autoscaling:DeleteAutoScalingGroup",
        "autoscaling:DescribeAutoScalingGroups",
        "autoscaling:DeleteLaunchConfiguration",
        "ec2:DeleteLaunchTemplate",
        "ec2:DeleteSecurityGroup",
        "ec2:DeleteVolume",
        "ec2:DescribeLaunchTemplates",
        "ec2:DescribeSecurityGroups",
        "ec2:DescribeVolumes",
        "elasticloadbalancing:DeleteLoadBalancer",
        "elasticloadbalancing:DescribeLoadBalancers",
        "elasticloadbalancing:DescribeTags"
      ],
      "Resource": "*"
    },
    {
      "Sid": "AmiLookupInSSM",
      "Effect": "Allow",
      "Action": [
        "ssm:GetParameters",
        "ssm:DescribeParameters",
        "ssm:GetParameter"
      ],
      "Resource": [
        "arn:aws:ssm:*::parameter/aws/service/ami-amazon-linux-latest/*",
        "arn:aws:ssm:*::parameter/aws/service/canonical/*",
        "arn:aws:ssm:*::parameter/aws/service/eks/*"
      ]
    }
  ]
}
```

3. Attach the connector policy to the `cpln-mk8s-${ORG}` _IAM Role_.

4. Edit the trust policy of the `cpln-mk8s-${ORG}` _IAM Role_.

   **Important:** Replace `${ACCOUNT_ID}` with your own account id.

```json Trust Policy
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Principal": {
        "Federated": "arn:aws:iam::${ACCOUNT_ID}:oidc-provider/oidc.mk8s.cpln.io/federate"
      },
      "Action": "sts:AssumeRoleWithWebIdentity",
      "Condition": {
        "StringEquals": {
          "oidc.mk8s.cpln.io/federate:aud": "sts.amazonaws.com",
          "oidc.mk8s.cpln.io/federate:sub": "observer-org"
        }
      }
    }
  ]
}
```

5. Save the updates and copy the ARN of the _IAM Role_ for use in the next step.

## Step 2 - Create a Managed Kubernetes Cluster Using a Manifest File

1. **Update the manifest below**: Modify the following `aws-mk8s-template.yaml` YAML manifest below with actual values.
 Customize the file as needed.
 Replace placeholders for `${ROLE_ARN}`, `${SSH_KEY_NAME}`, `${SUBNET_1}` and `${SUBNET_2}` and `${VPC_ID}`.
 Use the Role ARN of the IAM Role created in the previous step in place of `${ROLE_ARN}`.

```yaml YAML
kind: mk8s
name: aws-mk8s-example
description: aws-mk8s-example cluster
tags: {}
spec:
  provider:
    aws:
      deployRoleArn: ${ROLE_ARN}
      image:
        recommended: ubuntu/jammy-22.04
      # keyPair: ${SSH_KEY_NAME} # Optional
      nodePools:
        - name: general
          bootDiskSize: 25
          extraSecurityGroupIds: []
          instanceTypes:
            - m7g.large
            - m6gd.large
            - c7g.xlarge
          labels: {}
          maxSize: 4
          minSize: 1
          onDemandBaseCapacity: 0
          onDemandPercentageAboveBaseCapacity: 0
          # overrideImage:
          #   recommended: amazon/amzn2
          spotAllocationStrategy: lowest-price
          subnetIds:
            - ${SUBNET_1}
            - ${SUBNET_2}
          taints: []
      region: eu-central-1
      securityGroupIds: []
      skipCreateRoles: false
      vpcId: ${VPC_ID}
  addOns:
    awsECR: {}
    dashboard: {}
    localPathStorage: {}
    awsWorkloadIdentity: {}
  firewall:
    - description: default
      sourceCIDR: 0.0.0.0/0
  version: 1.30.3
```

This example creates a managed Kubernetes cluster in AWS with the following configurations:

- **[Add-ons](#supported-add-ons)**: Includes Dashboard, Local Path Storage, AWS Workload Identity and awsECR.
- **Location**: The cluster's Kubernetes control plane is managed in the `eu-central-1` region. Placing worker nodes close to the control plane is recommended for optimal performance. Full list of supported regions: `[af-south-1, ap-east-1, ap-northeast-1, ap-northeast-2, ap-northeast-3, ap-south-1, ap-south-2, ap-southeast-1, ap-southeast-2, ap-southeast-3, ap-southeast-4, ca-central-1, eu-central-1, eu-central-2, eu-north-1, eu-south-1, eu-south-2, eu-west-1, eu-west-2, eu-west-3, me-central-1, me-south-1, sa-east-1, us-east-1, us-east-2, us-west-1, us-west-2]`.
- **Kubernetes API Firewall**: Utilizes the `Default` rule, allowing public access to the Kubernetes API. It is advisable to restrict API access to a known IP range for security purposes.
- **Kubernetes Version**: 1.30.3.
- **Node Pool**: A single `general` node pool, scaling on-demand between 1 and 4 nodes.
- **Server Image**: ubuntu/jammy-22.04.

2. **Create the Cluster**: Deploy the `aws-mk8s-example` cluster by applying the manifest.

   - **Console**: Apply the `aws-mk8s-template.yaml` file using the `cpln apply >_` option in the upper right corner.
   - **CLI**: Execute `cpln apply -f aws-mk8s-template.yaml --org YOUR_ORG_HERE`.

   **Wait until the cluster is initialized.**

## Step 3 - Accessing the Cluster

### 1. Using the Terminal

1. **Obtain the Cluster's Kubeconfig File**: Execute the command `cpln mk8s kubeconfig aws-mk8s-example -f /tmp/aws-mk8s-example-conf`.
2. **Access the Cluster with `kubectl`**: Use the obtained kubeconfig file by running `export KUBECONFIG=/tmp/aws-mk8s-example-conf` for the current shell session.

### 2. Using Kubernetes Dashboard

1. **Navigate to Control Plane Console**: Visit the [Control Plane Console](https://console.cpln.io/console/).
2. **Access the Dashboard**: In the Control Plane Console, navigate to `Kubernetes` in the left sidebar panel and click on `Open` under `Dashboard` for the cluster `aws-mk8s-example`.

## Advanced Configuration Options

### Deploy Role Chain

AWS accounts with high security requirements may not allow a direct trust policy to allow direct access from Control Plane for setup and management.
 In this suituation, you can configure the initial login from Control Plane into a different intermediary account and add a chain of roles that will be assumed to reach the target account.

### `.spec.provider.aws.deployRoleChain`

Each record in the `deployRoleChain` array is assumed **after** the initial login into the `deployRole`.
 The chain of roles is processed in the order listed in the array, from top to bottom.
 Each step in the chain must have a trust policy in place to allow `sts:assumeRole` from the previous step.

| Property            | Type              | Description                                                                                                                                     |
| ------------------- | ----------------- | -------------------------------------------------------------------------------------------------- |
| `roleArn`           | string            | The role that will be assumed using `sts:assumeRole`.                                              |
| `externalId`        | string (optional) | The externalId to use during the assume role.                                                      |
| `sessionNamePrefix` | string (optional) | A prefix to use for the session name. The rest of the session will be generated to make it unique. |

```json example trust policy

{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Principal": {
        "AWS": "arn:aws:iam::333377778888:role/ExampleTrustedRole"
      },
      "Action": "sts:AssumeRole",
      "Condition": {
        "StringEquals": {
          "sts:ExternalId": "ExampleExternalId"
        }
      }
    }
  ]
}

```


### Generic Provider
**Path**: `self-hosted/mk8s/generic.mdx`

---
title: Generic Provider
---

The Generic provider for Managed Kubernetes allows Linux-based servers to be converted into worker nodes of a Kubernetes cluster, irrespective of their deployment in public clouds (such as AWS, Azure, GCP, Hetzner, etc.) or in private cloud / on-premises environments. Once integrated, these servers join a Kubernetes cluster as worker nodes, enabling the deployment of Kubernetes workloads through the Kubernetes API.

## Supported Add-Ons

- [Dashboard:](/mk8s/add-ons/dashboard) Provides a Kubernetes dashboard UI for the cluster.
- [AWS Workload Identity:](/mk8s/add-ons/aws_workload_identity) Allows your pods to assume AWS IAM Roles.
- [AWS ECR:](/mk8s/add-ons/aws_ecr) Allows pulling images from private ECR registries.
- [Local Path Storage:](/mk8s/add-ons/local_path_storage) Create PVCs backed by local volumes.
- [Logs:](/mk8s/add-ons/logs) Enable logging for pods and cluster auditing.

## Step 1 - Servers Setup

1. **Ensure Availability of Server(s)**: Create at least one server that matches the `server requirements`:
   - Server(s) requirements:
     - Linux Kernel version 5.x.x or higher
     - Minimum CPU: 1 Core
     - Minimum RAM: 512 MB
   - Servers require Internet egress access
   - Ensure you have SSH access to the servers

## Step 2 - Creating Managed Kubernetes Cluster with Manifest

1. **Update the manifest below**: (Optional) Modify the following `generic-mk8s-template.yaml` YAML manifest if needed.

```yaml YAML
kind: mk8s
name: generic-mk8s-example
description: generic-mk8s-example mk8s in gcp-us-east1
tags: {}
spec:
  provider:
    generic:
      location: gcp-us-east1
      nodePools:
        - name: general
          labels:
            environment: generic-mk8s-example
          taints: []
  addOns:
    dashboard: {}
    localPathStorage: {}
    awsWorkloadIdentity: {}
  firewall:
    - description: default
      sourceCIDR: 0.0.0.0/0
  version: 1.28.2
```

This example creates a Generic cluster with the following configurations:

- **[Add-ons](#supported-add-ons)**: Includes Dashboard, Local Path Storage, and AWS Workload Identity.
- **Location**: The cluster's Kubernetes control plane will be managed in the `gcp-us-east1` location. Placing worker nodes close to the control plane is recommended for optimal performance.
- **Kubernetes API Firewall**: Utilizes the `Default` rule, allowing public access to the Kubernetes API. It is advisable to restrict API access to a known IP range for security purposes.
- **Kubernetes Version**: 1.28.2.
- **Node Pool**: A single `general` node pool.

2. **Create the Cluster**: Deploy the `generic-mk8s-example` cluster by applying the manifest.

   - **CLI**: Execute `cpln apply -f generic-mk8s-template.yaml --org YOUR_ORG_HERE`.
   - **Console**: Apply the `generic-mk8s-template.yaml` file using the `cpln apply >_` option in the upper right corner.

   **Wait until the cluster is initialized.**

## Step 3 - Connecting the Server(s) to the Cluster

1. **Obtain the Join Script**:

   - **Using the CLI**:
     a. **Save the Join Script to a file**: Execute the command `cpln mk8s join generic-mk8s-example --type join-script --options nodePoolName=general > join_general.sh`

   - **Using the UI**:
     a. **Navigate to the Control Plane Console**: Visit the [Control Plane Console](https://console.cpln.io/console/).
     b. **Access the Dashboard**: In the Control Plane Console, navigate to `Kubernetes` in the left sidebar panel, click on the `generic-mk8s-example` cluster, and go to `Node Pools`. Click on `More` on the right side of the `general` Node Pool and select `Generate Join Script`.

2. **Copy and Execute the Script on the Server**: Connect to the remote server and execute the Join Script. After the execution, the server should be joined to the cluster as a node under the `general` node pool. Repeat these steps for all necessary servers.

## Step 4 - Accessing the Cluster

### 1. Using the Terminal

1. **Obtain the Cluster's Kubeconfig File**: Execute the command `cpln mk8s kubeconfig generic-mk8s-example -f /tmp/generic-mk8s-example-conf`.
2. **Access the Cluster with `kubectl`**: Use the obtained kubeconfig file by running `export KUBECONFIG=/tmp/generic-mk8s-example-conf` for the current shell session.

### 2. Using Kubernetes Dashboard

1. **Navigate to Control Plane Console**: Visit the [Control Plane Console](https://console.cpln.io/console/).
2. **Access the Dashboard**: In the Control Plane Console, navigate to `Kubernetes` in the left sidebar panel and click on `Open` under `Dashboard` for the cluster `generic-mk8s-example`.


### Hetzner Provider
**Path**: `self-hosted/mk8s/hetzner.mdx`

---
title: Hetzner Provider
---

The Hetzner Provider for Managed Kubernetes utilizes Hetzner Cloud to set up Kubernetes clusters. This provider automates the management of essential cloud components on Hetzner, enabling the creation of scalable and production-ready Kubernetes clusters. With its competitive pricing, Hetzner is an advantageous choice for users seeking to optimize cloud expenses compared to larger hyperscalers such as AWS, Azure, and GCP.

## Requirements

- [Hetzner Cloud](https://www.hetzner.com/) account and [hcloud CLI](https://github.com/hetznercloud/cli)

## Supported add-ons

- [Dashboard:](/mk8s/add-ons/dashboard) Provides a Kubernetes dashboard UI for the cluster.
- [AWS Workload Identity:](/mk8s/add-ons/aws_workload_identity) Allows your pods to assume AWS IAM Roles.
- [AWS ECR:](/mk8s/add-ons/aws_ecr) Allows pulling images from private ECR registries.
- [Local Path Storage:](/mk8s/add-ons/local_path_storage) Create PVCs backed by local volumes.
- [Logs:](/mk8s/add-ons/logs) Enable logging for pods and cluster auditing.

## Step 1 - Preparing the Hetzner Cloud Environment

1. **Log in to Hetzner Cloud Account**: Access your [Hetzner Cloud account](https://accounts.hetzner.com/login).
2. **Create a New Project**: Establish a new project named `hetzner-mk8s-example`.
3. **Create an API Token**:
   - Navigate to your newly created project.
   - Click on `Security` in the left sidebar, then proceed to `API tokens`.
   - Click on `Generate API Token`.
   - Grant `Read & Write` permissions to the token and copy it.
4. **Store the Token in Control Plane Secrets Manager**:
   - Log in to the [Control Plane Console](https://console.cpln.io/console/).
   - Click on `Secrets` in the left sidebar and then select `New`.
   - Choose `Opaque` as the secret type and name it `hetzner-mk8s-example`.
   - Store the API token's value in this secret.
5. **Create Network and Security Features in Project `hetzner-mk8s-example` on Hetzner**:

   - **Network (Required)**:

     - Click on `Networks` in the left sidebar.
     - Create a new network by selecting `Create Network`.

       <Note>

       The network zone should match the location you will use for your servers. For the Locations table, [click here](https://docs.hetzner.com/cloud/general/locations/).

       </Note>

   - **Firewall (Recommended)**:
     - Click on `Firewalls` in the left sidebar.
     - Create a new firewall by selecting `Create Firewall`.
   - **SSH Key (Recommended)**:
     - Click on `Security` in the left sidebar.
     - Go to `SSH Keys` and click on `Add SSH Key`.

<Note>

The steps above can be automated using the API or CLI tools of [Hetzner](https://docs.hetzner.com/cloud/) and [Control Plane](/reference/cli).

</Note>

## Step 2 - Create a Managed Kubernetes Cluster Using a Manifest File

1. **Connect with hcloud CLI**: Use the command `hcloud context create hetzner-mk8s-example` and insert the `API key` from the previous step.
2. **Capture the IDs**: Obtain the ID of the `network`, and optionally the `firewall` and the `ssh-key` created in the previous step using the [hcloud CLI](https://github.com/hetznercloud/cli).
   - Network: Use `hcloud network list`.
   - Firewall: Use `hcloud firewall list`.
   - SSH key: Use `hcloud ssh-key list`.
3. **Update the manifest below**: Modify the following `hetzner-mk8s-example.yaml` YAML manifest with actual values from above. Customize the file as needed. Replace the placeholders for `firewallId`, `networkId`, and `sshKey`.

```yaml YAML
kind: mk8s
name: hetzner-mk8s-example
description: An example of Hetzner mk8s
tags: {}
spec:
  provider:
    hetzner:
      dedicatedServerNodePools: []
      firewallId: '1111111'
      image: ubuntu-22.04
      networkId: '2222222'
      nodePools:
        - name: general
          labels:
            environment: hetzner-mk8s-example
          maxSize: 4
          minSize: 1
          serverType: cpx31
          taints: []
      region: hel1
      sshKey: '333333'
      tokenSecretLink: //secret/hetzner-mk8s-example
  addOns:
    dashboard: {}
    localPathStorage: {}
    awsWorkloadIdentity: {}
  firewall:
    - description: Default
      sourceCIDR: 0.0.0.0/0
  version: 1.28.2
```

This example creates a Managed Kubernetes cluster in Hetzner Cloud with the following configurations:

- **[Add-ons](#supported-add-ons)**: Includes Dashboard, Local Path Storage, and AWS Workload Identity.
- **Location**: The cluster's Kubernetes control plane will be managed in the `gcp-us-east1` location. Placing worker nodes close to the control plane is recommended for optimal performance.
- **Kubernetes API Firewall**: Utilizes the `Default` rule, allowing public access to the Kubernetes API. It is advisable to restrict API access to a known IP range for security purposes.
- **Kubernetes Version**: 1.28.2.
- **Node Pool**: A single `general` node pool, scaling on-demand between 1 and 4 nodes.
- **Server Image**: Ubuntu 22.04.

4. **Create the Cluster**: Deploy the `hetzner-mk8s-example` cluster by applying the manifest.

   - **Console**: Apply the `hetzner-mk8s-example.yaml` file using the `cpln apply >_` option in the upper right corner.
   - **CLI**: Execute `cpln apply -f hetzner-mk8s-example.yaml --org YOUR_ORG_HERE`.

   **Wait until the cluster is initialized.**

## Step 3 - Accessing the Cluster

### 1. Using the Terminal

1. **Obtain the Cluster's Kubeconfig File**: Execute the command `cpln mk8s kubeconfig hetzner-mk8s-example -f /tmp/hetzner-mk8s-example-conf`.
2. **Access the Cluster with `kubectl`**: Use the obtained kubeconfig file by running `export KUBECONFIG=/tmp/hetzner-mk8s-example-conf` for the current shell session.

### 2. Using Kubernetes Dashboard

1. **Navigate to Control Plane Console**: Visit the [Control Plane Console](https://console.cpln.io/console/).
2. **Access the Dashboard**: In the Control Plane Console, navigate to `Kubernetes` in the left sidebar panel and click on `Open` under `Dashboard` for the cluster `hetzner-mk8s-example`.


### Managed Kubernetes
**Path**: `self-hosted/mk8s/overview.mdx`

---
title: Managed Kubernetes
---

The Managed Kubernetes service developed by Control Plane is designed to facilitate the creation and management (i.e., upgrades and scaling) of Kubernetes clusters across multiple cloud platforms and private cloud environments. By offering a unified view for Kubernetes cluster management, this service enables the centralized management of numerous clusters on various cloud platforms, private clouds, and across accounts.

Managed Kubernetes handles the tasks required to maintain a healthy Kubernetes cluster. In addition, it manages autoscaling according to user preferences, optimizes costs by using spot instances when provided, and allows seamless upgrades based on the user's selected version.

## Supported Kubernetes versions

- 1.28.4 (latest)
- 1.28.2
- 1.27.3
- 1.26.4
- 1.26.0

## Infrastructure Providers

Click on provider name for details.

1. [Generic](/mk8s/generic)
2. [AWS](/mk8s/aws)
3. [Hetzner](/mk8s/hetzner)

## Add-Ons

Enables the user to turn on or off the following optional features.

- [Dashboard:](/mk8s/add-ons/dashboard) Provides a Kubernetes dashboard UI for the cluster.
- [AWS Workload Identity:](/mk8s/add-ons/aws_workload_identity) Allows your pods to assume AWS IAM Roles.
- [AWS ECR:](/mk8s/add-ons/aws_ecr) Allows pulling images from private ECR registries.
- [AWS EFS:](/mk8s/add-ons/aws_efs) Provides support for persistent volumes using AWS Elastic File System.
- [Local Path Storage:](/mk8s/add-ons/local_path_storage) Create PVCs backed by local volumes.
- [Logs:](/mk8s/add-ons/logs) Enable logging for pods and cluster auditing.