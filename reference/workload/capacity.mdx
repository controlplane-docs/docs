---
title: Capacity AI
---

## Overview

Workloads can leverage intelligent allocation of their container's resources (CPU and Memory) by using Capacity AI.

Capacity AI uses an analysis of historical usage to adjust the resources up/down between the configured minimum and maximum values of each container.

This can significantly reduce cost but may, in rare cases, cause temporary performance issues with sudden spikes in usage depending on the autoscaling settings of the workload.

If capacity AI is disabled, the amount of resources configured is set using the provided cpu and memory settings for each container.

## Resource Minimums

`minCpu` and `minMemory` are typically used only when Capacity AI is enabled. However, [stateful workloads](/reference/workload/types#stateful) always respect these fields.

## Limit Capacity AI update frequency

You can set the highest frequency that Capacity AI is allowed to update the resources of a workload by setting the `capacityAIUpdateMinutes` field in the workload options.
By defualt (when not set), Capacity AI can update the resources as frequently as necessary.

```yaml YAML
kind: workload
spec:
  defaultOptions:
    capacityAIUpdateMinutes: 30 # Capacity AI can update resources at most once every 30 minutes
```

## Caveats

Capacity AI must be disabled if the [autoscaling](/reference/workload/autoscaling) strategy is set to `CPU Utilization`.

Capacity AI is not supported for [stateful workloads](/reference/workload/types#stateful)

<Info>

Capacity AI will prevent the ratio of memory and cpu from diverging by a large percentage.

</Info>

<Note>Changes made to a workload will reset its historical usage and will restart the analysis process.</Note>

## Minimum Capacity AI

When resources are not being used, Capacity AI will downscale CPU usage to a minimum of 25 millicores. The minimum will increase depending on the memory size being recommended by Capacity AI using a 1:3 ratio of CPU millicores to memory MiB.
