---
title: Capacity AI
---

## Overview

Workloads can leverage intelligent allocation of their container's resources (CPU and Memory) by using Capacity AI.

Capacity AI uses an analysis of historical usage to adjust the resources up/down between the configured minimum and maximum values of each container.

This can significantly reduce cost but may, in rare cases, cause temporary performance issues with sudden spikes in usage depending on the autoscaling settings of the workload.

If capacity AI is disabled, the amount of resources configured is set using the provided cpu and memory settings for each container.

## Resource Minimums
`minCpu` and `minMemory` are typically used only when Capacity AI is enabled. However, [stateful workloads](/reference/workload/types#stateful) always respect these fields.

## Caveats
Capacity AI must be disabled if the [autoscaling](/reference/workload/autoscaling) strategy is set to `CPU Utilization`.

Capacity AI is not supported for [stateful workloads](/reference/workload/types#stateful)

<Info>

Capacity AI will prevent the ratio of memory and cpu from diverging by a large percentage.

</Info>

<Note>Changes made to a workload will reset its historical usage and will restart the analysis process.</Note>

## Minimum Capacity AI

When resources are not being used, Capacity AI will downscale CPU usage to a minimum of 25 millicores. The minimum will increase depending on the memory size being recommended by Capacity AI using a 1:3 ratio of CPU millicores to memory MiB.
